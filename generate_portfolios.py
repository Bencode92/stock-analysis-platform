import os
import json
import requests
import datetime
import locale
import time
import random
import re
from bs4 import BeautifulSoup

def extract_content_from_html(html_file):
    """Extraire le contenu pertinent d'un fichier HTML."""
    try:
        # Initialiser content comme une liste vide par d√©faut
        content = []
        
        with open(html_file, 'r', encoding='utf-8') as file:
            soup = BeautifulSoup(file, 'html.parser')
            
            # Extraire le contenu principal
            if html_file.endswith('actualites.html'):
                # Pour les actualit√©s, on cherche les articles de news
                articles = soup.select('.news-card, .article-item, .news-item')
                if not articles:
                    # Fallback: essayer de trouver d'autres √©l√©ments qui pourraient contenir des actualit√©s
                    articles = soup.select('article, .news, .actualite, .card')
                
                for article in articles[:15]:  # Limiter aux 15 premiers articles pour √©viter un prompt trop long
                    title = article.select_one('h2, h3, .title, .headline')
                    summary = article.select_one('p, .summary, .description')
                    
                    if title:
                        title_text = title.get_text(strip=True)
                        if title_text:
                            content.append("‚Ä¢ {}".format(title_text))
                            if summary:
                                summary_text = summary.get_text(strip=True)
                                if summary_text:
                                    content.append("  {}...".format(summary_text[:150]))  # Limiter la longueur
            
            elif html_file.endswith('marches.html'):
                # Extraction am√©lior√©e pour les march√©s - cibler les tableaux
                tables = soup.select('table, .table')
                if tables:
                    print(f"Trouv√© {len(tables)} tableaux dans {html_file}")
                    for table in tables:
                        # Extraire l'en-t√™te du tableau si pr√©sent
                        table_header = table.select_one('caption, thead, th')
                        if table_header:
                            header_text = table_header.get_text(strip=True)
                            content.append(f"üìä {header_text.upper()}:")
                        
                        # Extraire les lignes du tableau
                        rows = table.select('tr, .row')
                        for row in rows[:10]:  # Limiter √† 10 lignes
                            cells = row.select('td, th, .cell')
                            if cells:
                                row_data = " | ".join([cell.get_text(strip=True) for cell in cells if cell.get_text(strip=True)])
                                if row_data:
                                    content.append(f"‚Ä¢ {row_data}")
                
                # Si aucun tableau n'est trouv√©, essayer d'autres s√©lecteurs
                if not content:
                    market_data = soup.select('.market-trend, .market-data, .trend-item, .index-card, .market-item')
                    if not market_data:
                        # Fallback pour les √©l√©ments g√©n√©riques
                        market_data = soup.select('.card, .market, .indice, .asset-card')
                    
                    for item in market_data:
                        name = item.select_one('h3, h4, .name, .asset-name, .title')
                        value = item.select_one('.value, .price, .current-price')
                        change = item.select_one('.change, .variation, .performance')
                        
                        if name:
                            name_text = name.get_text(strip=True)
                            if name_text:
                                data_line = "‚Ä¢ {}".format(name_text)
                                if value:
                                    value_text = value.get_text(strip=True)
                                    data_line += ": {}".format(value_text)
                                if change:
                                    change_text = change.get_text(strip=True)
                                    data_line += " ({})".format(change_text)
                                content.append(data_line)
            
            elif html_file.endswith('secteurs.html'):
                # Extraction am√©lior√©e pour les secteurs - cibler les tableaux
                tables = soup.select('table, .table')
                if tables:
                    print(f"Trouv√© {len(tables)} tableaux dans {html_file}")
                    for table in tables:
                        # Extraire l'en-t√™te du tableau si pr√©sent
                        table_header = table.select_one('caption, thead, th')
                        if table_header:
                            header_text = table_header.get_text(strip=True)
                            content.append(f"üìä {header_text.upper() or 'PERFORMANCES SECTORIELLES'}:")
                        else:
                            content.append("üìä PERFORMANCES SECTORIELLES:")
                        
                        # Extraire les lignes du tableau
                        rows = table.select('tr, .row')
                        for row in rows[:15]:  # Limiter √† 15 lignes
                            cells = row.select('td, th, .cell')
                            if cells:
                                row_data = " | ".join([cell.get_text(strip=True) for cell in cells if cell.get_text(strip=True)])
                                if row_data:
                                    content.append(f"‚Ä¢ {row_data}")
                
                # Si aucun tableau n'est trouv√©, essayer les s√©lecteurs originaux
                if len(content) <= 1:
                    sector_data = soup.select('.sector-card, .sector-item, .performance-card')
                    if not sector_data:
                        # Fallback
                        sector_data = soup.select('.card, .sector, .industry-card, .industry-item')
                    
                    if not content:
                        content.append("üìä PERFORMANCES SECTORIELLES:")
                    
                    for item in sector_data:
                        name = item.select_one('h3, h4, .sector-name, .name, .title')
                        performance = item.select_one('.performance, .change, .variation')
                        trend = item.select_one('.trend, .direction, .recommendation')
                        
                        if name:
                            name_text = name.get_text(strip=True)
                            if name_text:
                                data_line = "‚Ä¢ {}".format(name_text)
                                if performance:
                                    perf_text = performance.get_text(strip=True)
                                    data_line += ": {}".format(perf_text)
                                if trend:
                                    trend_text = trend.get_text(strip=True)
                                    data_line += " - {}".format(trend_text)
                                content.append(data_line)
            
            elif html_file.endswith('liste.html'):
                # Extraction am√©lior√©e pour les listes - cibler les tableaux
                tables = soup.select('table, .table')
                if tables:
                    print(f"Trouv√© {len(tables)} tableaux dans {html_file}")
                    for table in tables:
                        # Extraire l'en-t√™te du tableau si pr√©sent
                        table_header = table.select_one('caption, thead, th')
                        if table_header:
                            header_text = table_header.get_text(strip=True)
                            # Utiliser des guillemets doubles pour √©viter d'√©chapper l'apostrophe
                            content.append(f"üìã {header_text.upper() or 'LISTES ACTIFS SURVEILL√âS'}:")
                        else:
                            content.append("üìã LISTES ACTIFS SURVEILL√âS:")
                        
                        # Extraire les lignes du tableau
                        rows = table.select('tr, .row')
                        for row in rows[:20]:  # Limiter √† 20 lignes
                            cells = row.select('td, th, .cell')
                            if cells:
                                row_data = " | ".join([cell.get_text(strip=True) for cell in cells if cell.get_text(strip=True)])
                                if row_data:
                                    content.append(f"‚Ä¢ {row_data}")
                
                # Si aucun tableau n'est trouv√©, essayer les s√©lecteurs originaux
                if len(content) <= 1:
                    asset_items = soup.select('.asset-item, .watchlist-item, .stock-item, .list-card')
                    if not asset_items:
                        # Fallback
                        asset_items = soup.select('.card, .item, tr, .asset')
                    
                    if not content:
                        content.append("üìã LISTES ACTIFS SURVEILL√âS:")
                    
                    for item in asset_items:
                        name = item.select_one('h3, h4, .asset-name, .name, .symbol, .title, td:first-child')
                        sector = item.select_one('.sector, .category, .type')
                        price = item.select_one('.price, .value, .current-price')
                        
                        if name:
                            name_text = name.get_text(strip=True)
                            if name_text:
                                data_line = "‚Ä¢ {}".format(name_text)
                                if sector:
                                    sector_text = sector.get_text(strip=True)
                                    data_line += " ({}): ".format(sector_text)
                                if price:
                                    price_text = price.get_text(strip=True)
                                    data_line += "{}".format(price_text)
                                content.append(data_line)
            
            elif html_file.endswith('etf.html'):
                # Extraction am√©lior√©e pour les ETF - cibler les tableaux
                tables = soup.select('table, .table')
                if tables:
                    print(f"Trouv√© {len(tables)} tableaux dans {html_file}")
                    for table in tables:
                        # Extraire l'en-t√™te du tableau si pr√©sent
                        table_header = table.select_one('caption, thead, th, h2, h3')
                        if table_header:
                            header_text = table_header.get_text(strip=True)
                            if "ETF" in header_text or not header_text:
                                content.append("üìä TOP ETF PERFORMANCES:")
                            else:
                                content.append(f"üìä {header_text.upper()}:")
                        else:
                            content.append("üìä ANALYSE DES ETF:")
                        
                        # Extraire les lignes du tableau
                        rows = table.select('tr, .row')
                        for row in rows[:15]:  # Limiter √† 15 lignes
                            cells = row.select('td, th, .cell')
                            if cells:
                                row_data = " | ".join([cell.get_text(strip=True) for cell in cells if cell.get_text(strip=True)])
                                if row_data:
                                    content.append(f"‚Ä¢ {row_data}")
                
                # Si aucun tableau n'est trouv√©, essayer des sections ou cartes d'ETF sp√©cifiques
                if len(content) <= 1:
                    # Chercher d'abord des sections avec des titres mentionnant ETF
                    etf_sections = []
                    for heading in soup.select('h1, h2, h3, h4, h5, h6'):
                        if 'ETF' in heading.get_text():
                            etf_sections.append(heading.parent)
                    
                    # Si des sections sont trouv√©es, extraire leur contenu
                    if etf_sections:
                        content.append("üìä ANALYSE DES ETF:")
                        for section in etf_sections:
                            title = section.select_one('h1, h2, h3, h4, h5, h6')
                            if title:
                                content.append(f"‚Ä¢ {title.get_text(strip=True)}")
                            
                            # Extraire des √©l√©ments liste ou paragraphes
                            items = section.select('li, p')
                            for item in items[:10]:
                                content.append(f"  - {item.get_text(strip=True)}")
                    
                    # Fallback sur les s√©lecteurs originaux
                    if len(content) <= 1:
                        etf_items = soup.select('.etf-card, .etf-item, .fund-card, .etf-table tr')
                        if not etf_items:
                            # Fallback
                            etf_items = soup.select('.card, .etf, tr, .fund')
                        
                        if not content:
                            content.append("üìä ANALYSE DES ETF:")
                        
                        for item in etf_items:
                            name = item.select_one('h3, h4, .etf-name, .name, .symbol, .title, td:first-child')
                            category = item.select_one('.category, .type, .asset-class')
                            aum = item.select_one('.aum, .size, .assets')
                            expense = item.select_one('.expense, .ter, .fee')
                            
                            if name:
                                name_text = name.get_text(strip=True)
                                if name_text:
                                    data_line = "‚Ä¢ {}".format(name_text)
                                    if category:
                                        category_text = category.get_text(strip=True)
                                        data_line += " ({})".format(category_text)
                                    if aum:
                                        aum_text = aum.get_text(strip=True)
                                        data_line += " AUM: {}".format(aum_text)
                                    if expense:
                                        expense_text = expense.get_text(strip=True)
                                        data_line += ", Frais: {}".format(expense_text)
                                    content.append(data_line)
            
            # Si aucun contenu sp√©cifique n'a √©t√© trouv√©, extraire le texte brut 
            if not content:
                # Extraire tout le contenu textuel de la page pour avoir quelque chose
                body_text = soup.body.get_text(strip=True) if soup.body else ""
                if body_text:
                    # Limiter √† 1000 caract√®res pour √©viter un prompt trop long
                    content.append(f"[Extraction brute de {html_file}]")
                    
                    # D√©couper le texte en lignes plus courtes pour plus de lisibilit√©
                    chunks = [body_text[i:i+100] for i in range(0, min(1000, len(body_text)), 100)]
                    for chunk in chunks:
                        content.append(chunk)
                else:
                    content.append(f"[Aucun contenu trouv√© dans {html_file}]")
            
            # Ajouter une ligne de log pour d√©boguer
            print(f"‚úÖ Contenu extrait de {html_file}: {len(content)} √©l√©ments trouv√©s")
            
            return "\n".join(content)
    except Exception as e:
        print(f"‚ùå Erreur lors de l'extraction du contenu de {html_file}: {str(e)}")
        # En cas d'erreur, retourner un placeholder pour ne pas bloquer l'ex√©cution
        return f"[Contenu non disponible pour {html_file}]"

def get_current_month_fr():
    """Retourne le nom du mois courant en fran√ßais."""
    try:
        # Tenter de d√©finir la locale en fran√ßais
        locale.setlocale(locale.LC_TIME, 'fr_FR.UTF-8')
    except locale.Error:
        # Fallback si la locale fran√ßaise n'est pas disponible
        month_names = {
            1: "janvier", 2: "f√©vrier", 3: "mars", 4: "avril",
            5: "mai", 6: "juin", 7: "juillet", 8: "ao√ªt",
            9: "septembre", 10: "octobre", 11: "novembre", 12: "d√©cembre"
        }
        return month_names[datetime.datetime.now().month]
    
    # Obtenir le mois en fran√ßais
    return datetime.datetime.now().strftime('%B').lower()

def filter_news_data(news_data):
    """Filtre les donn√©es d'actualit√©s pour n'inclure que les plus pertinentes."""
    if not news_data or not isinstance(news_data, dict):
        return "Aucune donn√©e d'actualit√© disponible"
    
    # S√©lectionner uniquement les actualit√©s des derniers jours
    filtered_news = []
    
    # Parcourir les actualit√©s par r√©gion
    for region, news_list in news_data.items():
        if not isinstance(news_list, list):
            continue
            
        # Ne prendre que les 5 actualit√©s les plus importantes par r√©gion
        important_news = []
        for news in news_list[:5]:  # Limiter √† 5 actualit√©s par r√©gion
            if not isinstance(news, dict):
                continue
                
            # Ne garder que les champs essentiels
            important_news.append({
                "title": news.get("title", ""),
                "impact": news.get("impact", ""),
                "category": news.get("category", ""),
                "date": news.get("date", "")
            })
        
        # Ajouter seulement si nous avons des actualit√©s
        if important_news:
            filtered_news.append(f"R√©gion {region}: " + 
                               ", ".join([f"{n['title']} ({n['impact']})" for n in important_news]))
    
    return "\n".join(filtered_news) if filtered_news else "Aucune actualit√© pertinente"

def filter_markets_data(markets_data):
    """Filtre les donn√©es de march√© pour n'inclure que les tendances principales."""
    if not markets_data or not isinstance(markets_data, dict):
        return "Aucune donn√©e de march√© disponible"
    
    market_summary = []
    
    # Traiter les indices
    if "indices" in markets_data and isinstance(markets_data["indices"], dict):
        for region, indices in markets_data["indices"].items():
            if not isinstance(indices, list):
                continue
                
            # Extraire seulement les principaux indices
            main_indices = []
            for idx in indices[:3]:  # Limiter √† 3 indices par r√©gion
                if not isinstance(idx, dict):
                    continue
                    
                name = idx.get("index_name", "")
                change = idx.get("change", "")
                trend = idx.get("trend", "")
                
                if name and change:
                    main_indices.append(f"{name}: {change} ({trend})")
            
            if main_indices:
                market_summary.append(f"Indices {region}: " + ", ".join(main_indices))
    
    # Ajouter d'autres sections importantes des march√©s si n√©cessaire
    # Par exemple, devises, mati√®res premi√®res, etc.
    
    return "\n".join(market_summary) if market_summary else "Aucune donn√©e de march√© significative"

def filter_sectors_data(sectors_data):
    """Filtre les donn√©es sectorielles pour identifier les secteurs performants et sous-performants."""
    if not sectors_data or not isinstance(sectors_data, dict):
        return "Aucune donn√©e sectorielle disponible"
    
    sector_summary = []
    
    if "sectors" in sectors_data and isinstance(sectors_data["sectors"], dict):
        # Identifier les secteurs avec les meilleures/pires performances
        top_performers = []
        worst_performers = []
        
        for sector_name, sector_data in sectors_data["sectors"].items():
            if not isinstance(sector_data, list):
                continue
                
            for item in sector_data[:2]:  # Limiter √† 2 √©l√©ments par secteur
                if not isinstance(item, dict):
                    continue
                    
                name = item.get("name", "")
                change = item.get("change", "")
                trend = item.get("trend", "")
                
                if name and change:
                    if trend == "up" and change.startswith("+"):
                        top_performers.append(f"{name} ({sector_name}): {change}")
                    elif trend == "down" and change.startswith("-"):
                        worst_performers.append(f"{name} ({sector_name}): {change}")
        
        # Limiter aux 5 meilleurs et 5 pires
        if top_performers:
            sector_summary.append("Secteurs performants: " + ", ".join(top_performers[:5]))
        if worst_performers:
            sector_summary.append("Secteurs sous-performants: " + ", ".join(worst_performers[:5]))
    
    return "\n".join(sector_summary) if sector_summary else "Aucune donn√©e sectorielle significative"

def filter_etf_data(etf_data):
    """Filtre les donn√©es ETF pour n'inclure que les ETF les plus performants."""
    if not etf_data or not isinstance(etf_data, dict):
        return "Aucune donn√©e ETF disponible"
    
    etf_summary = []
    
    # Extraire les ETF performants
    if "top50_etfs" in etf_data and isinstance(etf_data["top50_etfs"], list):
        top_etfs = []
        for etf in etf_data["top50_etfs"][:5]:  # Limiter aux 5 premiers
            if not isinstance(etf, dict):
                continue
                
            name = etf.get("name", "")
            ytd = etf.get("ytd", "")
            
            if name and ytd:
                top_etfs.append(f"{name}: {ytd}")
        
        if top_etfs:
            etf_summary.append("ETF performants: " + ", ".join(top_etfs))
    
    # Ajouter les top performers si disponibles
    if "top_performers" in etf_data and isinstance(etf_data["top_performers"], dict):
        if "ytd" in etf_data["top_performers"] and isinstance(etf_data["top_performers"]["ytd"], dict):
            best_ytd = etf_data["top_performers"]["ytd"].get("best", [])
            if isinstance(best_ytd, list) and best_ytd:
                best_names = []
                for etf in best_ytd[:3]:
                    if isinstance(etf, dict):
                        name = etf.get("name", "")
                        if name:
                            best_names.append(name)
                
                if best_names:
                    etf_summary.append("Meilleurs ETF YTD: " + ", ".join(best_names))
    
    return "\n".join(etf_summary) if etf_summary else "Aucune donn√©e ETF significative"

def filter_lists_data(lists_data):
    """Extrait les actifs les plus pertinents des listes de surveillance."""
    if not lists_data or not isinstance(lists_data, dict):
        return "Aucune liste d'actifs disponible"
    
    assets_summary = []
    
    # Parcourir les diff√©rentes listes
    for list_name, list_data in lists_data.items():
        if not isinstance(list_data, dict):
            continue
            
        trending_up = []
        trending_down = []
        
        # Rechercher dans les indices
        if "indices" in list_data and isinstance(list_data["indices"], dict):
            for letter, assets in list_data["indices"].items():
                if not isinstance(assets, list):
                    continue
                    
                for asset in assets:
                    if not isinstance(asset, dict):
                        continue
                        
                    name = asset.get("name", "")
                    change = asset.get("change", "")
                    trend = asset.get("trend", "")
                    
                    if name and change:
                        if trend == "up" and not change.startswith("-"):
                            trending_up.append(f"{name}: {change}")
                        elif trend == "down" and change.startswith("-"):
                            trending_down.append(f"{name}: {change}")
        
        # Limiter aux 5 meilleurs et 5 pires
        if trending_up:
            assets_summary.append(f"Actifs {list_name} en hausse: " + ", ".join(trending_up[:5]))
        if trending_down:
            assets_summary.append(f"Actifs {list_name} en baisse: " + ", ".join(trending_down[:5]))
    
    return "\n".join(assets_summary) if assets_summary else "Aucune donn√©e d'actifs significative"

def generate_portfolios(news_data, markets_data, sectors_data, lists_data, etfs_data):
    """G√©n√®re trois portefeuilles optimis√©s en combinant les donn√©es fournies et le contexte actuel du march√©."""
    api_key = os.environ.get('API_CHAT')
    if not api_key:
        raise ValueError("La cl√© API OpenAI (API_CHAT) n'est pas d√©finie.")
    
    # Obtenir le mois courant en fran√ßais
    current_month = get_current_month_fr()
    
    # ===== OPTIMISATION : FILTRER LES DONN√âES =====
    # Filtrer les donn√©es pour r√©duire la taille
    filtered_news = filter_news_data(news_data)
    filtered_markets = filter_markets_data(markets_data)
    filtered_sectors = filter_sectors_data(sectors_data)
    filtered_lists = filter_lists_data(lists_data)
    filtered_etfs = filter_etf_data(etfs_data)
    
    # Ajouter des logs pour d√©boguer les entr√©es
    print(f"üîç Longueur des donn√©es FILTR√âES:")
    print(f"  üì∞ Actualit√©s: {len(filtered_news)} caract√®res")
    print(f"  üìà March√©: {len(filtered_markets)} caract√®res")
    print(f"  üè≠ Secteurs: {len(filtered_sectors)} caract√®res")
    print(f"  üìã Listes: {len(filtered_lists)} caract√®res")
    print(f"  üìä ETFs: {len(filtered_etfs)} caract√®res")
    
    # Afficher les donn√©es filtr√©es pour v√©rification
    print("\n===== APER√áU DES DONN√âES FILTR√âES =====")
    print("\n----- ACTUALIT√âS (donn√©es filtr√©es) -----")
    print(filtered_news[:200] + "..." if len(filtered_news) > 200 else filtered_news)
    print("\n----- MARCH√âS (donn√©es filtr√©es) -----")
    print(filtered_markets[:200] + "..." if len(filtered_markets) > 200 else filtered_markets)
    print("\n----- SECTEURS (donn√©es filtr√©es) -----")
    print(filtered_sectors[:200] + "..." if len(filtered_sectors) > 200 else filtered_sectors)
    print("\n----- LISTES (donn√©es filtr√©es) -----")
    print(filtered_lists[:200] + "..." if len(filtered_lists) > 200 else filtered_lists)
    print("\n----- ETF (donn√©es filtr√©es) -----")
    print(filtered_etfs[:200] + "..." if len(filtered_etfs) > 200 else filtered_etfs)
    print("\n===========================================")
    
    # ===== SYST√àME DE RETRY AVEC BACKOFF EXPONENTIEL =====
    max_retries = 3
    backoff_time = 1  # Commencer avec 1 seconde
    
    for attempt in range(max_retries):
        try:
            # Construire un prompt beaucoup plus court avec les donn√©es filtr√©es
            prompt = f"""
Tu es un expert en gestion de portefeuille, avec une expertise en allocation strat√©gique et tactique. Tu vises √† maximiser le rendement ajust√© au risque en tenant compte de l'environnement macro√©conomique actuel.

Utilise ces donn√©es filtr√©es et synth√©tis√©es pour g√©n√©rer des portefeuilles optimis√©s :

üì∞ Actualit√©s financi√®res r√©centes: 
{filtered_news}

üìà Tendances du march√©: 
{filtered_markets}

üè≠ Analyse sectorielle: 
{filtered_sectors}

üìã Listes d'actifs surveill√©s: 
{filtered_lists}

üìä Analyse des ETF: 
{filtered_etfs}

üìÖ Contexte : Ces portefeuilles sont optimis√©s pour le mois de {current_month} en tenant compte des √©volutions √† court et moyen terme.

üéØ Ton objectif : G√©n√©rer trois portefeuilles optimis√©s :
1Ô∏è‚É£ Agressif : 10 √† 20 actifs tr√®s volatils (actions de croissance, crypto, ETF sp√©culatifs).  
2Ô∏è‚É£ Mod√©r√© : 10 √† 20 actifs √©quilibr√©s (blue chips, ETF diversifi√©s, obligations d'entreprises).  
3Ô∏è‚É£ Stable : 10 √† 20 actifs d√©fensifs (obligations souveraines, valeurs refuges, ETF stables).

üìä Format JSON uniquement:
{{
  "Agressif": {{
    "Actions": {{
      "Nom": "X%",
      ...
    }},
    "Crypto": {{ ... }},
    "ETF": {{ ... }},
    "Obligations": {{ ... }}
  }},
  "Mod√©r√©": {{ ... }},
  "Stable": {{ ... }}
}}

‚úÖ Contraintes :
- Chaque portefeuille: 10-20 actifs, somme 100%, minimum 2 classes d'actifs
- Surpond√©rer les secteurs en croissance dans Agressif/Mod√©r√©
- Renforcer les actifs refuges dans Stable en cas d'incertitude
- Ne r√©ponds qu'avec le JSON, sans commentaire ni explication.
"""
            
            headers = {
                "Authorization": f"Bearer {api_key}",
                "Content-Type": "application/json"
            }
            
            data = {
                "model": "gpt-4o",
                "messages": [{"role": "user", "content": prompt}],
                "temperature": 0.7
            }
            
            print(f"üöÄ Envoi de la requ√™te √† l'API OpenAI (tentative {attempt+1}/{max_retries})...")
            response = requests.post("https://api.openai.com/v1/chat/completions", headers=headers, json=data)
            response.raise_for_status()
            
            result = response.json()
            content = result["choices"][0]["message"]["content"]
            
            # Nettoyer la r√©ponse pour extraire seulement le JSON
            content = re.sub(r'^```json', '', content)
            content = re.sub(r'```$', '', content)
            content = content.strip()
            
            # V√©rifier que le contenu est bien du JSON valide
            portfolios = json.loads(content)
            print("‚úÖ Portefeuilles g√©n√©r√©s avec succ√®s")
            return portfolios
        
        except Exception as e:
            print(f"‚ùå Erreur lors de la tentative {attempt+1}: {str(e)}")
            
            if attempt < max_retries - 1:
                sleep_time = backoff_time + random.uniform(0, 1)
                print(f"‚è≥ Nouvelle tentative dans {sleep_time:.2f} secondes...")
                time.sleep(sleep_time)
                backoff_time *= 2  # Double le temps d'attente pour la prochaine tentative
            else:
                print("‚ùå √âchec apr√®s plusieurs tentatives, utilisation du portfolio par d√©faut")
                # En cas d'√©chec de toutes les tentatives, retourner un portfolio par d√©faut
                return {
                    "Agressif": {
                        "Actions": {"Apple": "15%", "Tesla": "10%", "Nvidia": "15%"},
                        "Crypto": {"Bitcoin": "15%", "Ethereum": "10%"},
                        "ETF": {"ARK Innovation ETF": "15%", "SPDR S&P 500 ETF": "10%"}
                    },
                    "Mod√©r√©": {
                        "Actions": {"Microsoft": "15%", "Alphabet": "10%", "Johnson & Johnson": "10%"},
                        "Obligations": {"US Treasury 10Y": "15%", "Corporate Bonds AAA": "15%"},
                        "ETF": {"Vanguard Total Stock Market ETF": "20%", "iShares Core MSCI EAFE ETF": "15%"}
                    },
                    "Stable": {
                        "Actions": {"Procter & Gamble": "10%", "Coca-Cola": "10%", "McDonald's": "10%"},
                        "Obligations": {"US Treasury 30Y": "25%", "Municipal Bonds AAA": "15%"},
                        "ETF": {"Vanguard High Dividend Yield ETF": "15%", "SPDR Gold Shares": "15%"}
                    }
                }

def save_portfolios(portfolios):
    """Sauvegarder les portefeuilles dans un fichier JSON et conserver l'historique."""
    try:
        # Cr√©ation du dossier d'historique s'il n'existe pas
        history_dir = 'data/portfolio_history'
        os.makedirs(history_dir, exist_ok=True)
        
        # G√©n√©ration d'un horodatage pour le nom de fichier
        timestamp = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')
        
        # Sauvegarder la version actuelle
        with open('portefeuilles.json', 'w', encoding='utf-8') as file:
            json.dump(portfolios, file, ensure_ascii=False, indent=4)
        
        # Sauvegarder dans l'historique avec l'horodatage
        history_file = "{}/portefeuilles_{}.json".format(history_dir, timestamp)
        with open(history_file, 'w', encoding='utf-8') as file:
            # Ajouter les m√©tadonn√©es de date pour faciliter la recherche ult√©rieure
            portfolios_with_metadata = {
                "timestamp": timestamp,
                "date": datetime.datetime.now().isoformat(),
                "portfolios": portfolios
            }
            json.dump(portfolios_with_metadata, file, ensure_ascii=False, indent=4)
        
        # Mettre √† jour le fichier d'index d'historique
        update_history_index(history_file, portfolios_with_metadata)
        
        print("‚úÖ Portefeuilles sauvegard√©s avec succ√®s dans portefeuilles.json et {}".format(history_file))
    except Exception as e:
        print("‚ùå Erreur lors de la sauvegarde des portefeuilles: {}".format(str(e)))

def update_history_index(history_file, portfolio_data):
    """Mettre √† jour l'index des portefeuilles historiques."""
    try:
        index_file = 'data/portfolio_history/index.json'
        
        # Charger l'index existant s'il existe
        index_data = []
        if os.path.exists(index_file):
            try:
                with open(index_file, 'r', encoding='utf-8') as file:
                    index_data = json.load(file)
            except json.JSONDecodeError:
                # R√©initialiser si le fichier est corrompu
                index_data = []
        
        # Cr√©er une entr√©e d'index avec les m√©tadonn√©es essentielles
        entry = {
            "file": os.path.basename(history_file),
            "timestamp": portfolio_data["timestamp"],
            "date": portfolio_data["date"],
            # Ajouter un r√©sum√© des allocations pour r√©f√©rence rapide
            "summary": {}
        }

        # Ajouter le r√©sum√© pour chaque type de portefeuille
        for portfolio_type, portfolio in portfolio_data["portfolios"].items():
            entry["summary"][portfolio_type] = {}
            for category, assets in portfolio.items():
                count = len(assets)
                entry["summary"][portfolio_type][category] = "{} actifs".format(count)
        
        # Ajouter la nouvelle entr√©e au d√©but de la liste (plus r√©cente en premier)
        index_data.insert(0, entry)
        
        # Limiter la taille de l'index si n√©cessaire (garder les 100 derni√®res entr√©es)
        if len(index_data) > 100:
            index_data = index_data[:100]
        
        # Sauvegarder l'index mis √† jour
        with open(index_file, 'w', encoding='utf-8') as file:
            json.dump(index_data, file, ensure_ascii=False, indent=4)
            
    except Exception as e:
        print("‚ö†Ô∏è Avertissement: Erreur lors de la mise √† jour de l'index: {}".format(str(e)))

def main():
    print("üîç Chargement des donn√©es financi√®res...")
    # Charger les donn√©es JSON directement depuis le dossier data/
    news_data = load_json_data('data/news.json')
    markets_data = load_json_data('data/markets.json')
    sectors_data = load_json_data('data/sectors.json')
    lists_data = load_json_data('data/lists.json')
    etfs_data = load_json_data('data/etf.json')
    
    print("üß† G√©n√©ration des portefeuilles optimis√©s...")
    portfolios = generate_portfolios(news_data, markets_data, sectors_data, lists_data, etfs_data)
    
    print("üíæ Sauvegarde des portefeuilles...")
    save_portfolios(portfolios)
    
    print("‚ú® Traitement termin√©!")

def load_json_data(file_path):
    """Charger des donn√©es depuis un fichier JSON."""
    try:
        with open(file_path, 'r', encoding='utf-8') as file:
            data = json.load(file)
            print(f"‚úÖ Donn√©es JSON charg√©es avec succ√®s depuis {file_path}")
            return data
    except Exception as e:
        print(f"‚ùå Erreur lors du chargement de {file_path}: {str(e)}")
        return {}

if __name__ == "__main__":
    main()