import os
import json
import requests
import datetime
import locale
import time
import random
import re
import math
import hashlib
from pathlib import Path
import pandas as pd
import numpy as np
from typing import Dict, List, Any, Tuple, Optional
from functools import lru_cache
from collections import defaultdict
import copy as _copy
import logging

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s | %(levelname)s | %(name)s | %(message)s"
)
logger = logging.getLogger("alloc-v3")

# Importer les fonctions d'ajustement des portefeuilles
from portfolio_adjuster import check_portfolio_constraints, adjust_portfolios, get_portfolio_prompt_additions, valid_etfs_cache, valid_bonds_cache
# Importer la fonction de formatage du brief
from brief_formatter import format_brief_data
# ============= PARSER JSON R√âPARATEUR (NOUVEAU) =============

def parse_json_strict_or_repair(s: str) -> dict:
    """Essaye json.loads, sinon r√©pare l√©g√®rement :
    - retire fences ```json ... ```
    - isole le bloc JSON ext√©rieur { ... }
    - normalise guillemets typographiques
    - remplace CR/LF bruts √† l'int√©rieur des cha√Ænes par \n
    - supprime virgules tra√Ænantes
    """
    try:
        return json.loads(s)
    except Exception:
        logger.warning("‚ö†Ô∏è JSON invalide d√©tect√©, tentative de r√©paration...")

        s2 = (s or "").strip()

        # 1) retirer √©ventuels fences
        s2 = re.sub(r'^\s*```(?:json)?\s*', '', s2)
        s2 = re.sub(r'\s*```\s*$', '', s2)

        # 2) ne garder que le premier '{' jusqu'au dernier '}'
        start = s2.find('{')
        end = s2.rfind('}')
        if start != -1 and end != -1 and end > start:
            s2 = s2[start:end+1]

        # 3) normaliser guillemets ‚Äú ‚Äù ‚Äò ‚Äô ‚Üí " '
        s2 = s2.translate({
            0x2018: 39, 0x2019: 39,  # ‚Äò ‚Äô -> '
            0x201C: 34, 0x201D: 34,  # ‚Äú ‚Äù -> "
        })

        # 4) remplacer CR/LF bruts √† l‚Äôint√©rieur des cha√Ænes par \n
        out = []
        in_str = False
        esc = False
        for ch in s2:
            if in_str:
                if esc:
                    out.append(ch)
                    esc = False
                elif ch == '\\':
                    out.append(ch)
                    esc = True
                elif ch == '"':
                    out.append(ch)
                    in_str = False
                elif ch in '\r\n':
                    out.append('\\n')
                else:
                    out.append(ch)
            else:
                out.append(ch)
                if ch == '"':
                    in_str = True
        s3 = ''.join(out)

        # 5) supprimer virgules finales avant } ou ]
        s3 = re.sub(r',(\s*[}\]])', r'\1', s3)

        logger.info("‚úÖ JSON r√©par√© avec succ√®s")
        return json.loads(s3)


# ============= COMPLIANCE AMF - GARDE-FOUS R√âGLEMENTAIRES =============

BANNED_MARKETING = [
    r"\bachet(?:er|ez|e|ons|√©es?)\b",
    r"\bvend(?:re|ez|e|ons|u(?:e|s|es)?)\b",
    r"\bconserv(?:er|ez|e|ons|ation)\b",

    # prioriser / privil√©gier (toutes variantes + accents)
    r"\b(prioriser|prioritaire|privil[e√©]g(?:ier|ie|i(?:e|ons))|√†\s*privil[e√©]gier)\b",

    # fortement recommand√© (toutes flexions + accents)
    r"\bfortement\s+recommand[e√©](?:e|es|s)?\b",

    # garanti, sans risque
    r"\bgaranti(?:e|es|s)?\b",
    r"\bsans\s*risque(?:s)?\b",

    # objectif/target de prix + price target
    r"\b(objectif|target)\s+de\s+prix\b",
    r"\bprice\s*target\b",

    # rendement attendu (pluriels/f√©minins)
    r"\brendement(?:s)?\s+attendu(?:s|e|es)?\b",

    # injonctions
    r"\b(vous\s+)?devez\b",
    r"\bil\s*faut\b",
    r"\bconseillons?\b",
    r"\brecommand(?:ons|e|ez)\b",
    r"\bvous\s+devriez\b"
]

def sanitize_marketing_language(text: str) -> str:
    """Supprime le langage d'incitation interdit par l'AMF"""
    out = text or ""
    for pat in BANNED_MARKETING:
        out = re.sub(pat, "[formulation neutre]", out, flags=re.IGNORECASE)
    return out

def get_compliance_block() -> Dict:
    """Retourne le bloc de compliance standardis√© AMF"""
    return {
        "jurisdiction": "FR",
        "disclaimer": (
            "Information √† caract√®re purement indicatif et p√©dagogique. "
            "Ce contenu ne constitue ni un conseil en investissement, ni une recommandation personnalis√©e, "
            "ni une sollicitation d'achat/vente. Performances pass√©es non indicatives des performances futures. "
            "Vous restez seul responsable de vos d√©cisions. Si besoin, consultez un conseiller en investissement financier (CIF) agr√©√©."
        ),
        "risk_notice": [
            "Les crypto-actifs sont tr√®s volatils et peuvent entra√Æner une perte totale.",
            "Les ETF √† effet de levier et produits inverses sont exclus.",
            "Diversification et horizon d'investissement requis.",
            "Risques de change pour les actifs internationaux.",
            "Risque de liquidit√© sur certains march√©s."
        ],
        "sources": ["Donn√©es de march√© publiques/CSV internes"],
        "last_update": datetime.datetime.utcnow().isoformat() + "Z"
    }

def attach_compliance(portfolios: Dict) -> Dict:
    """Attache le bloc compliance de mani√®re s√ªre en v√©rifiant les types"""
    if not isinstance(portfolios, dict):
        return portfolios
    
    block = get_compliance_block()
    for key in ["Agressif", "Mod√©r√©", "Stable"]:
        if isinstance(portfolios.get(key), dict):
            portfolios[key]["Compliance"] = block
    return portfolios

# ============= NOUVEAU SYST√àME DE SCORING V3 - QUANTITATIF =============

# FIX 1: Regex non-capturant pour √©viter le warning pandas
LEVERAGED_RE = re.compile(r"(?:2x|3x|ultra|lev|leverage|inverse|bear|-1x|-2x|-3x)", re.I)

def fnum(x):
    """Conversion robuste vers float"""
    s = re.sub(r"[^0-9.\-]", "", str(x or ""))
    try: 
        return float(s) if s not in ("", "-", ".", "-.") else 0.0
    except: 
        return 0.0

def _winsor(x, p=0.02):
    """Winsorisation pour √©liminer les outliers"""
    if len(x) == 0: 
        return np.array([])
    lo, hi = np.nanpercentile(x, [p*100, 100-p*100])
    return np.clip(x, lo, hi)

def _z(arr):
    """Z-score normalis√©"""
    v = np.array([fnum(a) for a in arr], dtype=float)
    if len(v) == 0: 
        return v
    v = _winsor(v)
    mu, sd = np.nanmean(v), (np.nanstd(v) or 1.0)
    return (v - mu) / sd

def compute_score(rows, kind):
    """
    Calcul du score quantitatif : momentum - risque - sur-extension + liquidit√©
    rows: [{name, perf_1m, perf_3m, perf_90d, perf_24h, perf_7d, ytd, vol30, vol_3y, maxdd90, liquidity}]
    kind: 'equity' | 'etf' | 'crypto'
    """
    n = len(rows)
    if n == 0: 
        return rows

    # -- Momentum adaptatif selon le type d'actif
    if kind == "crypto":
        mom_raw = [0.5*fnum(r.get("perf_7d")) + 0.5*fnum(r.get("perf_24h")) for r in rows]
    else:
        # Fallback robuste si 1m/3m manquants : 0.7*YTD + 0.3*Daily*20
        m1 = [fnum(r.get("perf_1m")) for r in rows]
        m3 = [fnum(r.get("perf_3m")) for r in rows]
        m90= [fnum(r.get("perf_90d")) for r in rows]
        ytd= [fnum(r.get("ytd")) for r in rows]
        d1 = [fnum(r.get("perf_24h")) for r in rows]
        have_m = any(m3) or any(m1) or any(m90)
        if have_m:
            mom_raw = [0.5*m3[i] + 0.3*m1[i] + 0.2*m90[i] for i in range(n)]
        else:
            mom_raw = [0.7*ytd[i] + 0.3*(d1[i]*20.0) for i in range(n)]
    mom = _z(mom_raw)

    # -- Mesure du risque (volatilit√© + drawdown)
    vol30 = [fnum(r.get("vol30")) for r in rows]
    vol3y = [fnum(r.get("vol_3y")) for r in rows]
    vol_used = [vol30[i] if vol30[i] != 0 else vol3y[i] for i in range(n)]
    risk_vol = _z(vol_used)

    # drawdown: toujours en valeur absolue
    dd = [abs(fnum(r.get("maxdd90"))) for r in rows]
    risk_dd = _z(dd) if any(dd) else np.zeros(n)

    # -- D√©tection de sur-extension (anti-fin-de-cycle)
    ytd = [fnum(r.get("ytd")) for r in rows]
    p1m = [fnum(r.get("perf_1m")) for r in rows]
    p7d = [fnum(r.get("perf_7d")) for r in rows]
    p24 = [fnum(r.get("perf_24h")) for r in rows]
    overext = []
    for i, r in enumerate(rows):
        if kind == "crypto":
            decel = p24[i] < (p7d[i]/3.0)
        else:
            decel = p1m[i] < (fnum(r.get("perf_3m"))/3.0)
        
        flag = (ytd[i] > 80 and (p1m[i] <= 0 or decel)) or (ytd[i] > 150)
        overext.append(1.0 if flag else 0.0)
        r["flags"] = {"overextended": bool(flag)}

    # -- Bonus liquidit√© (√©vite les nains illiquides)
    liq = _z([math.log(max(fnum(r.get("liquidity")), 1.0)) for r in rows]) if any(fnum(r.get("liquidity")) for r in rows) else np.zeros(n)
    liq_weight = 0.30 if kind == "etf" else (0.15 if kind == "equity" else 0.0)

    # -- Score final : momentum - risque - sur-extension + liquidit√©
    score = mom - (0.6*risk_vol + 0.4*risk_dd) - np.array(overext)*0.8 + liq_weight*liq
    
    for i, r in enumerate(rows):
        r["score"] = float(score[i])
    
    return rows

def read_combined_etf_csv(path_csv):
    """
    Lecture et pr√©paration des ETF avec d√©tection corrig√©e des ETF √† effet de levier
    + fallback robuste quand certaines colonnes manquent.
    """
    df = pd.read_csv(path_csv)

    # Cast des colonnes num√©riques (si pr√©sentes)
    num_cols = ["daily_change_pct", "ytd_return_pct", "one_year_return_pct",
                "vol_pct", "vol_3y_pct", "aum_usd", "total_expense_ratio", "yield_ttm"]
    for c in num_cols:
        if c in df.columns:
            df[c] = pd.to_numeric(df[c], errors="coerce")

    # ------ Fallback nom (assure la pr√©sence de df["name"]) ------
    name_col = next((c for c in ["name", "long_name", "etf_name", "symbol", "ticker"] if c in df.columns), None)
    if name_col is None:
        df["name"] = [f"ETF_{i}" for i in range(len(df))]
    else:
        df["name"] = df[name_col].astype(str)

    # Helper pour r√©cup√©rer une Series (sinon s√©rie vide align√©e sur l‚Äôindex)
    def _series(col, default=""):
        return df[col] if col in df.columns else pd.Series(default, index=df.index)

    # --- D√©tection obligations (robuste si colonnes absentes)
    df["is_bond"] = (
        _series("fund_type").astype(str).str.contains(r"Bond|Fixed Income|Obligation", case=False, na=False)
        | _series("etf_type").astype(str).str.contains(r"Bond|Fixed Income|Obligation", case=False, na=False)
    )

    # --- D√©tection levier corrig√©e (valeur explicite OU mots-cl√©s)
    lev_text = _series("leverage").fillna("").astype(str).str.strip().str.lower()
    has_lev_value = ~lev_text.isin(["", "0", "none", "nan", "na", "n/a"])

    looks_leveraged = (
        _series("etf_type").astype(str).str.contains(r"\b(?:lev|inverse|bear|bull)\b", case=False, na=False)
      | df["name"].astype(str).str.contains(LEVERAGED_RE, na=False)
    )


    df["is_leveraged"] = has_lev_value | looks_leveraged

    print(f"  üîç Debug ETF: Total={len(df)}, Bonds={df['is_bond'].sum()}, Leveraged={df['is_leveraged'].sum()}")
    print(f"  üìä ETF standards disponibles: {len(df[~df['is_bond'] & ~df['is_leveraged']])}")
    print(f"  üìâ ETF obligations disponibles: {len(df[df['is_bond'] & ~df['is_leveraged']])}")

    return df

def build_scored_universe_v3(stocks_jsons, etf_csv_path, crypto_csv_path):
    """
    Construction de l'univers ferm√© avec scoring quantitatif
    Retourne les meilleurs actifs √©quilibr√©s par risque
    """
    logger.info("üßÆ Construction de l'univers quantitatif v3...")

    # ====== ACTIONS (depuis les stocks_*.json) ======
    eq_rows = []
    total_stocks = 0
    for data in stocks_jsons:
        for it in data.get("stocks", []):
            total_stocks += 1
            eq_rows.append({
                "name": it.get("name") or it.get("ticker"),
                "perf_1m": it.get("perf_1m"),
                "perf_3m": it.get("perf_3m"),
                "perf_90d": it.get("perf_3m"),     # fallback acceptable
                "ytd": it.get("perf_ytd"),
                "vol30": None,                     # pas de 30j; on utilisera vol_3y
                "vol_3y": it.get("volatility_3y"),
                "maxdd90": it.get("max_drawdown_ytd"),  # best proxy dispo
                "perf_24h": it.get("perf_1d"),
                "liquidity": it.get("market_cap"),
                "sector": it.get("sector", "Unknown"),
                "country": it.get("country", "Unknown")
            })

    logger.info("üìä Stocks charg√©es: %s ‚Üí Analyse: %s", total_stocks, len(eq_rows))
    eq_rows = compute_score(eq_rows, "equity")
    
    # Filtrage actions : vol contr√¥l√©e + drawdown acceptable + pas de sur-extension
    def in_equity_bounds(r):
        v = fnum(r.get("vol_3y"))
        dd = abs(fnum(r.get("maxdd90")))
        return 12 <= v <= 60 and dd <= 25 and not r["flags"]["overextended"]
    
    eq_filtered = [r for r in eq_rows if in_equity_bounds(r)]
    print(f"  ‚úÖ Actions filtr√©es: {len(eq_filtered)}/{len(eq_rows)} (vol 12-60%, DD‚â§25%, non sur-√©tendues)")

    # ====== ETFs (CSV combin√©) ======
    etf_df = read_combined_etf_csv(etf_csv_path)
    etf_std = etf_df[~etf_df["is_bond"] & ~etf_df["is_leveraged"]]
    etf_bonds = etf_df[etf_df["is_bond"] & ~etf_df["is_leveraged"]]
    
    print(f"  üìä ETF analys√©s: {len(etf_df)} ‚Üí Standards: {len(etf_std)}, Obligations: {len(etf_bonds)}")
    print(f"  üö´ ETF √† effet de levier exclus: {len(etf_df[etf_df['is_leveraged']])}")

    def _etf_rows(df):
        rows = []
        for _, r in df.iterrows():
            rows.append({
                "name": str(r["name"]),
                "perf_1m": None, "perf_3m": None, "perf_90d": None,
                "perf_24h": r.get("daily_change_pct"),
                "ytd": r.get("ytd_return_pct"),
                "vol30": r.get("vol_pct") if str(r.get("vol_window", "")).lower() in ("30d", "1m", "30") else None,
                "vol_3y": r.get("vol_3y_pct") or r.get("vol_pct"),
                "maxdd90": None,
                "liquidity": r.get("aum_usd"),
                "flags": {"overextended": False},
            })
        return rows

    etf_rows = compute_score(_etf_rows(etf_std), "etf")
    
    # Filtrage ETF standards
    def _v_etf(r):
        v = fnum(r.get("vol30")) or fnum(r.get("vol_3y"))
        return 8 <= v <= 40
    
    etf_filtered = [r for r in etf_rows if _v_etf(r) and not r["flags"]["overextended"]]
    logger.info("‚úÖ ETF standards filtr√©s: %s/%s", len(etf_filtered), len(etf_rows))

    # ETF obligataires (liste blanche, pas de filtre strict)
    bond_rows = compute_score(_etf_rows(etf_bonds), "etf")
    print(f"  üìã ETF obligataires: {len(bond_rows)} (liste blanche)")

    # ====== CRYPTO (CSV filtr√© volatilit√©) ======
    try:
        cdf = pd.read_csv(crypto_csv_path)
        # Cast des colonnes crypto
        for c in ["ret_1d_pct", "ret_7d_pct", "ret_30d_pct", "ret_90d_pct", "ret_ytd_pct", "vol_30d_annual_pct", "drawdown_90d_pct", "atr14_pct"]:
            if c in cdf.columns: 
                cdf[c] = pd.to_numeric(cdf[c], errors="coerce")
        
        cr_rows = []
        for _, r in cdf.iterrows():
            cr_rows.append({
                "name": str(r.get("symbol")),
                "perf_24h": r.get("ret_1d_pct"),
                "perf_7d": r.get("ret_7d_pct"),
                "ytd": r.get("ret_ytd_pct"),
                "vol30": r.get("vol_30d_annual_pct"),
                "vol_3y": None,
                "maxdd90": r.get("drawdown_90d_pct"),
                "flags": {"overextended": False},
            })
        
        cr_rows = compute_score(cr_rows, "crypto")
        
        # Filtrage crypto : tendance + anti-spike + bornes vol
        crypto_filtered = []
        for r in cr_rows:
            p7d = fnum(r["perf_7d"])
            p24h = fnum(r["perf_24h"])
            ok_trend = p7d > p24h > 0 and p24h <= 0.4 * p7d  # Anti-spike
            
            v = fnum(r.get("vol30"))
            ok_vol = 40 <= v <= 140
            ok_dd = fnum(r.get("maxdd90")) > -40
            
            if ok_trend and ok_vol and ok_dd:
                crypto_filtered.append(r)
        
        print(f"  ‚úÖ Cryptos filtr√©es: {len(crypto_filtered)}/{len(cr_rows)} (tendance stable + vol 40-140% + DD>-40%)")
        
        # Fallback: si trop peu de candidats, desserrer l√©g√®rement les crit√®res
        if len(crypto_filtered) < 5:
            crypto_relaxed = []
            for r in cr_rows:
                p7d  = fnum(r.get("perf_7d"))
                p24h = fnum(r.get("perf_24h"))
                v    = fnum(r.get("vol30"))
                ddv  = abs(fnum(r.get("maxdd90")))
                ok_trend2 = p7d > p24h > 0 and p24h <= 0.5 * p7d
                ok_vol2   = 40 <= v <= 160
                ok_dd2    = ddv <= 50
                if ok_trend2 and ok_vol2 and ok_dd2:
                    crypto_relaxed.append(r)

            # Concat sans doublon puis limite √† 10
            seen = set(id(x) for x in crypto_filtered)
            for r in crypto_relaxed:
                if id(r) not in seen:
                    crypto_filtered.append(r)
                    seen.add(id(r))
            print(f"  üîÅ Fallback crypto appliqu√© ‚Üí {len(crypto_filtered)} candidats")
    
    except Exception as e:
        print(f"  ‚ö†Ô∏è Erreur crypto: {e}")
        crypto_filtered = []

    # ====== CLASSIFICATION PAR RISQUE ET √âQUILIBRAGE ======
    def risk_class(kind, r):
        v = fnum(r.get("vol30") or r.get("vol_3y"))
        if kind == "etf":   
            return "low" if 8 <= v <= 20 else ("mid" if 20 < v <= 40 else "out")
        if kind == "equity":
            return "low" if 12 <= v <= 25 else ("mid" if 25 < v <= 60 else "out")
        return "low" if 40 <= v <= 70 else ("mid" if 70 < v <= 140 else "out")

    for r in eq_filtered:    r["risk_class"] = risk_class("equity", r)
    for r in etf_filtered:   r["risk_class"] = risk_class("etf", r)
    for r in crypto_filtered: r["risk_class"] = risk_class("crypto", r)
    for r in bond_rows:      r["risk_class"] = "bond"

    def top_balanced(rows, n):
        """√âquilibrage low/mid risque pour √©viter la surconcentration"""
        rows = sorted(rows, key=lambda x: x["score"], reverse=True)
        low = [x for x in rows if x["risk_class"] == "low"][:n//2]
        mid = [x for x in rows if x["risk_class"] == "mid"][:n-len(low)]
        return low + mid

    # Diversification sectorielle pour les actions
    def sector_balanced(eq_rows, n, sector_cap=0.30):
        """Round-robin par secteur avec cap (30% par d√©faut)"""
        if not eq_rows:
            return []

        # Tri par score d√©croissant et bucket par secteur
        buckets = defaultdict(list)
        for x in sorted(eq_rows, key=lambda x: x["score"], reverse=True):
            buckets[x.get("sector", "Unknown")].append(x)

        # Ordre des secteurs: meilleur top-score en premier
        sector_order = sorted(
            buckets.keys(),
            key=lambda s: buckets[s][0]["score"] if buckets[s] else -1e9,
            reverse=True
        )

        out, picked_per_sector = [], defaultdict(int)
        max_per_sector = max(1, int(n * sector_cap))

        # Round-robin
        while len(out) < n:
            progressed = False
            for s in sector_order:
                if picked_per_sector[s] >= max_per_sector:
                    continue
                if buckets[s]:
                    out.append(buckets[s].pop(0))
                    picked_per_sector[s] += 1
                    progressed = True
                    if len(out) >= n:
                        break
            if not progressed:
                # plus rien √† prendre
                break

        return out[:n]

    # Limiter le nombre d'actifs pour r√©duire la taille du prompt
    universe = {
        "equities": sector_balanced(eq_filtered, min(25, len(eq_filtered))),  # R√©duit de 30 √† 25
        "etfs": top_balanced(etf_filtered, min(15, len(etf_filtered))),       # R√©duit de 20 √† 15
        "bonds": sorted(bond_rows, key=lambda x: x["score"], reverse=True)[:10],  # R√©duit de 20 √† 10
        "crypto": sorted(crypto_filtered, key=lambda x: x["score"], reverse=True)[:5],  # R√©duit de 10 √† 5
    }

    # Stats de l'univers
    stats = {
        "equities_avg_score": np.mean([e["score"] for e in universe["equities"]]) if universe["equities"] else 0,
        "etfs_avg_score": np.mean([e["score"] for e in universe["etfs"]]) if universe["etfs"] else 0,
        "crypto_avg_score": np.mean([c["score"] for c in universe["crypto"]]) if universe["crypto"] else 0,
        "total_assets": sum(len(v) for v in universe.values())
    }
    
    print(f"  üìä Univers final: {stats['total_assets']} actifs (optimis√© pour prompt)")
    print(f"     ‚Ä¢ Actions: {len(universe['equities'])} (score moy: {stats['equities_avg_score']:.2f})")
    print(f"     ‚Ä¢ ETF: {len(universe['etfs'])} (score moy: {stats['etfs_avg_score']:.2f})")  
    print(f"     ‚Ä¢ Obligations: {len(universe['bonds'])}")
    print(f"     ‚Ä¢ Crypto: {len(universe['crypto'])} (score moy: {stats['crypto_avg_score']:.2f})")

    return universe

# ============= NOUVELLES FONCTIONS ROBUSTES VERSION 3 =============

def prepare_structured_data(filtered_data: Dict) -> Dict:
    """
    Transforme les donn√©es filtr√©es en format structur√© avec IDs courts
    pour r√©duire les tokens et am√©liorer la pr√©cision
    """
    
    # 1. Brief en points num√©rot√©s
    brief_points = []
    if filtered_data.get('brief'):
        brief_text = filtered_data['brief']
        # Extraire les points cl√©s du brief et les structurer
        brief_lines = brief_text.split('\n')
        point_id = 1
        for line in brief_lines:
            line = line.strip()
            if line and len(line) > 20:  # √âviter les lignes trop courtes
                brief_points.append({
                    "id": f"BR{point_id}",
                    "text": line[:150] + "..." if len(line) > 150 else line
                })
                point_id += 1
                if point_id > 10:  # Limiter √† 10 points max
                    break
    
    # 2. Points march√©s (extraits depuis filtered_markets)
    market_points = []
    if filtered_data.get('markets'):
        markets_text = filtered_data['markets']
        market_lines = [line.strip() for line in markets_text.split('\n') if line.strip() and '‚Ä¢' in line]
        for i, line in enumerate(market_lines[:8]):  # Max 8 points
            market_points.append({
                "id": f"MC{i+1}",
                "text": line.replace('‚Ä¢', '').strip()[:120]
            })
    
    # 3. Points sectoriels (extraits depuis filtered_sectors)
    sector_points = []
    if filtered_data.get('sectors'):
        sectors_text = filtered_data['sectors']
        sector_lines = [line.strip() for line in sectors_text.split('\n') if line.strip() and '‚Ä¢' in line]
        for i, line in enumerate(sector_lines[:8]):  # Max 8 points
            sector_points.append({
                "id": f"SEC{i+1}",
                "text": line.replace('‚Ä¢', '').strip()[:120]
            })
    
    # 4. Th√®mes (extraits depuis filtered_themes)
    theme_points = []
    if filtered_data.get('themes'):
        themes_text = filtered_data['themes']
        theme_lines = [line.strip() for line in themes_text.split('\n') if line.strip() and '‚Ä¢' in line]
        for i, line in enumerate(theme_lines[:6]):  # Max 6 points
            theme_points.append({
                "id": f"TH{i+1}",
                "text": line.replace('‚Ä¢', '').strip()[:120]
            })
    
    return {
        "brief_points": brief_points,
        "market_points": market_points,
        "sector_points": sector_points,
        "theme_points": theme_points
    }

def extract_allowed_assets(filtered_data: Dict) -> Dict:
    """
    Extrait les actifs autoris√©s depuis les donn√©es filtr√©es.
    NOUVEAU: d√©duplication des ETF standards par ancres (gold, sp500, nasdaq, world,
    treasury, eurozone, emerging, silver, oil, energy) via dedupe_by_anchors,
    afin de n'autoriser qu'UN seul ETF par th√®me fortement corr√©l√©.
    """

    # ====== Cas v3 : univers quantitatif pr√©sent ======
    u = filtered_data.get("universe")
    if u:
        def mk(items, prefix):
            out = []
            for i, it in enumerate(items, start=1):
                out.append({
                    "id": f"{prefix}{i}",
                    "name": it.get("name"),
                    "symbol": (it.get("name") or "").split()[0][:6].upper(),
                    "score": round(float(it.get("score", 0)), 3),
                    "risk_class": it.get("risk_class", "mid"),
                    "flags": it.get("flags", {}),
                    "sector": it.get("sector", "Unknown"),
                    "country": it.get("country", "Global"),
                    # m√©triques utiles pour les contr√¥les
                    "ytd": fnum(it.get("ytd")),
                    "perf_1m": fnum(it.get("perf_1m")),
                })
            return out

        # D√©duplique les ETF standards par ancres AVANT mappage ID
        etfs_raw = u.get("etfs", []) or []
        etfs_dedup = dedupe_by_anchors(etfs_raw)  # <= cl√©: max 1 "gold", "sp500", etc.

        return {
            "allowed_equities": mk(u.get("equities", []) or [], "EQ_"),
            "allowed_etfs_standard": mk(etfs_dedup, "ETF_s"),
            "allowed_bond_etfs": mk(u.get("bonds", []) or [], "ETF_b"),  # pas de d√©dup sp√©cifique demand√©e c√¥t√© bonds
            "allowed_crypto": [{
                "id": f"CR_{i+1}",
                "name": it.get("name"),
                "symbol": (it.get("name") or "")[:6].upper(),
                "sevenDaysPositif": True,
                "score": round(float(it.get("score", 0)), 3),
                "risk_class": it.get("risk_class", "mid"),
                "ytd": fnum(it.get("ytd")),
                "perf_1m": fnum(it.get("perf_1m")),
            } for i, it in enumerate(u.get("crypto", []) or [])],
            # üëá NOUVEAU : tampon de liquidit√© optionnel (0‚Äì10% dans le prompt)
            "allowed_cash": [
                {"id": "CASH", "name": "Cash (placeholder)", "score": 0.0, "risk_class": "bond"}
            ],
        }

    # ====== Fallback legacy : parsing texte ======
    print("‚ö†Ô∏è Pas d'univers quantitatif, utilisation du fallback parsing texte")
    # Actions autoris√©es
    allowed_equities = []
    if filtered_data.get('lists'):
        lists_text = filtered_data['lists']
        equity_id = 1
        for line in lists_text.split('\n'):
            if '‚Ä¢' in line and 'YTD' in line:
                parts = line.split(':')
                if len(parts) >= 2:
                    name = parts[0].replace('‚Ä¢', '').strip()
                    name = re.sub(r'[üö©üìâ]', '', name).strip()
                    if '(' in name and 'potentielle' in name:
                        name = name.split('(')[0].strip()
                    region = "US" if any(x in name for x in ["Inc", "Corp", "LLC"]) else "Europe"
                    sector = "Technology"
                    allowed_equities.append({
                        "id": f"EQ_{equity_id}",
                        "name": name,
                        "symbol": name.split()[0] if len(name.split()) > 0 else name[:4].upper(),
                        "region": region,
                        "sector": sector,
                        "score": 0.0,
                        "risk_class": "mid",
                        "flags": {"overextended": False},
                        "ytd": 0.0,
                        "perf_1m": 0.0
                    })
                    equity_id += 1
                    if equity_id > 30:
                        break

    # ETF standards autoris√©s (legacy) ‚Äî> d√©dupliqu√©s par ancres
    raw_etfs_standard = []
    if filtered_data.get('etfs'):
        etfs_text = filtered_data['etfs']
        for line in etfs_text.split('\n'):
            if '‚Ä¢' in line and 'ETF' in line and 'OBLIGATAIRE' not in line.upper():
                etf_name = line.split('‚Ä¢')[1].split(':')[0].strip() if '‚Ä¢' in line else ""
                if etf_name and len(etf_name) > 5:
                    raw_etfs_standard.append({
                        "name": etf_name,
                        "score": 0.0,  # inconnu en legacy ‚Üí neutre
                        "risk_class": "mid",
                        "flags": {"overextended": False},
                        "ytd": 0.0,
                        "perf_1m": 0.0
                    })

    # D√©duplication par ancres (gold/sp500/nasdaq/world/treasury/‚Ä¶)
    etfs_dedup_legacy = dedupe_by_anchors(raw_etfs_standard)

    # R√©indexation propre des IDs apr√®s d√©dup
    allowed_etfs_standard = []
    for j, it in enumerate(etfs_dedup_legacy[:20], start=1):
        allowed_etfs_standard.append({
            "id": f"ETF_s{j}",
            "name": it["name"],
            "symbol": it["name"].split()[0][:4].upper() if it["name"].split() else "ETF",
            "score": float(it.get("score", 0.0)),
            "risk_class": it.get("risk_class", "mid"),
            "flags": it.get("flags", {"overextended": False}),
            "ytd": fnum(it.get("ytd")),
            "perf_1m": fnum(it.get("perf_1m")),
        })

    # ETF obligataires autoris√©s (legacy)
    allowed_bond_etfs = []
    if filtered_data.get('bond_etf_names'):
        for i, name in enumerate(filtered_data['bond_etf_names'][:15]):
            allowed_bond_etfs.append({
                "id": f"ETF_b{i+1}",
                "name": name,
                "symbol": name.split()[0][:4].upper() if name.split() else "BOND",
                "score": 0.0,
                "risk_class": "bond",
                "flags": {"overextended": False},
                "ytd": 0.0,
                "perf_1m": 0.0
            })

    # Cryptos autoris√©es (legacy)
    allowed_crypto = []
    if filtered_data.get('crypto'):
        crypto_text = filtered_data['crypto']
        crypto_id = 1
        for line in crypto_text.split('\n'):
            if '‚Ä¢' in line and '7j:' in line:
                parts = line.split('(')[0].replace('‚Ä¢', '').strip()
                name = parts.split(':')[0].strip() if ':' in parts else parts
                seven_days_positive = '7j: +' in line or ('7j:' in line and '+' in line.split('7j:')[1][:10])
                allowed_crypto.append({
                    "id": f"CR_{crypto_id}",
                    "name": name,
                    "symbol": name.upper()[:3],
                    "sevenDaysPositif": seven_days_positive,
                    "score": 0.0,
                    "risk_class": "mid",
                    "ytd": 0.0,
                    "perf_1m": 0.0
                })
                crypto_id += 1
                if crypto_id > 10:
                    break

    return {
        "allowed_equities": allowed_equities,
        "allowed_etfs_standard": allowed_etfs_standard,
        "allowed_bond_etfs": allowed_bond_etfs,
        "allowed_crypto": allowed_crypto,
        "allowed_cash": [  # üëà ajout√© aussi en fallback pour homog√©n√©it√©
            {"id": "CASH", "name": "Cash (placeholder)", "score": 0.0, "risk_class": "bond"}
        ],
    }
def extract_allowed_assets_legacy(filtered_data: Dict) -> Dict:
    """Version legacy pour compatibilit√©"""
    # Actions autoris√©es (extraire depuis filtered_lists)
    allowed_equities = []
    if filtered_data.get('lists'):
        lists_text = filtered_data['lists']
        equity_id = 1
        for line in lists_text.split('\n'):
            if '‚Ä¢' in line and 'YTD' in line:
                parts = line.split(':')
                if len(parts) >= 2:
                    name = parts[0].replace('‚Ä¢', '').strip()
                    name = re.sub(r'[üö©üìâ]', '', name).strip()
                    if '(' in name and 'potentielle' in name:
                        name = name.split('(')[0].strip()
                    
                    region = "US" if any(x in name for x in ["Inc", "Corp", "LLC"]) else "Europe"
                    sector = "Technology"
                    
                    allowed_equities.append({
                        "id": f"EQ_{equity_id}",
                        "name": name,
                        "symbol": name.split()[0] if len(name.split()) > 0 else name[:4].upper(),
                        "region": region,
                        "sector": sector,
                        "score": 0.0,
                        "risk_class": "mid",
                        "flags": {"overextended": False},
                        "ytd": 0.0,
                        "perf_1m": 0.0
                    })
                    equity_id += 1
                    if equity_id > 30:
                        break
    
    # ETF standards autoris√©s
    allowed_etfs_standard = []
    if filtered_data.get('etfs'):
        etfs_text = filtered_data['etfs']
        etf_id = 1
        for line in etfs_text.split('\n'):
            if '‚Ä¢' in line and 'ETF' in line and 'OBLIGATAIRE' not in line.upper():
                etf_name = line.split('‚Ä¢')[1].split(':')[0].strip() if '‚Ä¢' in line else ""
                if etf_name and len(etf_name) > 5:
                    allowed_etfs_standard.append({
                        "id": f"ETF_s{etf_id}",
                        "name": etf_name,
                        "symbol": etf_name.split()[0][:4].upper() if etf_name.split() else "ETF",
                        "score": 0.0,
                        "risk_class": "mid",
                        "flags": {"overextended": False},
                        "ytd": 0.0,
                        "perf_1m": 0.0
                    })
                    etf_id += 1
                    if etf_id > 20:
                        break
    
    # ETF obligataires autoris√©s
    allowed_bond_etfs = []
    if filtered_data.get('bond_etf_names'):
        for i, name in enumerate(filtered_data['bond_etf_names'][:15]):
            allowed_bond_etfs.append({
                "id": f"ETF_b{i+1}",
                "name": name,
                "symbol": name.split()[0][:4].upper() if name.split() else "BOND",
                "score": 0.0,
                "risk_class": "bond",
                "flags": {"overextended": False},
                "ytd": 0.0,
                "perf_1m": 0.0
            })
    
    # Cryptos autoris√©es
    allowed_crypto = []
    if filtered_data.get('crypto'):
        crypto_text = filtered_data['crypto']
        crypto_id = 1
        for line in crypto_text.split('\n'):
            if '‚Ä¢' in line and '7j:' in line:
                parts = line.split('(')[0].replace('‚Ä¢', '').strip()
                name = parts.split(':')[0].strip() if ':' in parts else parts
                
                seven_days_positive = '7j: +' in line or ('7j:' in line and '+' in line.split('7j:')[1][:10])
                
                allowed_crypto.append({
                    "id": f"CR_{crypto_id}",
                    "name": name,
                    "symbol": name.upper()[:3],
                    "sevenDaysPositif": seven_days_positive,
                    "score": 0.0,
                    "risk_class": "mid",
                    "ytd": 0.0,
                    "perf_1m": 0.0
                })
                crypto_id += 1
                if crypto_id > 10:
                    break
    
    return {
        "allowed_equities": allowed_equities,
        "allowed_etfs_standard": allowed_etfs_standard,
        "allowed_bond_etfs": allowed_bond_etfs,
        "allowed_crypto": allowed_crypto
    }

def build_robust_prompt_v3(structured_data: Dict, allowed_assets: Dict, current_month: str) -> str:
    """
    Construit le prompt v3 avec univers quantitatif et garde-fous renforc√©s + COMPLIANCE AMF
    """
    
    prompt = f"""Tu es un expert en allocation quantitative. Construis TROIS portefeuilles (Agressif, Mod√©r√©, Stable).

## Donn√©es structur√©es (univers ferm√©s v3)
BRIEF_POINTS = {json.dumps(structured_data['brief_points'], ensure_ascii=False)}
MARKETS = {json.dumps(structured_data['market_points'], ensure_ascii=False)}
SECTORS = {json.dumps(structured_data['sector_points'], ensure_ascii=False)}
THEMES = {json.dumps(structured_data['theme_points'], ensure_ascii=False)}

ALLOWED_EQUITIES = {json.dumps(allowed_assets['allowed_equities'], ensure_ascii=False)}
ALLOWED_ETFS_STANDARD = {json.dumps(allowed_assets['allowed_etfs_standard'], ensure_ascii=False)}
ALLOWED_BOND_ETFS = {json.dumps(allowed_assets['allowed_bond_etfs'], ensure_ascii=False)}
ALLOWED_CRYPTO = {json.dumps(allowed_assets['allowed_crypto'], ensure_ascii=False)}

## R√®gles ABSOLUES v3 (scoring quantitatif)
- Choisir uniquement des actifs dont l'`id` figure dans les listes ALLOWED_*.
- 3 portefeuilles : chacun **12 √† 15** lignes (somme Actions+ETF+Obligations+Crypto).
- **‚â•2 cat√©gories** par portefeuille (parmi: Actions, ETF, Obligations, Crypto).
- **Somme des allocations = 100.00** avec **2 d√©cimales**. La **derni√®re ligne** ajuste pour atteindre 100.00.
- Cat√©gorie **Obligations** = ALLOWED_BOND_ETFS exclusivement. Interdit ailleurs.
- Cat√©gorie **ETF** = uniquement ALLOWED_ETFS_STANDARD (aucun bond ETF ici).
- Cat√©gorie **Crypto** = actifs de ALLOWED_CRYPTO avec `sevenDaysPositif=true`.
- Un m√™me `id` ne peut appara√Ætre qu'**une fois** par portefeuille.
- Diversification anti-doublon (ETF) :
  - √âviter deux ETF offrant la m√™me exposition (m√™me th√®me/indice/m√©tal).
  - **Au plus 1 ETF par th√®me fortement corr√©l√©** (gold, S&P 500, Nasdaq 100, World, Treasuries, etc.).
  - Interdit si overlap th√©matique ‚â• 0.6 ou overlap de holdings ‚â• 0.5.
  - **Profil Mod√©r√© : somme des lignes `Crypto` ‚â§ 5.00%** (si aucun actif crypto √©ligible, mettre 0%).
- Sp√©cifique au profil Stable :
  - **Aucune ligne Crypto (0%)**.

## R√®gles de scoring quantitatif (NOUVELLES)
- N'utiliser que les actifs avec `flags.overextended=false`.
- **‚â•70% des lignes** d'un portefeuille doivent avoir `score ‚â• 0`.
- La **m√©diane des scores par portefeuille ‚â• 0**.
- Interdit: ETF √† effet de levier (d√©j√† exclus en amont).
- **Anti-fin-de-cycle**: Interdiction d'ajouter un actif avec `YTD>100%` si `Perf 1M ‚â§ 0`.
- Privil√©gier √©quilibrage `risk_class` : mix low/mid selon profil (Stable=80% low, Mod√©r√©=60% low, Agressif=40% low).

## Style de justification (obligatoire, par ligne)
- Commencer par: **"Pond√©ration {{allocation_pct:.2f}}% ‚Äî"**
- Expliquer la logique: **march√©** (MARKETS), **secteur** (SECTORS), **th√®me** (THEMES) et/ou **brief macro** (BRIEF), en reliant explicitement l‚Äôexposition vis√©e (ex: "large cap US", "or physique", "obligations souveraines euro 3‚Äì5 ans").
- Mentionner **le score** et **la classe de risque**: "Score {{score:+.2f}}, risque {{risk_class}}"
- Terminer par **R√©fs** avec des IDs (ex: `R√©fs: [BR2,"MC1","SEC3"]`).
- Ton neutre et descriptif (pas d‚Äôincitation). Exemple court:
  "Pond√©ration 7.50% ‚Äî exposition th√©orique au S&P 500, port√©e par momentum US large cap et th√©matique IA diffuse; Score +0.82, risque mid. R√©fs: [BR1, MC2, TH1]."

## COMPLIANCE (obligatoire)
- Ce contenu est une **information financi√®re g√©n√©rale**. Il **ne constitue pas** un conseil en investissement personnalis√© ni une recommandation individuelle.
- N'utilise **aucune** donn√©e personnelle, ne d√©duis **aucun** profil de l'utilisateur et **n'adapte** pas les portefeuilles au lecteur. Reste **strictement g√©n√©rique**.
- **Langage neutre uniquement** : interdit d'employer ¬´ acheter ¬ª, ¬´ vendre ¬ª, ¬´ conserver ¬ª, ¬´ √† privil√©gier ¬ª, ¬´ fortement recommand√© ¬ª, ¬´ garanti ¬ª, ¬´ sans risque ¬ª, ¬´ objectif de prix ¬ª, ¬´ rendement attendu ¬ª. Utiliser des formulations comme ¬´ pond√©ration mod√®le ¬ª, ¬´ exposition th√©orique ¬ª, ¬´ sc√©narios possibles ¬ª.
- **Aucune incitation** √† passer un ordre, **aucun lien affili√©**, **aucune promesse** de performance.
- **Toujours** ajouter dans la sortie un bloc `Compliance` avec :
  - `Disclaimer` : texte court (2‚Äì3 phrases) rappelant que c'est de l'information g√©n√©rale, que les performances pass√©es ne pr√©jugent pas des performances futures, et qu'il existe un risque de perte en capital.
  - `Risques` : 3‚Äì6 puces, incluant au minimum : ¬´ Perte en capital possible ¬ª, ¬´ Performances pass√©es ‚â† performances futures ¬ª, ¬´ Volatilit√© des march√©s ¬ª, et pour la cat√©gorie Crypto : ¬´ Forte volatilit√©, possibilit√© de perte totale ¬ª.
  - `Methodologie` : 1‚Äì2 phrases sur l'approche quantitative (scoring momentum/risque/liquidit√©) et ses limites (incertitudes, donn√©es susceptibles d'√©voluer).
- Les commentaires/justifications doivent rester **descriptifs** (pas d'imp√©ratifs, pas d'injonctions).

## Logique d'investissement (synth√®se)
- Chaque actif doit √™tre justifi√© par **‚â•2 r√©f√©rences** parmi BRIEF(Macro), MARKETS(G√©o), SECTORS(Secteur), THEMES(Th√®mes).
  Utilise les **IDs** (ex: ["BR2","MC1"]).
- Ne **jamais** choisir sur la seule base de la perf YTD ou du score.
- Mentionne bri√®vement le score et la classe de risque dans la justification.
- Pr√©f√©rer les actifs avec score > 0 et diversification sectorielle/g√©ographique.

## Commentaires attendus (par portefeuille)
- `Commentaire` (‚â§1200 caract√®res), structure:
  1) Actualit√©s (BRIEF) ‚Äî 2‚Äì3 phrases neutres
  2) March√©s (MARKETS) ‚Äî 2‚Äì3 phrases
  3) Secteurs (SECTORS/THEMES) ‚Äî 2‚Äì3 phrases
  4) Approche quantitative ‚Äî 2‚Äì3 phrases sur l'√©quilibrage score/risque

## Actifs exclus
- Fournis 2‚Äì3 `ActifsExclus` avec `reason` courte et `refs` (IDs) expliquant l'exclusion.
- Priorit√© aux actifs sur-√©tendus ou √† score tr√®s n√©gatif.

## Format de SORTIE (STRICT, JSON UNIQUEMENT, pas de markdown, aucun texte hors JSON)
{{
  "Agressif": {{
    "Commentaire": "...",
    "Lignes": [
      {{"id":"EQ_1",   "name":"Microsoft Corporation", "category":"Actions",     "allocation_pct":12.50, "justificationRefs":["BR1","SEC2"], "justification":"Score 1.23 (momentum tech) + r√©silience IA face ralentissement", "score":1.23, "risk_class":"low"}},
      {{"id":"ETF_s1", "name":"Vanguard S&P 500 ETF",  "category":"ETF",         "allocation_pct":25.00, "justificationRefs":["MC1","TH1"],  "justification":"Score 0.87 + exposition th√©orique large march√© US", "score":0.87, "risk_class":"mid"}},
      {{"id":"ETF_b1", "name":"iShares Euro Govt Bond", "category":"Obligations", "allocation_pct":15.00, "justificationRefs":["BR3","SEC4"], "justification":"Pond√©ration refuge g√©opolitique", "score":0.12, "risk_class":"bond"}},
      {{"id":"CR_1",   "name":"Bitcoin",               "category":"Crypto",      "allocation_pct":5.00,  "justificationRefs":["TH3","MC2"],  "justification":"Score 2.15 + exposition institutionnelle", "score":2.15, "risk_class":"mid"}}
    ],
    "ActifsExclus": [
      {{"name":"Tesla Inc", "reason":"Score -0.85 + sur-extension YTD >150%", "refs":["BR1","SEC1"]}},
      {{"name":"ARKK ETF", "reason":"Score -1.23 + exposition correction s√©v√®re", "refs":["BR2"]}}
    ],
    "Compliance": {{
      "Disclaimer": "Communication d'information financi√®re √† caract√®re g√©n√©ral. Ce contenu n'est pas un conseil en investissement personnalis√©. Les performances pass√©es ne pr√©jugent pas des performances futures. Investir comporte un risque de perte en capital. Aucune ex√©cution ni transmission d'ordres n'est fournie.",
      "Risques": [
        "Perte en capital possible",
        "Performances pass√©es ne pr√©jugent pas des performances futures",
        "Volatilit√© accrue selon les classes d'actifs",
        "Crypto-actifs : volatilit√© √©lev√©e, perte totale possible",
        "Risques de change pour les actifs internationaux",
        "Risque de liquidit√© sur certains march√©s"
      ],
      "Methodologie": "Allocation issue d'un scoring quantitatif (momentum, volatilit√©, drawdown, liquidit√©). Les donn√©es et le classement peuvent √©voluer. Cette approche ne garantit aucun r√©sultat."
    }}
  }},
  "Mod√©r√©": {{ "Commentaire": "...", "Lignes": [...], "ActifsExclus": [...], "Compliance": {{...}} }},
  "Stable": {{ "Commentaire": "...", "Lignes": [...], "ActifsExclus": [...], "Compliance": {{...}} }}
}}

### CONTR√îLE QUALIT√â v3 (obligatoire avant d'√©mettre la r√©ponse)
- V√©rifie que chaque portefeuille a 12‚Äì15 lignes, ‚â•2 cat√©gories, somme = 100.00 exactement (2 d√©cimales).
- V√©rifie qu'aucun `id` n'est dupliqu√© et que chaque cat√©gorie respecte ses univers autoris√©s.
- V√©rifie que ‚â•70% des actifs ont score ‚â• 0 et m√©diane des scores ‚â• 0.
- V√©rifie l'√©quilibrage risk_class selon profil.
- V√©rifie que chaque portefeuille contient le bloc `Compliance` complet.
- Si une r√®gle √©choue, corrige puis ne sors que le JSON final conforme.


Contexte temporel: Portefeuilles optimis√©s pour {current_month} 2025.
"""
    
    return prompt

def validate_portfolios_v3(portfolios: Dict, allowed_assets: Dict) -> Tuple[bool, List[str]]:
    """
    Validation stricte des portefeuilles v3 :
      - 12‚Äì15 lignes, ‚â•2 cat√©gories, somme = 100.00%
      - Bloc Compliance complet
      - Contraintes de scores & risque
      - Anti-fin-de-cycle
      - Doublons ETF (th√©matique/holdings)
      - Un seul ETF par ancre forte (sp500, nasdaq, world, gold, silver, treasury, eurozone, emerging, oil, energy)
      - R√®gles sp√©cifiques profils :
          ‚Ä¢ Stable : Crypto interdite
          ‚Ä¢ Mod√©r√© : Crypto ‚â§ 5.00%
    """
    errors = []

    # Map id -> actif (m√©tadonn√©es: score, flags, risk_class, ytd, perf_1m)
    id_to_asset = {}
    for asset_type in ["allowed_equities", "allowed_etfs_standard", "allowed_bond_etfs", "allowed_crypto"]:
        for asset in allowed_assets.get(asset_type, []):
            id_to_asset[asset["id"]] = asset

    for portfolio_name, portfolio in portfolios.items():
        if not isinstance(portfolio.get('Lignes'), list):
            errors.append(f"{portfolio_name}: 'Lignes' manquant ou invalide")
            continue

        lignes = portfolio['Lignes']

        # üîí R√®gles de profil
        if portfolio_name == "Stable":
            if any(l.get('category') == 'Crypto' for l in lignes):
                errors.append("Stable: Crypto interdite (0 ligne attendue)")

        if portfolio_name == "Mod√©r√©":
            crypto_sum = sum(float(l.get('allocation_pct', 0) or 0)
                             for l in lignes if l.get('category') == 'Crypto')
            if crypto_sum > 5.00 + 1e-6:
                errors.append(f"Mod√©r√©: crypto={crypto_sum:.2f}% (> 5.00% autoris√©s)")

        # Taille du portefeuille
        if not (12 <= len(lignes) <= 15):
            errors.append(f"{portfolio_name}: {len(lignes)} actifs (requis: 12-15)")

        # Somme des allocations
        total_allocation = sum(float(l.get('allocation_pct', 0) or 0) for l in lignes)
        if abs(total_allocation - 100.0) > 0.01:
            errors.append(f"{portfolio_name}: allocation totale = {total_allocation:.2f}% (requis: 100.00%)")

        # IDs uniques
        ids = [l.get('id') for l in lignes]
        if len(ids) != len(set(ids)):
            errors.append(f"{portfolio_name}: IDs dupliqu√©s d√©tect√©s")

        # ‚â• 2 cat√©gories
        categories = set(l.get('category') for l in lignes)
        if len(categories) < 2:
            errors.append(f"{portfolio_name}: moins de 2 cat√©gories ({categories})")

        # Bloc Compliance complet
        compliance = portfolio.get('Compliance', {})
        if not compliance:
            errors.append(f"{portfolio_name}: bloc 'Compliance' manquant")
        else:
            for field in ['Disclaimer', 'Risques', 'Methodologie']:
                if not compliance.get(field):
                    errors.append(f"{portfolio_name}: champ Compliance.{field} manquant")

        # üîí Un seul ETF par "ancre forte"
        # (sp500, nasdaq, world, gold, silver, treasury, eurozone, emerging, oil, energy)
        anchors = {"gold","sp500","nasdaq","world","treasury","eurozone","emerging","silver","oil","energy"}
        anchors_seen = set()
        for l in lignes:
            if l.get('category') in ('ETF', 'Obligations'):
                toks = _tokenize_theme(l.get('name', '') or '')
                hit = next((a for a in anchors if a in toks), None)
                if hit:
                    if hit in anchors_seen:
                        errors.append(f"{portfolio_name}: ancre ETF dupliqu√©e ({hit})")
                    anchors_seen.add(hit)

        # Contr√¥les quantitatifs & coh√©rences
        scores = []
        overextended_count = 0
        risk_distribution = defaultdict(int)

        for l in lignes:
            asset_id = l.get('id', '')
            asset = id_to_asset.get(asset_id)

            # Coh√©rence cat√©gorie ‚Üî id
            category = l.get('category')
            if category == 'Obligations' and not str(asset_id).startswith('ETF_b'):
                errors.append(f"{portfolio_name}: {asset_id} dans Obligations mais n'est pas un bond ETF")
            elif category == 'ETF' and str(asset_id).startswith('ETF_b'):
                errors.append(f"{portfolio_name}: {asset_id} est un bond ETF mais plac√© dans ETF standard")
            elif category == 'Crypto' and not str(asset_id).startswith('CR_'):
                errors.append(f"{portfolio_name}: {asset_id} dans Crypto mais n'est pas une crypto autoris√©e")
            elif category == 'Actions' and not str(asset_id).startswith('EQ_'):
                errors.append(f"{portfolio_name}: {asset_id} dans Actions mais n'est pas une action autoris√©e")

            if not asset:
                continue

            # Anti-fin-de-cycle
            ytd_val = fnum(asset.get("ytd"))
            m1_val  = fnum(asset.get("perf_1m"))
            if ytd_val > 100 and m1_val <= 0:
                errors.append(f"{portfolio_name}: {asset_id} viole 'YTD>100% & 1M‚â§0' (anti-fin-de-cycle)")

            # Scores
            score = float(asset.get('score', 0))
            scores.append(score)

            # Flags & distribution du risque
            if asset.get('flags', {}).get('overextended', False):
                overextended_count += 1

            risk_class = asset.get('risk_class', 'unknown')
            risk_distribution[risk_class] += 1

        # Ratios de score
        if scores:
            positive_score_ratio = sum(1 for s in scores if s >= 0) / len(scores)
            median_score = float(np.median(scores))
            if positive_score_ratio < 0.70:
                errors.append(f"{portfolio_name}: seulement {positive_score_ratio:.1%} d'actifs avec score ‚â• 0 (requis: ‚â•70%)")
            if median_score < 0:
                errors.append(f"{portfolio_name}: m√©diane des scores = {median_score:.2f} (requis: ‚â• 0)")

        if overextended_count > 0:
            errors.append(f"{portfolio_name}: {overextended_count} actif(s) sur-√©tendu(s) (interdit)")

        # √âquilibrage des classes de risque (hors 'bond')
        total_non_bond = sum(c for r, c in risk_distribution.items() if r != 'bond')
        if total_non_bond > 0:
            low_ratio = risk_distribution['low'] / total_non_bond
            expected_low = {"Stable": 0.80, "Mod√©r√©": 0.60, "Agressif": 0.40}.get(portfolio_name, 0.50)
            if abs(low_ratio - expected_low) > 0.20:
                errors.append(f"{portfolio_name}: {low_ratio:.1%} d'actifs low-risk (attendu: ~{expected_low:.0%})")

        # Doublons ETF (th√®mes/holdings)
        try:
            overlaps = detect_portfolio_overlaps_v3(
                portfolio, allowed_assets, etf_df=None, theme_thresh=0.6, hold_thresh=0.5
            )
            for o in overlaps:
                n1, n2, typ, sc = o["names"][0], o["names"][1], o["type"], o["score"]
                errors.append(f"{portfolio_name}: doublon ETF {n1} ‚Üî {n2} ({typ} {sc})")
        except Exception as e:
            # Utiliser logger si disponible
            try:
                logger.warning("‚ö†Ô∏è Validation overlap: %s: %s", portfolio_name, e)
            except Exception:
                print(f"‚ö†Ô∏è Validation overlap: {portfolio_name}: {e}")

    return len(errors) == 0, errors



def score_guard(portfolios: Dict, allowed_assets: Dict):
    """
    Garde-fou post-LLM sur la qualit√© des scores:
      - m√©diane des scores >= 0
      - ‚â§ 30% d'actifs score n√©gatif
    """
    id2score = {}
    for k in ("allowed_equities", "allowed_etfs_standard", "allowed_bond_etfs", "allowed_crypto"):
        for a in allowed_assets.get(k, []):
            id2score[a["id"]] = float(a.get("score", 0))

    for name, p in portfolios.items():
        sc = [id2score.get(l["id"], 0.0) for l in p.get("Lignes", [])]
        if not sc:
            continue
        med = float(np.median(sc))
        neg_ratio = sum(1 for s in sc if s < 0) / len(sc)
        if med < 0 or neg_ratio > 0.30:
            raise ValueError(f"{name}: score sant√© KO (m√©diane={med:.2f}<0) ou {neg_ratio:.0%} n√©gatifs (>30%)")

    print("‚úÖ Score guard: tous les portefeuilles passent les contr√¥les quantitatifs")
    
    # ============= HELPERS ALLOCATION (ajustement √† 100%) =============
def adjust_to_100_safe(lines, prefer_category="Obligations"):
    total = round(sum(float(l.get("allocation_pct", 0) or 0) for l in lines), 2)
    if not lines or abs(total - 100.0) <= 0.01:
        return lines
    diff = round(100.0 - total, 2)
    target = next((l for l in lines if l.get("category") == prefer_category), None)
    if not target:
        target = next((l for l in lines if l.get("category") == "Cash"), None)
    if not target:
        target = max(
            (l for l in lines if l.get("category") != "Crypto"),
            key=lambda x: float(x.get("allocation_pct", 0) or 0),
            default=lines[-1]
        )
    target["allocation_pct"] = round(float(target.get("allocation_pct", 0) or 0) + diff, 2)
    return lines


def fix_portfolios_v3(portfolios: Dict, errors: List[str], allowed_assets: Dict) -> Dict:
    """
    Corrections post-LLM :
      - Stable : supprime Crypto (r√©affecte vers Obligations sinon derni√®re ligne)
      - Mod√©r√© : cap Crypto ‚â§ 5% (r√©duit la/les lignes crypto, r√©affecte)
      - Somme = 100.00% (ajuste la derni√®re ligne)
      - Ajout Compliance si manquant
      - Remplacement des doublons d'ETF (overlaps) + 1 ETF / ancre forte
      - Purge des lignes √† 0 puis re-somme √† 100.00%
    """
    # Helpers
    def _id2asset(aid: str) -> Dict:
        for k in ("allowed_equities", "allowed_etfs_standard", "allowed_bond_etfs", "allowed_crypto"):
            for a in allowed_assets.get(k, []):
                if a["id"] == aid:
                    return a
        return {}

    def _tokens(name: str) -> set:
        return _tokenize_theme(name or "")

    # --- Corrections de base (profil + compliance + somme) ---
    for portfolio_name, portfolio in portfolios.items():
        if not isinstance(portfolio, dict):
            continue
        if 'Lignes' not in portfolio or not isinstance(portfolio['Lignes'], list):
            portfolio['Lignes'] = []
        lignes = portfolio['Lignes']

        # Stable : pas de crypto
        if portfolio_name == "Stable":
            crypto_lines = [l for l in lignes if l.get("category") == "Crypto"]
            if crypto_lines:
                freed = sum(float(l.get("allocation_pct", 0) or 0) for l in crypto_lines)
                lignes[:] = [l for l in lignes if l.get("category") != "Crypto"]
                bond_target = next((x for x in lignes if x.get("category") == "Obligations"), None)
                target = bond_target or (lignes[-1] if lignes else None)
                if target:
                    target["allocation_pct"] = round(float(target.get("allocation_pct", 0)) + freed, 2)

        # Mod√©r√© : cap crypto ‚â§ 5.00%
        if portfolio_name == "Mod√©r√©":
            crypto_lines = [l for l in lignes if l.get("category") == "Crypto"]
            crypto_sum = sum(float(l.get("allocation_pct", 0) or 0) for l in crypto_lines)
            if crypto_sum > 5.00:
                to_cut = crypto_sum - 5.00
                # r√©duire d'abord la plus grosse ligne
                for l in sorted(crypto_lines, key=lambda x: float(x.get("allocation_pct", 0) or 0), reverse=True):
                    cur = float(l.get("allocation_pct", 0) or 0)
                    take = min(cur, to_cut)
                    l["allocation_pct"] = round(cur - take, 2)
                    to_cut -= take
                    if to_cut <= 0:
                        break
                freed = round(crypto_sum - 5.00, 2)
                if freed > 0:
                    bond_target = next((x for x in lignes if x.get("category") == "Obligations"), None)
                    target = bond_target or (lignes[-1] if lignes else None)
                    if target:
                        target["allocation_pct"] = round(float(target.get("allocation_pct", 0) or 0) + freed, 2)

        # Ajout Compliance si manquant
        if 'Compliance' not in portfolio:
            portfolio['Compliance'] = get_compliance_block()

        # Ajuste somme √† 100.00 (provisoirement, on reprendra √† la fin aussi)
        total = sum(float(l.get('allocation_pct', 0) or 0) for l in lignes)
        if abs(total - 100.0) > 0.01 and lignes:
            diff = 100.0 - total
            lignes[-1]['allocation_pct'] = round(float(lignes[-1].get('allocation_pct', 0) or 0) + diff, 2)

    # --- D√©tection & correction des overlaps d'ETF + 1 ETF / ancre forte ---
    for pf_name in ["Agressif", "Mod√©r√©", "Stable"]:
        pf = portfolios.get(pf_name, {})
        if not isinstance(pf, dict) or not isinstance(pf.get("Lignes"), list):
            continue
        lignes = pf["Lignes"]

        # 1) Overlaps (th√©matique/holdings) ‚Üí tenter remplacement
        try:
            overlaps = detect_portfolio_overlaps_v3(
                pf, allowed_assets, etf_df=None, theme_thresh=0.45, hold_thresh=0.5
            )
        except Exception:
            overlaps = []

        used_ids = {l.get("id") for l in lignes}
        present_tokens = set()
        for l in lignes:
            present_tokens |= _tokens(l.get("name", ""))

        for o in overlaps:
            l1 = next((x for x in lignes if x.get("name") == o["names"][0]), None)
            l2 = next((x for x in lignes if x.get("name") == o["names"][1]), None)
            if not l1 or not l2:
                continue
            s1 = float(_id2asset(l1.get("id")).get("score", 0))
            s2 = float(_id2asset(l2.get("id")).get("score", 0))
            a_keep, a_drop = (l1, l2) if s1 >= s2 else (l2, l1)
            freed = float(a_drop.get("allocation_pct", 0) or 0)

            replacement = None
            for cand in sorted(allowed_assets.get("allowed_etfs_standard", []), key=lambda x: x.get("score", 0), reverse=True):
                if cand["id"] in used_ids:
                    continue
                t = _tokens(cand.get("name", ""))
                if t and t.isdisjoint(present_tokens):
                    replacement = cand
                    break

            if replacement:
                a_drop.update({"id": replacement["id"], "name": replacement["name"], "category": "ETF"})
                present_tokens |= _tokens(replacement["name"])
                used_ids.add(replacement["id"])
            else:
                a_drop["allocation_pct"] = 0.0
                bond_target = next((x for x in lignes if x.get("category") == "Obligations"), None)
                target = bond_target or a_keep
                target["allocation_pct"] = round(float(target.get("allocation_pct", 0)) + freed, 2)

        # 2) Dernier filet : au plus 1 ETF par ancre forte
        anchors = {"gold", "sp500", "nasdaq", "world", "treasury", "eurozone", "emerging"}
        groups = {a: [] for a in anchors}

        used_ids = {l.get("id") for l in lignes}
        present_tokens = set()
        for l in lignes:
            present_tokens |= _tokens(l.get("name", ""))

        for l in lignes:
            if l.get("category") not in ("ETF", "Obligations"):
                continue
            toks = _tokens(l.get("name", ""))
            for a in anchors:
                if a in toks:
                    groups[a].append(l)

        for a, lines in groups.items():
            if len(lines) <= 1:
                continue
            best = max(lines, key=lambda x: float(_id2asset(x.get("id")).get("score", 0)))
            for loser in (x for x in lines if x is not best):
                freed = float(loser.get("allocation_pct", 0) or 0)
                repl = None
                for cand in sorted(allowed_assets.get("allowed_etfs_standard", []), key=lambda x: x.get("score", 0), reverse=True):
                    if cand["id"] in used_ids:
                        continue
                    t = _tokens(cand.get("name", ""))
                    if a not in t and t.isdisjoint(present_tokens):
                        repl = cand
                        break
                if repl:
                    loser.update({"id": repl["id"], "name": repl["name"], "category": "ETF"})
                    used_ids.add(repl["id"])
                    present_tokens |= _tokens(repl["name"])
                else:
                    loser["allocation_pct"] = 0.0
                    best["allocation_pct"] = round(float(best.get("allocation_pct", 0)) + freed, 2)

        # Purge 0 et re-somme √† 100.00
        pf["Lignes"] = adjust_to_100_safe(pf["Lignes"], prefer_category="Obligations")

     return portfolios

  def apply_compliance_sanitization(portfolios: Dict) -> Dict:
    """Sanitise les termes marketing interdits (AMF) dans commentaires/justifications/exclusions."""
    for _, portfolio in portfolios.items():
        if not isinstance(portfolio, dict):
            continue

        if 'Commentaire' in portfolio:
            portfolio['Commentaire'] = sanitize_marketing_language(portfolio['Commentaire'])

        if 'Lignes' in portfolio and isinstance(portfolio['Lignes'], list):
            for ligne in portfolio['Lignes']:
                if isinstance(ligne, dict) and 'justification' in ligne:
                    ligne['justification'] = sanitize_marketing_language(ligne['justification'])

        if 'ActifsExclus' in portfolio and isinstance(portfolio['ActifsExclus'], list):
            for actif in portfolio['ActifsExclus']:
                if isinstance(actif, dict) and 'reason' in actif:
                    actif['reason'] = sanitize_marketing_language(actif['reason'])

    return portfolios
    # ---------- G√©n√©rateur d'explications par actif (macro/secteur/th√®me + score) ----------
def build_explanations(portfolios_obj: dict, allowed_assets: dict, structured_data: dict) -> dict:
    """
    Construit un dictionnaire d'explications par portefeuille.
    - Compatible v3 : parcourt pf["Lignes"] (id, name, category, allocation_pct, justificationRefs, justification)
    - Compatible v1 : parcourt pf["Actions"/"ETF"/"Obligations"/"Crypto"] (nom -> "12%")
      et tente de reconstituer (id, score, risk_class) depuis allowed_assets.
    """
    # --- Helpers LUT ---
    def _score_and_risk_by_id(aid: str):
        for k in ("allowed_equities", "allowed_etfs_standard", "allowed_bond_etfs", "allowed_crypto"):
            for a in allowed_assets.get(k, []) or []:
                if a.get("id") == aid:
                    return float(a.get("score", 0.0)), a.get("risk_class", "mid")
        return 0.0, "mid"

    def _find_meta_by_name(nm: str, category_hint: str):
        """Retourne (id, score, risk_class, category_norm) en cherchant par nom exact dans allowed_assets."""
        nm_low = (nm or "").strip().lower()
        pools = [
            ("Actions", "allowed_equities"),
            ("ETF", "allowed_etfs_standard"),
            ("Obligations", "allowed_bond_etfs"),
            ("Crypto", "allowed_crypto"),
        ]
        # Priorit√© √† la cat√©gorie sugg√©r√©e
        pools.sort(key=lambda t: 0 if t[0] == category_hint else 1)
        for cat, key in pools:
            for a in allowed_assets.get(key, []) or []:
                if str(a.get("name", "")).strip().lower() == nm_low:
                    return a.get("id"), float(a.get("score", 0.0)), a.get("risk_class", "mid"), cat
        # D√©faut si introuvable
        return nm, 0.0, "mid", category_hint

    # Index des points (pour g√©n√©rer des refs BR/MC/SEC/TH)
    pools_idx = {
        "BR": structured_data.get("brief_points", []) or [],
        "MC": structured_data.get("market_points", []) or [],
        "SEC": structured_data.get("sector_points", []) or [],
        "TH": structured_data.get("theme_points", []) or [],
    }

    def _pick_refs(name: str, category: str) -> list:
        nm = (name or "").lower()
        refs = []
        anchors = [
            ("uranium", "TH"), ("metals", "SEC"), ("gold", "TH"),
            ("s&p", "MC"), ("nasdaq", "MC"), ("world", "MC"),
            ("treasury", "MC"), ("euro", "MC"), ("emerging", "MC"),
            ("health", "SEC"), ("pharma", "SEC"), ("retail", "SEC"),
            ("housing", "SEC"), ("semiconductor", "SEC"),
            ("software", "SEC"), ("energy", "SEC"), ("oil", "SEC"),
            ("bank", "SEC"), ("telecom", "SEC"), ("bitcoin", "TH"),
        ]
        for kw, key in anchors:
            if kw in nm:
                cand = [p["id"] for p in pools_idx.get(key, []) if re.search(kw, p.get("text", ""), re.I)]
                if cand:
                    refs.append(cand[0])
        # Compl√©ter pour atteindre 2‚Äì4 r√©f.
        for key in ("BR", "MC", "SEC", "TH"):
            if len(refs) >= 4:
                break
            arr = pools_idx.get(key, [])
            if arr:
                refs.append(arr[0]["id"])
        # D√©doublonner et limiter
        seen, out = set(), []
        for r in refs:
            if r not in seen:
                out.append(r)
                seen.add(r)
        return out[:4]

    explanations: dict = {}
    if not isinstance(portfolios_obj, dict):
        return explanations  # garde-fou

    # D√©tecter v3 (pr√©sence de 'Lignes' dans au moins un portefeuille)
    is_v3 = any(isinstance(p, dict) and "Lignes" in p for p in portfolios_obj.values())

    for pf_name, pf in portfolios_obj.items():
        if not isinstance(pf, dict):
            continue
        lines = []

        if is_v3 and isinstance(pf.get("Lignes"), list):
            # ---- Chemin v3 ----
            for l in pf["Lignes"]:
                aid   = l.get("id") or ""
                nm    = l.get("name") or ""
                cat   = l.get("category") or ""
                alloc = float(l.get("allocation_pct", 0) or 0)
                score, risk = _score_and_risk_by_id(aid)
                refs  = l.get("justificationRefs") or _pick_refs(nm, cat)

                base_just = l.get("justification")
                if not base_just:
                    base_just = f"Pond√©ration {alloc:.2f}% ‚Äî exposition {cat.lower()} via {nm}; Score {score:+.2f}, risque {risk}. R√©fs: {refs}."

                lines.append({
                    "id": aid,
                    "name": nm,
                    "category": cat,
                    "allocation_pct": round(alloc, 2),
                    "score": round(score, 3),
                    "risk_class": risk,
                    "refs": refs,
                    "justification": sanitize_marketing_language(base_just),
                })

        else:
            # ---- Chemin v1 (dicos par cat√©gories) ----
            for cat in ("Actions", "ETF", "Obligations", "Crypto"):
                d = pf.get(cat) or {}
                if not isinstance(d, dict):
                    continue
                for nm, alloc in d.items():
                    # "12%" -> 12.0
                    try:
                        alloc_f = float(re.sub(r"[^0-9.\-]", "", str(alloc)) or 0.0)
                    except Exception:
                        alloc_f = 0.0
                    aid, score, risk, cat_norm = _find_meta_by_name(nm, cat)
                    refs = _pick_refs(nm, cat_norm)
                    base_just = f"Pond√©ration {alloc_f:.2f}% ‚Äî exposition {cat_norm.lower()} via {nm}; Score {score:+.2f}, risque {risk}. R√©fs: {refs}."
                    lines.append({
                        "id": aid,
                        "name": nm,
                        "category": cat_norm,
                        "allocation_pct": round(alloc_f, 2),
                        "score": round(score, 3),
                        "risk_class": risk,
                        "refs": refs,
                        "justification": sanitize_marketing_language(base_just),
                    })

        explanations[pf_name] = lines

    return explanations


def write_explanations_files(explanations: dict,
                             path_json: str = "data/portfolio_explanations.json",
                             path_md: str   = "data/portfolio_explanations.md") -> None:
    os.makedirs(os.path.dirname(path_json), exist_ok=True)
    with open(path_json, "w", encoding="utf-8") as f:
        json.dump(explanations, f, ensure_ascii=False, indent=2)

    md = []
    for pf, rows in explanations.items():
        md.append(f"# {pf}")
        for r in rows:
            refs_txt = ", ".join(r.get("refs", []))
            md.append(f"- **{r['name']}** ({r['category']}, {r['allocation_pct']:.2f}%): "
                      f"{r['justification']} "
                      f"(Score {r['score']:+.2f}, risque {r['risk_class']}; R√©fs: {refs_txt})")
        md.append("")
    with open(path_md, "w", encoding="utf-8") as f:
        f.write("\n".join(md))


# ============= CACHE D'UNIVERS AVEC HASH DE FICHIERS =============
_UNIVERSE_CACHE = {}

def _sha1_bytes(b: bytes) -> str:
    return hashlib.sha1(b).hexdigest()

def file_sha1(path: Path) -> str:
    try:
        with open(path, "rb") as fh:
            return _sha1_bytes(fh.read())
    except Exception:
        return "NA"

def json_sha1(obj: Any) -> str:
    try:
        blob = json.dumps(obj, sort_keys=True, ensure_ascii=False, default=str).encode("utf-8")
        return _sha1_bytes(blob)
    except Exception:
        return str(random.random())

def set_cached_universe(etf_hash: str, stocks_hash: str, crypto_hash: str, universe: Dict):
    _UNIVERSE_CACHE[(etf_hash, stocks_hash, crypto_hash)] = universe

def get_cached_universe(etf_hash: str, stocks_hash: str, crypto_hash: str):
    return _UNIVERSE_CACHE.get((etf_hash, stocks_hash, crypto_hash))


# ============= FIX 3: RETRY API ROBUSTE AVEC TIMEOUTS √âTENDUS =============

def post_with_retry(url, headers, payload, tries=5, timeout=(20, 180), backoff=2.0, jitter=0.25):
    """
    Retry robuste avec backoff exponentiel + jitter.
    - timeout: tuple (connect_timeout, read_timeout)
    - jitter: facteur al√©atoire ¬±jitter autour du d√©lai (ex: 0.25 => ¬±25%)
    """
    last_err = None
    for i in range(tries):
        try:
            return requests.post(url, headers=headers, json=payload, timeout=timeout)
        except (requests.ReadTimeout, requests.ConnectionError, requests.Timeout) as e:
            last_err = e
            base = backoff ** i
            factor = 1.0 + (random.uniform(-jitter, jitter) if jitter else 0.0)
            wait = max(0.05, base * factor)  # √©vite un sleep trop court ou n√©gatif
            logger.warning("‚ö†Ô∏è API retry %s/%s dans %.2fs: %s", i + 1, tries, wait, e)
            time.sleep(wait)
    raise last_err

# ============= FIX 4: FILET DE S√âCURIT√â CACHE =============

def load_cached_portfolios(path="data/portefeuilles.json"):
    """Charge le dernier portefeuille valid√© en cache"""
    try:
        with open(path, "r", encoding="utf-8") as f:
            return json.load(f)
    except Exception:
        return None

def generate_portfolios_v3(filtered_data: Dict) -> Dict:
    """
    Version 3 am√©lior√©e avec syst√®me de scoring quantitatif + COMPLIANCE AMF
    """
    api_key = os.environ.get('API_CHAT')
    if not api_key:
        raise ValueError("La cl√© API OpenAI (API_CHAT) n'est pas d√©finie.")

    current_month = get_current_month_fr()

    # V√©rifier si on a un univers quantitatif
    if not filtered_data.get('universe'):
        print("‚ö†Ô∏è Pas d'univers quantitatif d√©tect√©, g√©n√©ration en mode legacy")
        return generate_portfolios_legacy(filtered_data)

    # Pr√©parer les donn√©es structur√©es
    print("üîÑ Pr√©paration des donn√©es structur√©es v3...")
    structured_data = prepare_structured_data(filtered_data)
    allowed_assets = extract_allowed_assets(filtered_data)

    universe = filtered_data['universe']
    print(f"  üìä Brief: {len(structured_data['brief_points'])} points")
    print(f"  üìà March√©s: {len(structured_data['market_points'])} points")
    print(f"  üè≠ Secteurs: {len(structured_data['sector_points'])} points")
    print(f"  üîç Th√®mes: {len(structured_data['theme_points'])} points")
    print(f"  üíº Actions autoris√©es: {len(allowed_assets['allowed_equities'])}")
    print(f"  üìä ETF standards: {len(allowed_assets['allowed_etfs_standard'])}")
    print(f"  üìâ ETF obligataires: {len(allowed_assets['allowed_bond_etfs'])}")
    print(f"  ü™ô Cryptos autoris√©es: {len(allowed_assets['allowed_crypto'])}")

    # Construire le prompt robuste v3 avec compliance AMF
    prompt = build_robust_prompt_v3(structured_data, allowed_assets, current_month)

    # Horodatage pour les fichiers de debug
    debug_timestamp = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')

    # Sauvegarder le prompt pour debug
    print("üîç Sauvegarde du prompt v3 pour debug...")
    debug_file, html_file = save_prompt_to_debug_file(prompt, debug_timestamp)
    print(f"‚úÖ Prompt v3 sauvegard√© dans {debug_file}")

    # ===================== Appel API (Responses API, JSON strict + seed + temperature 0) =====================
    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json",
    }

    data = {
        "model": "gpt-4.1-mini",
        "input": [
            {
                "role": "user",
                "content": [
                    {"type": "text", "text": prompt}
                ]
            }
        ],
        "temperature": 0,
        "seed": 42,
        "response_format": {
            "type": "json_schema",
            "json_schema": {
                "name": "three_portfolios",
                "strict": True,  # emp√™che tout texte hors JSON / strings mal √©chapp√©es
                "schema": {
                    "type": "object",
                    "required": ["Agressif", "Mod√©r√©", "Stable"],
                    "properties": {
                        "Agressif": {"$ref": "#/$defs/Portfolio"},
                        "Mod√©r√©": {"$ref": "#/$defs/Portfolio"},
                        "Stable": {"$ref": "#/$defs/Portfolio"}
                    },
                    "$defs": {
                        "Line": {
                            "type": "object",
                            "required": [
                                "id", "name", "category", "allocation_pct",
                                "justification", "justificationRefs", "score", "risk_class"
                            ],
                            "properties": {
                                "id": {"type": "string"},
                                "name": {"type": "string", "minLength": 1},
                                "category": {
                                    "type": "string",
                                    "enum": ["Actions", "ETF", "Obligations", "Crypto", "Cash"]
                                },
                                "allocation_pct": {
                                    "type": "number",
                                    "minimum": 0,
                                    "maximum": 100,
                                    "multipleOf": 0.01
                                },
                                "justification": {"type": "string", "maxLength": 280},
                                "justificationRefs": {
                                    "type": "array",
                                    "items": {"type": "string"},
                                    "minItems": 1,
                                    "maxItems": 4
                                },
                                "score": {"type": "number"},
                                "risk_class": {"type": "string", "enum": ["low", "mid", "bond"]}
                            },
                            "additionalProperties": False
                        },
                        "Portfolio": {
                            "type": "object",
                            "required": ["Commentaire", "Lignes", "ActifsExclus", "Compliance"],
                            "properties": {
                                "Commentaire": {"type": "string", "maxLength": 1200},
                                "Lignes": {
                                    "type": "array",
                                    "items": {"$ref": "#/$defs/Line"},
                                    "minItems": 12,
                                    "maxItems": 15
                                },
                                "ActifsExclus": {
                                    "type": "array",
                                    "items": {
                                        "type": "object",
                                        "required": ["name", "reason", "refs"],
                                        "properties": {
                                            "name": {"type": "string"},
                                            "reason": {"type": "string", "maxLength": 160},
                                            "refs": {
                                                "type": "array",
                                                "items": {"type": "string"},
                                                "minItems": 1,
                                                "maxItems": 3
                                            }
                                        },
                                        "additionalProperties": False
                                    },
                                    "maxItems": 5
                                },
                                "Compliance": {
                                    "type": "object",
                                    "required": ["Disclaimer", "Risques", "Methodologie"],
                                    "properties": {
                                        "Disclaimer": {"type": "string", "maxLength": 300},
                                        "Risques": {
                                            "type": "array",
                                            "items": {"type": "string"},
                                            "minItems": 3,
                                            "maxItems": 6
                                        },
                                        "Methodologie": {"type": "string", "maxLength": 240}
                                    },
                                    "additionalProperties": False
                                }
                            },
                            "additionalProperties": False
                        }
                    },
                    "additionalProperties": False
                }
            }
        },
        "max_output_tokens": 1800
    }

    print("üöÄ Envoi de la requ√™te √† l'API OpenAI (prompt v2 fallback)...")
    response = post_with_retry(
        "https://api.openai.com/v1/responses",
        headers,
        data,
        tries=5,
        timeout=(20, 180),
    )
    response.raise_for_status()

    result = response.json()

    # ---- R√©cup contenu (Responses API) ----
    # 1) raccourci s'il est pr√©sent
    content = result.get("output_text")
    if not content:
        # 2) parcours canonique
        try:
            content = result["output"][0]["content"][0]["text"]
        except Exception:
            # 3) dernier filet : quelques variantes observ√©es
            msg = (result.get("response") or {}).get("output", [])
            if msg and "content" in msg[0] and msg[0]["content"]:
                content = msg[0]["content"][0].get("text")

    if content is None:
        raise ValueError("R√©ponse vide du mod√®le (output_text/content introuvable)")

    # Sauvegarder la r√©ponse brute pour debug
    response_debug_file = f"debug/prompts/response_v3_{debug_timestamp}.txt"
    os.makedirs("debug/prompts", exist_ok=True)
    with open(response_debug_file, "w", encoding="utf-8") as f:
        f.write(content if isinstance(content, str) else json.dumps(content, ensure_ascii=False, indent=2))
    print(f"‚úÖ R√©ponse v3 sauvegard√©e dans {response_debug_file}")

    # Structured Outputs: le mod√®le peut renvoyer un objet dict directement
    if isinstance(content, dict):
        portfolios = content
    else:
        if not isinstance(content, str) or not content.strip():
            raise ValueError("R√©ponse vide du mod√®le (content string)")
        portfolios = parse_json_strict_or_repair(content)

        # ---------- post-traitements communs (toujours ex√©cut√©s) ----------
        # Sanity check minimal
        expected = {"Agressif", "Mod√©r√©", "Stable"}
        if not isinstance(portfolios, dict) or not expected.issubset(portfolios.keys()):
            raise ValueError("R√©ponse v3 invalide/partielle ‚Äî pas de portefeuilles utilisables")
        if any(not isinstance(portfolios[k], dict) for k in expected):
            raise ValueError("R√©ponse v3 invalide ‚Äî mauvais format (cl√© non-dict)")
        if all(len(portfolios[k].get("Lignes", [])) == 0 for k in expected):
            raise ValueError("R√©ponse v3 vide ‚Äî aucune 'Lignes' fournie")

        # Attacher compliance + sanitisation
        portfolios = attach_compliance(portfolios)
        print("üõ°Ô∏è Application de la sanitisation compliance AMF...")
        portfolios = apply_compliance_sanitization(portfolios)

        # Validation & auto-fix
        validation_ok, errors = validate_portfolios_v3(portfolios, allowed_assets)
        if not validation_ok:
            print(f"‚ö†Ô∏è Erreurs de validation v3 d√©tect√©es: {errors}")
            portfolios = fix_portfolios_v3(portfolios, errors, allowed_assets)
            validation_ok, remaining_errors = validate_portfolios_v3(portfolios, allowed_assets)
            if not validation_ok:
                print(f"‚ö†Ô∏è Erreurs restantes apr√®s correction: {remaining_errors}")

        # Rapport overlaps (diagnostic)
        try:
            overlap_report = build_overlap_report(
                portfolios,
                allowed_assets,
                etf_csv_path="data/combined_etfs.csv",
            )
            for k, v in overlap_report.items():
                if v:
                    sample = v[0]
                    print(
                        f"üîé Overlap {k}: {len(v)} paire(s) suspecte(s) ‚Äî "
                        f"ex: {sample['names'][0]} ‚Üî {sample['names'][1]} "
                        f"({sample['type']} {sample['score']})"
                    )
                else:
                    print(f"üîé Overlap {k}: RAS")
        except Exception as e:
            print(f"‚ö†Ô∏è Overlap: erreur durant l'analyse ({e})")

        # Contr√¥le final des scores
        try:
            score_guard(portfolios, allowed_assets)
        except ValueError as e:
            logger.error("‚ùå Score guard failed: %s", e, exc_info=True)

        logger.info("‚úÖ Portefeuilles v3 g√©n√©r√©s avec succ√®s (scoring quantitatif + compliance AMF)")

        # R√©cap console (facultatif)
        for portfolio_name, portfolio in portfolios.items():
            if isinstance(portfolio, dict) and 'Lignes' in portfolio:
                lignes = portfolio['Lignes']
                total_alloc = sum(ligne.get('allocation_pct', 0) for ligne in lignes)
                categories = set(ligne.get('category') for ligne in lignes)

                # Stats scores
                scores = []
                risk_counts = defaultdict(int)
                for ligne in lignes:
                    asset_id = ligne.get('id', '')
                    for asset_type in ["allowed_equities", "allowed_etfs_standard", "allowed_bond_etfs", "allowed_crypto"]:
                        for asset in allowed_assets.get(asset_type, []):
                            if asset["id"] == asset_id:
                                scores.append(asset.get('score', 0))
                                risk_counts[asset.get('risk_class', 'unknown')] += 1
                                break

                avg_score = np.mean(scores) if scores else 0
                median_score = np.median(scores) if scores else 0
                compliance_ok = bool(portfolio.get('Compliance'))

                print(f"  üìä {portfolio_name}: {len(lignes)} actifs, {len(categories)} cat√©gories, {total_alloc:.2f}%")
                print(f"     Score moyen: {avg_score:.2f}, m√©diane: {median_score:.2f}")
                print(f"     R√©partition risque: {dict(risk_counts)}")
                print(f"     Compliance AMF: {'‚úÖ' if compliance_ok else '‚ùå'}")

    return portfolios



    # === NORMALISATION V3 -> SCH√âMA FRONT HISTORIQUE (Agressif/Mod√©r√©/Stable) ===
def _infer_category_from_id(asset_id: str) -> str:
    if str(asset_id).startswith("EQ_"):    return "Actions"
    if str(asset_id).startswith("ETF_b"):  return "Obligations"
    if str(asset_id).startswith("ETF_s"):  return "ETF"
    if str(asset_id).startswith("CR_"):    return "Crypto"
    return "Autres"

def _build_asset_lookup(allowed_assets: dict) -> dict:
    # id -> {name, category}
    lut = {}
    for k, cat in [("allowed_equities","Actions"),
                   ("allowed_etfs_standard","ETF"),
                   ("allowed_bond_etfs","Obligations"),
                   ("allowed_crypto","Crypto")]:
        for a in allowed_assets.get(k, []):
            lut[a["id"]] = {"name": a.get("name", a["id"]), "category": cat}
    return lut

def _pct(v) -> str:
    try: return f"{round(float(v))}%"
    except: return f"{v}%"

def normalize_v3_to_frontend_v1(raw_obj: dict, allowed_assets: dict) -> dict:
    """Convertit le format v3 (avec 'Lignes') vers le format v1 attendu par le front."""
    lut = _build_asset_lookup(allowed_assets)
    out: dict = {}

    def _put(pf_key: str, category: str, name: str, alloc):
        # structure du portefeuille
        out.setdefault(pf_key, {
            "Commentaire": "",
            "Actions": {}, "ETF": {}, "Obligations": {}, "Crypto": {}
        })
        # cat inconnue -> ETF
        if category not in ("Actions", "ETF", "Obligations", "Crypto"):
            category = "ETF"
        out[pf_key][category][name] = _pct(alloc)

    def _sum_pct_dict(d: dict) -> float:
        tot = 0.0
        if isinstance(d, dict):
            for v in d.values():
                try:
                    tot += float(re.sub(r'[^0-9.\-]', '', str(v)))
                except Exception:
                    pass
        return round(tot)

    def _ensure_comment(pf_key: str, base_text: str = ""):
        base = sanitize_marketing_language((base_text or "").strip())
        if base:
            out[pf_key]["Commentaire"] = base
            return
        a = _sum_pct_dict(out[pf_key].get("Actions"))
        e = _sum_pct_dict(out[pf_key].get("ETF"))
        b = _sum_pct_dict(out[pf_key].get("Obligations"))
        c = _sum_pct_dict(out[pf_key].get("Crypto"))
        out[pf_key]["Commentaire"] = sanitize_marketing_language(
            f"Portefeuille mod√®le {pf_key.lower()} : ‚âà{a}% Actions, ‚âà{e}% ETF, "
            f"‚âà{b}% Obligations, ‚âà{c}% Crypto. R√©partition indicative, non prescriptive. "
            "Information g√©n√©rale ; performances pass√©es non indicatives des performances futures."
        )

    # --- 1) Cl√©s directes: Agressif / Mod√©r√© / Stable ---
    for portfolio_name in ["Agressif", "Mod√©r√©", "Stable"]:
        pf = raw_obj.get(portfolio_name)
        if not isinstance(pf, dict):
            continue

        base_comment = pf.get("Commentaire") or pf.get("Description") or ""

        out.setdefault(portfolio_name, {
            "Commentaire": "",
            "Actions": {}, "ETF": {}, "Obligations": {}, "Crypto": {}
        })

        # Cas v2 : cat√©gories d√©j√† pr√©sentes
        if any(k in pf for k in ("Actions", "ETF", "Obligations", "Crypto")):
            out[portfolio_name]["Actions"] = pf.get("Actions", {}) or {}
            out[portfolio_name]["ETF"] = pf.get("ETF", {}) or {}
            out[portfolio_name]["Obligations"] = pf.get("Obligations", {}) or {}
            out[portfolio_name]["Crypto"] = pf.get("Crypto", {}) or {}
            _ensure_comment(portfolio_name, base_comment)
            continue

        # Cas v3 : format 'Lignes'
        for ligne in pf.get("Lignes", []) or []:
            asset_id = ligne.get("id") or ligne.get("ID") or ""
            alloc = ligne.get("allocation_pct") or ligne.get("allocation") or 0
            if asset_id in lut:
                name = lut[asset_id]["name"]
                category = lut[asset_id]["category"]
            else:
                name = ligne.get("name", asset_id)
                category = _infer_category_from_id(asset_id)
            _put(portfolio_name, category, name, alloc)

        _ensure_comment(portfolio_name, base_comment)

    # --- 2) Format "Portefeuilles" (archives non standard) ---
    if not out and isinstance(raw_obj, dict):
        pfs = raw_obj.get("Portefeuilles") or raw_obj.get("portefeuilles") or []

        def canon(nom: str) -> str:
            s = (nom or "").lower()
            if "agress" in s: return "Agressif"
            if "mod" in s or "√©quili" in s or "equili" in s: return "Mod√©r√©"
            return "Stable"

        for pf in pfs:
            pf_key = canon(pf.get("Nom") or pf.get("name"))
            base_comment = pf.get("Commentaire") or pf.get("Description") or ""

            out.setdefault(pf_key, {
                "Commentaire": "",
                "Actions": {}, "ETF": {}, "Obligations": {}, "Crypto": {}
            })

            for it in pf.get("Actifs", []) or []:
                asset_id = it.get("id") or it.get("ID") or ""
                alloc = it.get("allocation") or it.get("allocation_pct") or 0
                if asset_id in lut:
                    name = lut[asset_id]["name"]
                    category = lut[asset_id]["category"]
                else:
                    name = it.get("name") or it.get("Nom") or asset_id
                    category = _infer_category_from_id(asset_id)
                _put(pf_key, category, name, alloc)

            _ensure_comment(pf_key, base_comment)

    return out


# === V1: validation & auto-fix de la somme 100% ===
def _to_float_pct(v):
    s = re.sub(r'[^0-9.\-\.]', '', str(v) if v is not None else '')
    try:
        return float(s) if s else 0.0
    except:
        return 0.0

def _fmt_int_pct(x):
    # v1 = entiers avec "%" (ex: "12%")
    try:
        v = max(0.0, min(100.0, float(x)))
        return f"{int(round(v))}%"
    except:
        return f"{x}%"

def validate_and_fix_v1_sum(portfolios_v1: dict, fix: bool = True):
    """
    V√©rifie que chaque portefeuille (Agressif/Mod√©r√©/Stable) en format v1
    a une somme d'allocations = 100%. Si fix=True, ajuste la DERNI√àRE ligne rencontr√©e.
    Retourne: (ok: bool, erreurs: [str], v1_fixed: dict)
    """
    errors = []
    fixed = _copy.deepcopy(portfolios_v1)

    for pf_name in ["Agressif", "Mod√©r√©", "Stable"]:
        pf = fixed.get(pf_name, {})
        if not isinstance(pf, dict):
            continue

        total = 0.0
        last_key = None  # (cat, nom_actif)

        for cat in ["Actions", "ETF", "Obligations", "Crypto"]:
            d = pf.get(cat, {})
            if not isinstance(d, dict):
                continue
            for name, val in d.items():
                total += _to_float_pct(val)
                last_key = (cat, name)

        if round(total) != 100:
            if fix and last_key:
                diff = 100.0 - total
                cat, name = last_key
                cur = _to_float_pct(fixed[pf_name][cat][name])
                newv = max(0.0, min(100.0, cur + diff))  # borne prudente
                fixed[pf_name][cat][name] = _fmt_int_pct(newv)
            else:
                errors.append(f"{pf_name}: somme={total:.2f}% (‚â† 100%)")

    return (len(errors) == 0), errors, fixed

# === Module Overlap / Doublons ===
# D√©tection de paires d‚ÄôETF potentiellement redondantes (m√™mes th√®mes ou m√™mes principaux holdings).

_THEMATIC_STOPWORDS = {
    "ishares","xtrackers","invesco","lyxor","spdr","vanguard","amundi","hsbc",
    "ucits","etf","acc","dist","eur","usd","gbp","inc","cap","accumulating",
    "distributing","hedged","unhedged","physically","replicating","swap","1c","1d","2d",
     "shares","share","trust","physical","core","ftse","all","fund","index","class","ucits"
}

_THEMATIC_SYNONYMS = {
    "or":"gold","gold":"gold","xau":"gold",
    "metaux":"metals","m√©taux":"metals","precious":"metals","precieux":"metals","pr√©cieux":"metals",
    "miners":"miners","mineurs":"miners","miniers":"miners","mines":"miners",
    "sp500":"sp500","s&p":"sp500","s&p500":"sp500","sandp":"sp500",
    "nasdaq":"nasdaq","nasdaq100":"nasdaq",
    "world":"world","global":"world","acwi":"world","allworld":"world",
    "msci":"msci",
    "eurozone":"eurozone","euro":"eurozone",
    "gov":"treasury","sovereign":"treasury","treasury":"treasury",
    "oil":"oil","energy":"energy","bitcoin":"bitcoin","silver":"silver"
}

# ---------- Shims (s√©curise l'ex√©cution si tes helpers ne sont pas d√©j√† import√©s) ----------
try:
    _build_asset_lookup  # type: ignore[name-defined]
except NameError:  # pragma: no cover
    def _build_asset_lookup(allowed_assets: dict) -> dict:
        """Fallback minimal : mappe id -> {name, category} depuis allowed_assets."""
        lut = {}
        mapping = [
            ("allowed_equities", "Actions"),
            ("allowed_etfs_standard", "ETF"),
            ("allowed_bond_etfs", "Obligations"),
            ("allowed_crypto", "Crypto"),
        ]
        for key, cat in mapping:
            for a in allowed_assets.get(key, []) or []:
                lut[a["id"]] = {"name": a.get("name", a["id"]), "category": cat}
        return lut

try:
    _infer_category_from_id  # type: ignore[name-defined]
except NameError:  # pragma: no cover
    def _infer_category_from_id(asset_id: str) -> str:
        """Fallback minimal : inf√®re la cat√©gorie depuis le pr√©fixe de l'ID."""
        s = str(asset_id)
        if s.startswith("EQ_"): return "Actions"
        if s.startswith("ETF_b"): return "Obligations"
        if s.startswith("ETF_s"): return "ETF"
        if s.startswith("CR_"): return "Crypto"
        return "ETF"

# ---------- Tokenisation th√©matique ----------
def _tokenize_theme(name: str) -> set:
    """
    Tokenisation grossi√®re du nom d‚ÄôETF pour comparer les th√®mes :
      - enl√®ve stopwords & mots tr√®s courts
      - normalise via _THEMATIC_SYNONYMS
      - ajoute ancres fortes (sp500 / gold) si rep√©r√©es
    """
    low = (name or "").lower()
    toks = set()

    # mots alphanum√©riques
    for w in re.findall(r"[a-z0-9&]+", low):
        if len(w) <= 2 or w in _THEMATIC_STOPWORDS:
            continue
        toks.add(_THEMATIC_SYNONYMS.get(w, w))

    # ancres fortes fr√©quemment √©crites d'une autre mani√®re
    if "s&p" in low or "s&p 500" in low:
        toks.add("sp500")
    # ‚Äúor‚Äù (FR) comme mot entier, sans confondre avec ‚Äúworld‚Äù
    if re.search(r"\bor\b", low) or "gold" in low:
        toks.add("gold")

    # pr√©cision utile pour dissocier bullion vs. miners
    if re.search(r"\bminers?\b|\bmineurs?\b|\bminiers?\b|\bmines?\b", low):
        toks.add("miners")

    return toks
def enforce_one_per_anchor_v1(portfolios_v1: dict,
                              anchors: set = {"gold","sp500","nasdaq","world","treasury","eurozone","emerging","silver","oil","energy"}):
    def tok(name: str) -> set:
        return _tokenize_theme(name or "")

    fixed = _copy.deepcopy(portfolios_v1)

    for pf_name in ["Agressif","Mod√©r√©","Stable"]:
        pf = fixed.get(pf_name, {})
        if not isinstance(pf, dict):
            continue

        # üîí Stable: aucune crypto
        if pf_name == "Stable":
            pf["Crypto"] = {}

        etf_dict = pf.get("ETF", {}) or {}
        if etf_dict:
            seen = set()
            keep = {}
            surplus_pct = 0.0

            # garde le 1er ETF par ancre; accumule l‚Äôallocation des doublons
            for etf_name, alloc in etf_dict.items():
                toks = tok(etf_name)
                hit = next((a for a in anchors if a in toks), None)
                if hit:
                    if hit in seen:
                        surplus_pct += _to_float_pct(alloc)
                        continue
                    seen.add(hit)
                keep[etf_name] = alloc

            # redistribute : privil√©gie Obligations si pr√©sent, sinon la derni√®re ligne ETF
            pf["ETF"] = keep
            if surplus_pct > 0:
                target = None
                if pf.get("Obligations"):
                    last_bond = next(reversed(pf["Obligations"]))
                    target = ("Obligations", last_bond)
                elif pf.get("ETF"):
                    last_etf = next(reversed(pf["ETF"]))
                    target = ("ETF", last_etf)

                if target:
                    cat, name = target
                    cur = _to_float_pct(pf[cat][name])
                    pf[cat][name] = _fmt_int_pct(cur + surplus_pct)

        fixed[pf_name] = pf

    # somme = 100% s√ªre
    _, _, fixed = validate_and_fix_v1_sum(fixed, fix=True)
    return fixed
# ---------- Index des holdings ETF ----------
def _build_etf_holdings_index(etf_df: Optional[pd.DataFrame]) -> dict:
    """
    Construit un index :
        { etf_name: { 'holdings': set(tickers), 'tokens': set(...) } }
    Reconnait des colonnes contenant 'holding' / 'constituent' si pr√©sentes.
    """
    idx: dict = {}
    if etf_df is None or etf_df.empty:
        return idx

    name_col = next(
        (c for c in ["name", "long_name", "etf_name", "symbol", "ticker"] if c in etf_df.columns),
        None
    )
    if not name_col:
        return idx

    hold_cols = [c for c in etf_df.columns if re.search(r"(holding|constituent)", c, re.I)]

    for _, r in etf_df.iterrows():
        name = str(r.get(name_col) or "").strip()
        if not name:
            continue

        holdings: set = set()
        for c in hold_cols:
            val = r.get(c)
            if pd.isna(val):
                continue
            s = str(val).strip()
            if not s:
                continue

            # JSON-like (["AAPL","MSFT",...]) OU simple CSV de tickers
            if s.startswith("["):
                try:
                    arr = json.loads(s)
                    for t in arr:
                        if isinstance(t, str):
                            holdings.add(re.sub(r"[^A-Z0-9]", "", t.upper())[:8])
                except Exception:
                    pass
            else:
                for t in re.findall(r"[A-Z]{2,6}", s.upper()):
                    holdings.add(t)

        idx[name] = {
            "holdings": holdings,
            "tokens": _tokenize_theme(name),
        }

    return idx

# ---------- Score de recouvrement pour une paire d'ETF ----------
def _pair_overlap_score(
    n1: str,
    n2: str,
    idx: dict,
    theme_thresh: float = 0.6,
    hold_thresh: float = 0.5
) -> Tuple[Optional[str], float]:
    """
    Calcule un score d‚Äôoverlap pour n1/n2 :
      1) si 2 listes de holdings ‚Üí Jaccard holdings
      2) sinon ancres fortes (gold/sp500/nasdaq/world/treasury/‚Ä¶) √† ~1.0
      3) sinon Jaccard sur tokens th√©matiques
    Retourne (type_overlap, score) ou (None, 0.0)
    """
    # 1) Overlap via holdings (si dispo)
    h1 = idx.get(n1, {}).get("holdings") or set()
    h2 = idx.get(n2, {}).get("holdings") or set()
    if h1 and h2:
        jac = len(h1 & h2) / max(1, len(h1 | h2))
        if jac >= hold_thresh:
            return ("holdings_overlap", round(jac, 3))

    # 2) Tokens th√©matiques (avec ancres fortes)
    t1 = idx.get(n1, {}).get("tokens") or _tokenize_theme(n1)
    t2 = idx.get(n2, {}).get("tokens") or _tokenize_theme(n2)

    STRONG = {"gold", "sp500", "nasdaq", "world", "treasury", "eurozone", "emerging", "bitcoin", "silver", "oil", "energy"}
    common_anchor = next((a for a in STRONG if a in t1 and a in t2), None)
    if common_anchor:
        # Exception : ne pas confondre ‚Äúgold miners‚Äù avec ‚Äúgold bullion‚Äù
        if not (common_anchor == "gold" and (("miners" in t1) ^ ("miners" in t2))):
            typ = "thematic_gold_overlap" if common_anchor == "gold" else "thematic_overlap"
            return (typ, 0.99)

    # 3) Jaccard sur tokens th√©matiques
    jac_t = len(t1 & t2) / max(1, len(t1 | t2))
    if jac_t >= theme_thresh:
        typ = "thematic_gold_overlap" if ("gold" in t1 and "gold" in t2) else "thematic_overlap"
        return (typ, round(jac_t, 3))

    return (None, 0.0)

# ---------- D√©tection des doublons dans un portefeuille ----------
def detect_portfolio_overlaps_v3(
    portfolio: dict,
    allowed_assets: dict,
    etf_df: Optional[pd.DataFrame] = None,
    theme_thresh: float = 0.6,
    hold_thresh: float = 0.5
) -> List[dict]:
    """
    Inspecte un portefeuille v3 ('Lignes') et renvoie une liste de paires d‚ÄôETF potentiellement en doublon.
    Inclut les ETF obligataires (cat√©gorie 'Obligations') pour rep√©rer les clusters th√©matiques (ex: plusieurs gold ETFs).
    """
    lut = _build_asset_lookup(allowed_assets)

    etf_names: List[str] = []
    for l in portfolio.get("Lignes", []) or []:
        aid = l.get("id", "")
        meta = lut.get(aid, {"name": l.get("name", ""), "category": _infer_category_from_id(aid)})
        if meta.get("category") in ("ETF", "Obligations"):
            if meta.get("name"):
                etf_names.append(str(meta["name"]))

    if len(etf_names) < 2:
        return []

    idx = _build_etf_holdings_index(etf_df) if etf_df is not None else {}
    out: List[dict] = []
    for i in range(len(etf_names)):
        for j in range(i + 1, len(etf_names)):
            typ, sc = _pair_overlap_score(etf_names[i], etf_names[j], idx, theme_thresh, hold_thresh)
            if typ:
                out.append({"names": [etf_names[i], etf_names[j]], "type": typ, "score": sc})
    return out

# ---------- Rapport multi-portefeuilles ----------
def build_overlap_report(
    portfolios_v3: dict,
    allowed_assets: dict,
    etf_csv_path: str = "data/combined_etfs.csv",
    theme_thresh: float = 0.6,
    hold_thresh: float = 0.5
) -> Dict[str, List[dict]]:
    """
    Applique la d√©tection d‚Äôoverlap aux 3 portefeuilles et retourne un dict :
      { "Agressif": [...], "Mod√©r√©": [...], "Stable": [...] }
    """
    etf_df: Optional[pd.DataFrame] = None
    try:
        p = Path(etf_csv_path)
        if p.exists():
            etf_df = pd.read_csv(p)
    except Exception as e:
        logger.warning("‚ö†Ô∏è Overlap: impossible de lire %s (%s)", etf_csv_path, e)

    report: Dict[str, List[dict]] = {}
    for name in ("Agressif", "Mod√©r√©", "Stable"):
        pf = portfolios_v3.get(name, {}) or {}
        report[name] = detect_portfolio_overlaps_v3(
            pf, allowed_assets, etf_df=etf_df, theme_thresh=theme_thresh, hold_thresh=hold_thresh
        )
    return report

# ---------- Bonus : d√©duplication pr√©-g√©n√©ration par ancres ----------
def dedupe_by_anchors(
    items: List[dict],
    anchors: set = {"gold", "sp500", "nasdaq", "world", "treasury", "eurozone", "emerging", "silver", "oil", "energy"}
) -> List[dict]:
    """
    Garde au plus 1 ETF par grande ancre th√©matique (gold/sp500/‚Ä¶).
    Trie d‚Äôabord par score d√©croissant, puis filtre.
      items: liste d‚Äôobjets de allowed_assets (ex: allowed_etfs_standard)
    """
    seen, out = set(), []
    for it in sorted(items or [], key=lambda x: x.get("score", 0), reverse=True):
        toks = _tokenize_theme(it.get("name", ""))
        hit = next((a for a in anchors if a in toks), None)
        if hit and hit in seen:
            continue
        if hit:
            seen.add(hit)
        out.append(it)
    return out

def update_history_index_from_normalized(normalized_json: dict, history_file: str, version: str):
    """Met √† jour l'index avec les donn√©es normalis√©es"""
    try:
        index_file = 'data/portfolio_history/index.json'
        index_data = []
        if os.path.exists(index_file):
            try:
                with open(index_file,'r',encoding='utf-8') as f:
                    index_data = json.load(f)
            except json.JSONDecodeError:
                index_data = []

        entry = {
            "file": os.path.basename(history_file),
            "version": version,
            "timestamp": datetime.datetime.now().strftime('%Y%m%d_%H%M%S'),
            "date": datetime.datetime.now().isoformat(),
            "summary": {}
        }
        
        for pf_name, pf in normalized_json.items():
            if isinstance(pf, dict):
                entry["summary"][pf_name] = {
                    "Actions": f"{len(pf.get('Actions',{}))} actifs",
                    "ETF": f"{len(pf.get('ETF',{}))} actifs",
                    "Obligations": f"{len(pf.get('Obligations',{}))} actifs",
                    "Crypto": f"{len(pf.get('Crypto',{}))} actifs",
                }
        
        index_data.insert(0, entry)
        index_data = index_data[:100]
        
        with open(index_file,'w',encoding='utf-8') as f:
            json.dump(index_data, f, ensure_ascii=False, indent=4)
    except Exception as e:
        print(f"‚ö†Ô∏è Avertissement: index non mis √† jour ({e})")

def save_portfolios_normalized(portfolios_v3: dict, allowed_assets: dict) -> None:
    """
    Sauvegarde double :
      - vue normalis√©e v1 pour le front : data/portfolios.json
      - archive v3 d√©taill√©e avec m√©tadonn√©es : data/portfolio_history/portefeuilles_v3_stable_YYYYMMDD_HHMMSS.json
      - met √† jour l'index d'historique
    """
    try:
        os.makedirs("data", exist_ok=True)
        os.makedirs("data/portfolio_history", exist_ok=True)

        # Rapport d‚Äôoverlap (diagnostic)
        overlap_report = build_overlap_report(
            portfolios_v3,
            allowed_assets,
            etf_csv_path="data/combined_etfs.csv"
        )

        # 1) Normaliser v3 -> v1
        normalized_v1 = normalize_v3_to_frontend_v1(portfolios_v3, allowed_assets)

        # 2) Filet post-g√©n√©ration : 1 ETF par ancre + pas de crypto en Stable
        normalized_v1 = enforce_one_per_anchor_v1(normalized_v1)

        # 3) Force la somme = 100%
        _, _, normalized_v1 = validate_and_fix_v1_sum(normalized_v1, fix=True)

        # 4) Fichier v1 (nom historique en anglais)
        v1_path = "data/portfolios.json"
        with open(v1_path, "w", encoding="utf-8") as f:
            json.dump(normalized_v1, f, ensure_ascii=False, indent=4)

        # 5) Archive v3 + m√©tadonn√©es
        ts = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')
        hist_path = f"data/portfolio_history/portefeuilles_v3_stable_{ts}.json"
        archive_payload = {
            "version": "v3_quantitatif_compliance_amf_stable",
            "timestamp": ts,
            "date": datetime.datetime.now().isoformat(),
            "portfolios": portfolios_v3,
            "overlap_report": overlap_report,
            "features": [
                "drawdown_normalis√©",
                "diversification_round_robin",
                "validation_anti_fin_cycle",
                "fallback_crypto_progressif",
                "cache_univers_hash",
                "retry_api_robuste",
                "compliance_amf",
                "sanitisation_marketing",
                "disclaimer_automatique",
                "regex_pandas_fixed",
                "etf_detection_fixed",
                "timeout_extended",
                "type_safety_improved",
                "cache_fallback_system"
            ]
        }
        with open(hist_path, "w", encoding="utf-8") as f:
            json.dump(archive_payload, f, ensure_ascii=False, indent=4)

        # 6) Mettre √† jour l‚Äôindex d‚Äôhistorique √† partir de la vue normalis√©e
        update_history_index_from_normalized(
            normalized_json=normalized_v1,
            history_file=hist_path,
            version="v3_quantitatif_compliance_amf_stable"
        )

        print(f"‚úÖ Sauvegarde OK ‚Üí {v1_path} (v1) + {hist_path} (archive v3)")

    except Exception as e:
        print(f"‚ùå Erreur lors de la sauvegarde normalis√©e: {e}")



# ============= FONCTIONS HELPER POUR LES NOUVEAUX FICHIERS (am√©lior√©es) =============

def build_lists_summary_from_stocks_files(stocks_paths):
    """Remplace filter_lists_data(lists_data) avec les nouveaux stocks_*.json."""
    def load_json_safe(p):
        try:
            with open(p, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            print(f"  ‚ö†Ô∏è Impossible de charger {p}: {str(e)}")
            return {}
    
    by_sector, by_country = {}, {}
    total_stocks_loaded = 0
    
    for p in stocks_paths:
        data = load_json_safe(p)
        items = data.get("stocks", [])
        print(f"  üìä {p.name}: {len(items)} stocks trouv√©es")
        total_stocks_loaded += len(items)
        
        for it in items:
            name = it.get("name") or it.get("ticker") or ""
            sector = it.get("sector") or "Non class√©"
            country = it.get("country") or "Non pr√©cis√©"
            ytd = it.get("perf_ytd") or it.get("ytd") or it.get("perf_1y") or 0
            daily = it.get("perf_1d") or it.get("change_percent") or 0
            ytd_v, daily_v = fnum(ytd), fnum(daily)
            
            # Filtre: YTD [-5,120], Daily > -10
            if -5 <= ytd_v <= 120 and daily_v > -10:
                display_name = name
                if ytd_v > 50 and daily_v < 0:
                    display_name = f"üö© {name} (potentielle sur√©valuation)"
                elif ytd_v > 10 and daily_v < -5:
                    display_name = f"üìâ {name} (forte baisse r√©cente mais secteur haussier)"
                
                row = {
                    "name": display_name,
                    "ytd": ytd_v,
                    "daily": daily_v,
                    "sector": sector,
                    "country": country,
                    "original_name": name
                }
                by_sector.setdefault(sector, []).append(row)
                by_country.setdefault(country, []).append(row)

    print(f"  ‚úÖ Total stocks charg√©es: {total_stocks_loaded}")
    print(f"  ‚úÖ Stocks filtr√©es (YTD -5% √† 120% et Daily > -10%): {sum(len(v) for v in by_sector.values())}")

    lines = ["üìã TOP 5 ACTIFS PAR SECTEUR (YTD -5% √† 120% et Daily > -10%) :"]
    total = 0
    
    for sector in sorted(by_sector.keys()):
        xs = sorted(by_sector[sector], key=lambda r: r["ytd"], reverse=True)[:5]
        if not xs: 
            continue
        lines.append(f"\nüè≠ SECTEUR: {sector.upper()} ({len(xs)} actifs)")
        for r in xs:
            country_info = f" | Pays: {r['country']}" if r['country'] != "Non pr√©cis√©" else ""
            lines.append(f"‚Ä¢ {r['name']}: YTD {r['ytd']:.2f}%, Daily {r['daily']:.2f}%{country_info}")
        total += len(xs)
    
    lines.insert(1, f"Total: {total} actifs r√©partis dans {len(by_sector)} secteurs")
    
    return "\n".join(lines) if total else "Aucune donn√©e d'actifs significative"

def load_etf_dict_from_csvs(etf_csv_path, bonds_csv_path):
    """Construit le dict attendu par filter_etf_data() √† partir des CSV."""
    etf = {"top50_etfs": [], "top_short_term_etfs": [], "top_bond_etfs": []}
    
    # Charger les ETF obligataires
    try:
        if Path(bonds_csv_path).exists():
            bdf = pd.read_csv(bonds_csv_path)
            print(f"  üìä ETF obligataires: {len(bdf)} trouv√©s")
            
            name_col = next((c for c in bdf.columns if str(c).lower() in ["name", "etf_name", "long_name", "symbol"]), None)
            ytd_col = next((c for c in bdf.columns if "ytd" in str(c).lower()), None)
            
            if name_col:
                for _, r in bdf.iterrows():
                    etf["top_bond_etfs"].append({
                        "name": str(r[name_col]),
                        "ytd": str(r[ytd_col]) if ytd_col and pd.notna(r[ytd_col]) else "N/A"
                    })
    except Exception as e:
        print(f"  ‚ö†Ô∏è Erreur lors du chargement des bonds: {str(e)}")
    
    # Charger les ETF standards
    try:
        if Path(etf_csv_path).exists():
            df = pd.read_csv(etf_csv_path)
            print(f"  üìä ETF standards: {len(df)} trouv√©s")
            
            name_col = next((c for c in df.columns if str(c).lower() in ["name", "etf_name", "long_name", "symbol"]), None)
            ytd_col = next((c for c in df.columns if "ytd" in str(c).lower()), None)
            dur_col = next((c for c in df.columns if "duration" in str(c).lower()), None)
            
            if name_col:
                if ytd_col:
                    df_sorted = df.sort_values(ytd_col, ascending=False)
                else:
                    df_sorted = df
                    
                for _, r in df_sorted.head(50).iterrows():
                    etf["top50_etfs"].append({
                        "name": str(r[name_col]),
                        "ytd": str(r[ytd_col]) if ytd_col and pd.notna(r[ytd_col]) else "N/A"
                    })
                
                # ETF court terme
                if dur_col and dur_col in df.columns:
                    short = df[df[dur_col] <= 1.0]
                else:
                    pattern = r"short\s*term|ultra\s*short|0[-‚Äì]1|1[-‚Äì]3\s*year"
                    short = df[df[name_col].astype(str).str.contains(pattern, case=False, regex=True, na=False)]
                
                for _, r in short.head(20).iterrows():
                    etf["top_short_term_etfs"].append({
                        "name": str(r[name_col]),
                        "oneMonth": "N/A"
                    })
    except Exception as e:
        print(f"  ‚ö†Ô∏è Erreur lors du chargement des ETF: {str(e)}")
    
    return etf

def load_crypto_dict_from_csv(csv_path):
    """Construit une structure minimale compatible filter_crypto_data()."""
    out = {"categories": {"main": []}}
    
    try:
        if Path(csv_path).exists():
            df = pd.read_csv(csv_path)
            print(f"  ü™ô Cryptos: {len(df)} trouv√©es dans le CSV")
        else:
            print(f"  ‚ö†Ô∏è Fichier crypto non trouv√©: {csv_path}")
            return out
    except Exception as e:
        print(f"  ‚ö†Ô∏è Erreur lors du chargement des cryptos: {str(e)}")
        return out
    
    # Mapper les colonnes
    cols = {c.lower(): c for c in df.columns}
    c_sym = next((cols[x] for x in cols if x in ["symbol", "pair"]), None)
    c_r1 = next((cols[x] for x in cols if x in ["ret_1d_pct", "ret_1d", "ret_1d%", "perf_1d"]), None)
    c_r7 = next((cols[x] for x in cols if x in ["ret_7d_pct", "ret_7d", "ret_7d%", "perf_7d"]), None)
    c_pr = next((cols[x] for x in cols if "last_close" in x or "price" in x), None)
    c_tier = next((cols[x] for x in cols if "tier1" in x), None)
    
    def as_bool(v):
        return str(v).lower() in ["true", "1", "yes"]
    
    cryptos_added = 0
    for _, r in df.iterrows():
        # Filtrer par tier si la colonne existe
        if c_tier and not as_bool(r[c_tier]):
            continue
            
        name = str(r[c_sym]) if c_sym else ""
        out["categories"]["main"].append({
            "name": name,
            "symbol": name,
            "price": str(r[c_pr]) if c_pr and pd.notna(r[c_pr]) else "",
            "change_24h": f"{r[c_r1]}%" if c_r1 and pd.notna(r[c_r1]) else "0%",
            "change_7d": f"{r[c_r7]}%" if c_r7 and pd.notna(r[c_r7]) else "0%",
        })
        cryptos_added += 1
    
    print(f"  ‚úÖ Cryptos ajout√©es au dict: {cryptos_added}")
    return out

# ============= FONCTIONS ORIGINALES (gard√©es intactes) =============

def get_current_month_fr():
    """Retourne le nom du mois courant en fran√ßais."""
    try:
        locale.setlocale(locale.LC_TIME, 'fr_FR.UTF-8')
    except locale.Error:
        month_names = {
            1: "janvier", 2: "f√©vrier", 3: "mars", 4: "avril",
            5: "mai", 6: "juin", 7: "juillet", 8: "ao√ªt",
            9: "septembre", 10: "octobre", 11: "novembre", 12: "d√©cembre"
        }
        return month_names[datetime.datetime.now().month]
    
    return datetime.datetime.now().strftime('%B').lower()

def filter_news_data(news_data):
    """Filtre les donn√©es d'actualit√©s pour n'inclure que les plus pertinentes."""
    if not news_data or not isinstance(news_data, dict):
        return "Aucune donn√©e d'actualit√© disponible"
    
    filtered_news = []
    
    for region, news_list in news_data.items():
        if not isinstance(news_list, list):
            continue
            
        important_news = []
        for news in news_list[:5]:
            if not isinstance(news, dict):
                continue
                
            important_news.append({
                "title": news.get("title", ""),
                "impact": news.get("impact", ""),
                "category": news.get("category", ""),
                "date": news.get("date", "")
            })
        
        if important_news:
            filtered_news.append(f"R√©gion {region}: " + 
                               ", ".join([f"{n['title']} ({n['impact']})" for n in important_news]))
    
    return "\n".join(filtered_news) if filtered_news else "Aucune donn√©e d'actualit√© pertinente"

def filter_markets_data(markets_data):
    """Filtre les donn√©es de march√© pour inclure les indices cl√©s et les top performers."""
    if not markets_data or not isinstance(markets_data, dict):
        return "Aucune donn√©e de march√© disponible"
    
    lines = []
    
    # R√©sum√© par r√©gion ‚Äì indices globaux
    indices_data = markets_data.get("indices", {})
    for region, indices in indices_data.items():
        if not isinstance(indices, list):
            continue
        
        lines.append(f"üìà {region}")
        for idx in indices[:5]:
            name = idx.get("index_name", "")
            var = idx.get("change", "")
            ytd = idx.get("ytdChange", "")
            if name and var:
                lines.append(f"‚Ä¢ {name}: {var} | YTD: {ytd}")
    
    # Traitement des Top Performers
    if "top_performers" in markets_data and isinstance(markets_data["top_performers"], dict):
        if "daily" in markets_data["top_performers"]:
            daily = markets_data["top_performers"]["daily"]
            
            if "best" in daily and isinstance(daily["best"], list) and daily["best"]:
                lines.append("üèÜ Top Hausses (variation quotidienne):")
                for item in daily["best"][:3]:
                    if isinstance(item, dict):
                        name = item.get("index_name", "")
                        change = item.get("change", "")
                        country = item.get("country", "")
                        if name and country:
                            lines.append(f"‚Ä¢ {name} ({country}): {change}")
            
            if "worst" in daily and isinstance(daily["worst"], list) and daily["worst"]:
                lines.append("üìâ Top Baisses (variation quotidienne):")
                for item in daily["worst"][:3]:
                    if isinstance(item, dict):
                        name = item.get("index_name", "")
                        change = item.get("change", "")
                        country = item.get("country", "")
                        if name and country:
                            lines.append(f"‚Ä¢ {name} ({country}): {change}")
    
    return "\n".join(lines) if lines else "Aucune donn√©e de march√© significative"

def filter_sectors_data(sectors_data):
    """Filtre les donn√©es sectorielles pour montrer les meilleures et pires variations par r√©gion."""
    if not sectors_data or not isinstance(sectors_data, dict):
        return "Aucune donn√©e sectorielle disponible"
    
    summary = []
    sectors = sectors_data.get("sectors", {})
    
    for region, sector_list in sectors.items():
        if not isinstance(sector_list, list):
            continue
        
        try:
            sector_list_sorted = sorted(
                sector_list, 
                key=lambda x: float(str(x.get("ytd", "0")).replace('%','').replace(',', '.')), 
                reverse=True
            )
        except (ValueError, TypeError):
            sector_list_sorted = sector_list
        
        summary.append(f"üè≠ {region}")
        for sec in sector_list_sorted[:5]:
            name = sec.get("name", "")
            var = sec.get("change", "")
            ytd = sec.get("ytd", "")
            if name and var:
                summary.append(f"‚Ä¢ {name} : {var} | YTD : {ytd}")
    
    return "\n".join(summary) if summary else "Aucune donn√©e sectorielle significative"

def filter_etf_data(etfs_data):
    """Filtre les ETF par cat√©gories."""
    if not etfs_data or not isinstance(etfs_data, dict):
        return "Aucune donn√©e ETF disponible", []
    
    summary = []
    summary.append("üìä LISTE DES ETF STANDARDS DISPONIBLES POUR LES PORTEFEUILLES:")

    # TOP ETF 2025 ‚Üí √† utiliser comme ETF standards
    top_etfs = etfs_data.get("top50_etfs", [])
    selected_top = []
    for etf in top_etfs:
        if etf.get('name'):
            selected_top.append(f"{etf['name']} : {etf.get('ytd', 'N/A')}")
    if selected_top:
        summary.append("üìä TOP ETF STANDARDS 2025:")
        summary.extend(f"‚Ä¢ {etf}" for etf in selected_top)

    # TOP ETF OBLIGATIONS 2025
    bond_etfs = etfs_data.get("top_bond_etfs", [])
    bond_names = []
    selected_bonds = []
    
    for etf in bond_etfs:
        if etf.get('name'):
            bond_names.append(etf['name'])
            selected_bonds.append(f"{etf['name']} : {etf.get('ytd', 'N/A')}")
    
    if selected_bonds:
        summary.append("üìâ LISTE DES ETF OBLIGATAIRES (√Ä UTILISER UNIQUEMENT DANS LA CAT√âGORIE OBLIGATIONS):")
        summary.extend(f"‚Ä¢ {etf}" for etf in selected_bonds)

    # ETF court terme
    short_term_etfs = etfs_data.get("top_short_term_etfs", [])
    selected_short_term = []
    for etf in short_term_etfs:
        if etf.get('name'):
            selected_short_term.append(f"{etf['name']} : {etf.get('oneMonth', 'N/A')}")
    if selected_short_term:
        summary.append("üìÜ ETF COURT TERME:")
        summary.extend(f"‚Ä¢ {etf}" for etf in selected_short_term)
    
    # Fallback si aucun ETF obligataire
    if not bond_names:
        print("‚ö†Ô∏è Aucun ETF obligataire trouv√© dans les donn√©es, ajout d'exemples de secours")
        bond_names = [
            "iShares Euro Government Bond 3-5yr UCITS ETF",
            "Xtrackers II Eurozone Government Bond UCITS ETF",
            "Lyxor Euro Government Bond UCITS ETF"
        ]
    
    return "\n".join(summary), bond_names

def filter_crypto_data(crypto_data):
    """Retourne toutes les cryptos o√π 7j > 24h > 0, ou √† d√©faut 24h > 0 et 7j > -5"""
    if not crypto_data or not isinstance(crypto_data, dict):
        return "Aucune donn√©e de crypto-monnaie disponible"
    
    print("üîç D√©bogage du filtre crypto: Analyse des donn√©es d'entr√©e")
    main = crypto_data.get('categories', {}).get('main', [])
    print(f"   Nombre de cryptos trouv√©es: {len(main)}")
    
    cryptos = []
    alt_cryptos = []

    for i, crypto in enumerate(main):
        try:
            name = crypto.get('name', '')
            symbol = crypto.get('symbol', '')
            price = crypto.get('price', '')
            
            c24h_raw = crypto.get('change_24h', '0%')
            c7d_raw = crypto.get('change_7d', '0%')
            
            c24_str = re.sub(r'[^0-9.\-]', '', str(c24h_raw))
            c7_str = re.sub(r'[^0-9.\-]', '', str(c7d_raw))
            
            c24 = float(c24_str or 0)
            c7 = float(c7_str or 0)
            
            if i < 5:
                print(f"   {name} ({symbol}) | 24h brut: {c24h_raw}, 7j brut: {c7d_raw}")
                print(f"   ‚Üí Converti: 24h = {c24}, 7j = {c7}")
            
            if c7 > c24 > 0:
                cryptos.append((name, symbol, price, c24, c7))
                if i < 5:
                    print(f"   ‚úÖ {name} PASSE le filtre ! 7j: {c7} > 24h: {c24} > 0")
            elif c24 > 0 and c7 > -5:
                alt_cryptos.append((name, symbol, price, c24, c7))
                
        except Exception as e:
            if i < 5:
                print(f"   ‚ö†Ô∏è ERREUR pour {crypto.get('name', 'inconnu')}: {str(e)}")
            continue

    # Fallback si aucun r√©sultat strict
    if not cryptos and alt_cryptos:
        print("‚ö†Ô∏è Aucune crypto ne respecte 7j > 24h > 0 ‚Üí Fallback: 24h > 0 et 7j > -5")
        cryptos = alt_cryptos
        criteria_desc = "24h > 0 ET 7j > -5%"
    elif cryptos:
        criteria_desc = "7j > 24h > 0%"
    else:
        criteria_desc = "aucun crit√®re satisfait"

    if not cryptos:
        return "Aucune crypto ne respecte les crit√®res de tendance positive stable"

    summary = [f"ü™ô CRYPTOS AVEC TENDANCE POSITIVE ({criteria_desc}) :"]
    summary.append(f"Total: {len(cryptos)} cryptos")

    for name, symbol, price, c24, c7 in cryptos:
        stability = c7/c24 if c24 != 0 else 0
        stability_txt = f"| Stabilit√©: {stability:.1f}x" if criteria_desc == "7j > 24h > 0%" else ""
        sign_24 = "+" if c24 > 0 else ""
        sign_7 = "+" if c7 > 0 else ""
        summary.append(f"‚Ä¢ {name} ({symbol}): 24h: {sign_24}{c24:.2f}%, 7j: {sign_7}{c7:.2f}% {stability_txt} | Prix: {price}")

    return "\n".join(summary)

def filter_themes_data(themes_data):
    """Filtre les donn√©es de th√®mes et tendances pour les int√©grer au prompt."""
    if not themes_data or not isinstance(themes_data, dict):
        return "Aucune donn√©e de tendances th√©matiques disponible"
    
    summary = ["üìä TENDANCES TH√âMATIQUES ACTUELLES:"]
    
    if "bullish" in themes_data and isinstance(themes_data["bullish"], list):
        summary.append("üîº TH√àMES HAUSSIERS:")
        for theme in themes_data["bullish"]:
            if isinstance(theme, dict):
                name = theme.get("name", "")
                reason = theme.get("reason", "")
                score = theme.get("score", "")
                if name:
                    summary.append(f"‚Ä¢ {name}: {reason} (Score: {score})")
    
    if "bearish" in themes_data and isinstance(themes_data["bearish"], list):
        summary.append("üîΩ TH√àMES BAISSIERS:")
        for theme in themes_data["bearish"]:
            if isinstance(theme, dict):
                name = theme.get("name", "")
                reason = theme.get("reason", "")
                score = theme.get("score", "")
                if name:
                    summary.append(f"‚Ä¢ {name}: {reason} (Score: {score})")
    
    if "emerging" in themes_data and isinstance(themes_data["emerging"], list):
        summary.append("üîÑ TH√àMES √âMERGENTS:")
        for theme in themes_data["emerging"]:
            if isinstance(theme, dict):
                name = theme.get("name", "")
                description = theme.get("description", "")
                if name:
                    summary.append(f"‚Ä¢ {name}: {description}")
    
    return "\n".join(summary)

def save_prompt_to_debug_file(prompt, timestamp=None):
    """Sauvegarde le prompt complet dans un fichier de d√©bogage."""
    debug_dir = "debug/prompts"
    os.makedirs(debug_dir, exist_ok=True)
    
    if timestamp is None:
        timestamp = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')
    
    debug_file = f"{debug_dir}/prompt_v3_{timestamp}.txt"
    
    with open(debug_file, 'w', encoding='utf-8') as f:
        f.write(prompt)
    
    # G√©n√©rer un fichier HTML plus lisible
    html_file = f"{debug_dir}/prompt_v3_{timestamp}.html"
    html_content = f"""
    <!DOCTYPE html>
    <html>
    <head>
        <title>TradePulse - Debug de Prompt v3 Quantitatif + Compliance STABLE</title>
        <meta charset="UTF-8">
        <style>
            body {{ font-family: Arial, sans-serif; margin: 20px; line-height: 1.6; }}
            pre {{ background-color: #f5f5f5; padding: 15px; border-radius: 5px; overflow-x: auto; white-space: pre-wrap; }}
            h1, h2 {{ color: #2c3e50; }}
            .info {{ background-color: #e8f4f8; padding: 10px; border-radius: 5px; margin-bottom: 20px; }}
            .highlight {{ background-color: #ffffcc; }}
            .v3-badge {{ background: linear-gradient(45deg, #6c5ce7, #a29bfe); color: white; padding: 5px 10px; border-radius: 15px; font-weight: bold; }}
            .feature {{ background: linear-gradient(45deg, #00b894, #00cec9); color: white; padding: 3px 8px; border-radius: 10px; font-size: 0.8em; margin: 0 3px; }}
            .compliance {{ background: linear-gradient(45deg, #d63031, #e84393); color: white; padding: 3px 8px; border-radius: 10px; font-size: 0.8em; margin: 0 3px; }}
            .fix {{ background: linear-gradient(45deg, #fdcb6e, #e17055); color: white; padding: 3px 8px; border-radius: 10px; font-size: 0.8em; margin: 0 3px; }}
        </style>
    </head>
    <body>
        <h1>TradePulse - Debug de Prompt v3 <span class="v3-badge">STABLE</span></h1>
        <div class="info">
            <p><strong>Version:</strong> v3 - Scoring quantitatif + Anti-hallucinations + Compliance AMF + Fixes de stabilit√©</p>
            <p><strong>Timestamp:</strong> {timestamp}</p>
            <p><strong>Taille totale du prompt:</strong> {len(prompt)} caract√®res</p>
            <p><strong>Fonctionnalit√©s:</strong> 
                <span class="feature">Score Momentum</span>
                <span class="feature">D√©tection Sur-extension</span>
                <span class="feature">Classes de Risque</span>
                <span class="feature">Filtre Anti-Levier</span>
                <span class="feature">√âquilibrage Sectoriel</span>
                <span class="feature">Retry API</span>
                <span class="feature">Cache Univers</span>
                <span class="compliance">Compliance AMF</span>
                <span class="compliance">Anti-Marketing</span>
                <span class="compliance">Disclaimer Auto</span>
                <span class="fix">Regex Fixed</span>
                <span class="fix">ETF Detection Fixed</span>
                <span class="fix">Timeout Extended</span>
                <span class="fix">Type Safety</span>
            </p>
        </div>
        <h2>Contenu du prompt v3 envoy√© √† OpenAI :</h2>
        <pre>{prompt.replace('<', '&lt;').replace('>', '&gt;')}</pre>
    </body>
    </html>
    """
    
    with open(html_file, 'w', encoding='utf-8') as f:
        f.write(html_content)

    print(f"‚úÖ Fichier HTML lisible g√©n√©r√© : {html_file}")
    
    return debug_file, html_file

def generate_portfolios(filtered_data):
    """
    FIX 4: Fonction principale de g√©n√©ration avec filet de s√©curit√© cache
    (Validation "v1" effectu√©e en lecture seule sur une vue normalis√©e)
    """
    print("üöÄ Lancement de la g√©n√©ration de portefeuilles v3 (scoring quantitatif + compliance AMF)")

    try:
        # G√©n√©ration v3
        portfolios = generate_portfolios_v3(filtered_data)

        # ‚úÖ Compatibilit√©: contr√¥le "v1" en lecture seule (pas de mutation du v3)
        try:
            allowed_assets = extract_allowed_assets(filtered_data)
            normalized_view = normalize_v3_to_frontend_v1(portfolios, allowed_assets)

            # NEW: forcer Somme=100% sur la vue v1 (lecture/affichage)
            ok100, errs100, normalized_view = validate_and_fix_v1_sum(normalized_view, fix=True)
            if not ok100 and errs100:
                print(f"‚ö†Ô∏è Somme v1 non-100%: {errs100}")

            ok, errs = check_portfolio_constraints(normalized_view)
            if not ok:
                print(f"‚ö†Ô∏è Avertissements (sch√©ma v1): {errs}")
        except Exception as e:
            print(f"‚ÑπÔ∏è Contr√¥le de compatibilit√© v1 ignor√©: {e}")

        return portfolios

    except Exception as e:
        print(f"‚ùå Erreur dans la g√©n√©ration v3: {e}\n‚ö†Ô∏è Fallback v2‚Ä¶")
        try:
            portfolios = generate_portfolios_v2(filtered_data)
            return portfolios
        except Exception as e2:
            print(f"‚ùå Erreur v2: {e2}")
            # Filet de s√©curit√© - utiliser le cache
            cached = load_cached_portfolios()
            if cached:
                print("üõü API indisponible ‚Üí on r√©utilise le dernier portefeuille en cache.")
                cached = attach_compliance(cached)
                return cached
            raise  # plus rien en r√©serve ‚Üí on laisse √©chouer

def generate_portfolios_v2(filtered_data):
    """Version v2 en fallback si v3 √©choue"""
    print("‚ö†Ô∏è Utilisation de la version v2 en fallback")
    
    api_key = os.environ.get('API_CHAT')
    if not api_key:
        raise ValueError("La cl√© API OpenAI (API_CHAT) n'est pas d√©finie.")
    
    current_month = get_current_month_fr()
    
    # Pr√©parer les donn√©es structur√©es
    structured_data = prepare_structured_data(filtered_data)
    allowed_assets = extract_allowed_assets(filtered_data)
    
    # Construire le prompt v2
    prompt = build_robust_prompt_v2(structured_data, allowed_assets, current_month)

    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json"
    }

    data = {
        "model": "gpt-4.1-mini",
        "messages": [{"role": "user", "content": prompt}],
        "temperature": 0,
        "seed": 42,
        # Forcer une sortie JSON pure (m√™me sans sch√©ma)
        "response_format": {"type": "json_object"},
        "max_tokens": 1800,
    }
    
print("üöÄ Envoi de la requ√™te √† l'API OpenAI (prompt v2 fallback)...")
    response = post_with_retry(
        "https://api.openai.com/v1/chat/completions",
        headers,
        data,
        tries=5,
        timeout=(20, 180)
    )
    response.raise_for_status()
    
    result = response.json()
    content = result["choices"][0]["message"]["content"]
    
    try:
        portfolios = json.loads(content)
    except json.JSONDecodeError as e:
        print(f"‚ùå Erreur de parsing JSON: {e}")
        content = re.sub(r'^```json', '', content)
        content = re.sub(r'```$', '', content)
        content = content.strip()
        portfolios = json.loads(content)
    
    # FIX 3: Attacher compliance de mani√®re s√ªre m√™me en fallback
    portfolios = attach_compliance(portfolios)
    portfolios = apply_compliance_sanitization(portfolios)
    
    print("‚úÖ Portefeuilles v2 g√©n√©r√©s avec succ√®s (fallback + compliance)")
    return portfolios



def build_robust_prompt_v2(structured_data: Dict, allowed_assets: Dict, current_month: str) -> str:
    """Version v2 du prompt pour fallback"""
    prompt = f"""Tu es un expert en allocation. Construis TROIS portefeuilles (Agressif, Mod√©r√©, Stable).

## Donn√©es structur√©es (univers ferm√©s)
BRIEF_POINTS = {json.dumps(structured_data['brief_points'], ensure_ascii=False)}
MARKETS = {json.dumps(structured_data['market_points'], ensure_ascii=False)}
SECTORS = {json.dumps(structured_data['sector_points'], ensure_ascii=False)}
THEMES = {json.dumps(structured_data['theme_points'], ensure_ascii=False)}

ALLOWED_EQUITIES = {json.dumps(allowed_assets['allowed_equities'], ensure_ascii=False)}
ALLOWED_ETFS_STANDARD = {json.dumps(allowed_assets['allowed_etfs_standard'], ensure_ascii=False)}
ALLOWED_BOND_ETFS = {json.dumps(allowed_assets['allowed_bond_etfs'], ensure_ascii=False)}
ALLOWED_CRYPTO = {json.dumps(allowed_assets['allowed_crypto'], ensure_ascii=False)}

## R√®gles ABSOLUES
- Choisir uniquement des actifs dont l'`id` figure dans les listes ALLOWED_*.
- 3 portefeuilles : chacun **12 √† 15** lignes (somme Actions+ETF+Obligations+Crypto).
- **‚â•2 cat√©gories** par portefeuille (parmi: Actions, ETF, Obligations, Crypto).
- **Somme des allocations = 100.00** avec **2 d√©cimales**. La **derni√®re ligne** ajuste pour atteindre 100.00.
- Inclure un bloc `Compliance` dans chaque portefeuille.
- üîí **Au plus 1 ETF par th√®me fortement corr√©l√©** (ex: gold, S&P 500, Nasdaq 100, World, Treasuries, etc.).  # ‚Üê NEW
- üîí **Stable : aucune ligne Crypto (0%)**.  # ‚Üê NEW

Format JSON strict. Contexte temporel: Portefeuilles pour {current_month} 2025.
"""
    return prompt

def generate_portfolios_legacy(filtered_data):
    """Version originale en dernier recours"""
    print("‚ö†Ô∏è Utilisation de la version legacy en dernier recours")
    
    api_key = os.environ.get('API_CHAT')
    if not api_key:
        raise ValueError("La cl√© API OpenAI (API_CHAT) n'est pas d√©finie.")
    
    current_month = get_current_month_fr()
    
    # R√©cup√©rer les donn√©es pr√©-filtr√©es du dictionnaire
    filtered_news = filtered_data.get('news', "Aucune donn√©e d'actualit√© disponible")
    filtered_markets = filtered_data.get('markets', "Aucune donn√©e de march√© disponible")
    filtered_sectors = filtered_data.get('sectors', "Aucune donn√©e sectorielle disponible")
    filtered_lists = filtered_data.get('lists', "Aucune donn√©e d'actifs disponible")
    filtered_etfs = filtered_data.get('etfs', "Aucune donn√©e ETF disponible")
    filtered_crypto = filtered_data.get('crypto', "Aucune donn√©e crypto disponible")
    filtered_themes = filtered_data.get('themes', "Aucune donn√©e de tendances disponible")
    filtered_brief = filtered_data.get('brief', "Aucun r√©sum√© disponible")
    bond_etf_names = filtered_data.get('bond_etf_names', [])
    
    bond_etf_list = "\n".join([f"- {name}" for name in bond_etf_names])
    minimum_requirements = get_portfolio_prompt_additions()
    
    prompt = f"""
Tu es un expert en gestion de portefeuille. Cr√©e TROIS portefeuilles (Agressif, Mod√©r√©, Stable) avec 12-15 actifs chacun.

üìú BRIEF STRAT√âGIQUE: {filtered_brief[:500]}...
üì∞ ACTUALIT√âS: {filtered_news[:300]}...
üìà MARCH√âS: {filtered_markets[:300]}...
üè≠ SECTEURS: {filtered_sectors[:300]}...
üìã ACTIFS: {filtered_lists[:500]}...
üìä ETF: {filtered_etfs[:300]}...
ü™ô CRYPTO: {filtered_crypto[:200]}...

ETF OBLIGATAIRES AUTORIS√âS:
{bond_etf_list}

{minimum_requirements}

Format JSON strict:
{{
  "Agressif": {{"Commentaire": "...", "Actions": {{"Nom": "X%"}}, "ETF": {{}}, "Obligations": {{}}, "Crypto": {{}}, "Compliance": {{...}}}},
  "Mod√©r√©": {{...}},
  "Stable": {{...}}
}}
"""
    
    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json"
    }
    
    data = {
       "model": "gpt-4.1-mini",
        "messages": [{"role": "user", "content": prompt}],
        "temperature": 0.3,
        "max_tokens": 1800  # FIX 3: M√™me limite pour legacy
    }
    
    response = post_with_retry("https://api.openai.com/v1/chat/completions", headers, data, tries=5, timeout=(20, 180))
    response.raise_for_status()
    
    result = response.json()
    content = result["choices"][0]["message"]["content"]
    
    content = re.sub(r'^```json', '', content)
    content = re.sub(r'```$', '', content)
    content = content.strip()
    
    portfolios = json.loads(content)
    
    # FIX 3: Attacher compliance m√™me en legacy
    portfolios = attach_compliance(portfolios)
    portfolios = apply_compliance_sanitization(portfolios)
    
    print("‚úÖ Portefeuilles legacy g√©n√©r√©s avec succ√®s")
    return portfolios

def save_portfolios(portfolios):
    """
    Wrapper r√©tro-compatibilit√© : d√©l√®gue √† save_portfolios_normalized.
    √âvite l'appel √† update_history_index() qui n'existe pas.
    """
    try:
        # on peut passer un mapping vide : la normalisation saura inf√©rer les cat√©gories via les pr√©fixes d'ID (EQ_/ETF_s/ETF_b/CR_)
        allowed_assets_stub = {
            "allowed_equities": [],
            "allowed_etfs_standard": [],
            "allowed_bond_etfs": [],
            "allowed_crypto": []
        }
        save_portfolios_normalized(portfolios, allowed_assets_stub)
    except Exception as e:
        print(f"‚ùå Erreur lors de la sauvegarde (wrapper): {e}")

def main():
    """Version modifi√©e pour utiliser le syst√®me de scoring quantitatif v3 avec compliance AMF et fixes de stabilit√©."""
    print("üîç Chargement des donn√©es financi√®res...")
    print("=" * 60)
    
    # ========== CHARGEMENT DES DONN√âES DEPUIS LES NOUVEAUX FICHIERS ==========
    
    print("\nüìÇ Chargement des fichiers JSON standards...")
    markets_data = load_json_data('data/markets.json')
    sectors_data = load_json_data('data/sectors.json')
    themes_data = load_json_data('data/themes.json')
    news_data = load_json_data('data/news.json')
    
    print("\nüìÇ Chargement des nouveaux fichiers stocks...")
    stocks_files = [
        Path('data/stocks_us.json'),
        Path('data/stocks_europe.json'),
        Path('data/stocks_asia.json')
    ]
    stocks_files_exist = [f for f in stocks_files if f.exists()]
    print(f"  Fichiers trouv√©s: {[f.name for f in stocks_files_exist]}")
    
    logger.info("üìÇ Chargement des nouveaux fichiers ETF/Bonds...")
    etf_csv = Path('data/combined_etfs.csv')
    bonds_csv = Path('data/combined_bonds.csv')
    logger.info("ETF CSV existe: %s", etf_csv.exists())
    print(f"  Bonds CSV existe: {bonds_csv.exists()}")
    
    print("\nüìÇ Chargement du nouveau fichier crypto...")
    crypto_csv = Path('data/filtered/Crypto_filtered_volatility.csv')
    print(f"  Crypto CSV existe: {crypto_csv.exists()}")
    
    print("\nüìÇ Recherche du brief strat√©gique...")
    brief_data = None
    brief_paths = ['brief_ia.json', './brief_ia.json', 'data/brief_ia.json']
    for path in brief_paths:
        try:
            with open(path, 'r', encoding='utf-8') as f:
                brief_data = json.load(f)
                print(f"  ‚úÖ Brief charg√© depuis {path}")
                break
        except Exception:
            pass
    
    if brief_data is None:
        print("  ‚ö†Ô∏è Aucun fichier brief_ia.json trouv√©")
    
    print("\n" + "=" * 60)
    
    # ========== CONSTRUCTION DE L'UNIVERS QUANTITATIF V3 AVEC CACHE ==========
    
    print("\nüßÆ Construction de l'univers quantitatif v3 (avec cache)...")
    
    # Charger les donn√©es JSON des stocks
    stocks_jsons = []
    for f in stocks_files_exist:
        stocks_jsons.append(load_json_data(str(f)))
    
    # Hash des sources pour cache
    etf_hash    = file_sha1(etf_csv) if etf_csv.exists() else "NA"
    stocks_hash = json_sha1(stocks_jsons)
    crypto_hash = file_sha1(crypto_csv) if crypto_csv.exists() else "NA"

    cached = get_cached_universe(etf_hash, stocks_hash, crypto_hash)
    if cached:
        print("üóÉÔ∏è Univers r√©cup√©r√© depuis le cache")
        universe = cached
    else:
        universe = build_scored_universe_v3(
            stocks_jsons,
            str(etf_csv),
            str(crypto_csv)
        )
        set_cached_universe(etf_hash, stocks_hash, crypto_hash, universe)
        print("üóÇÔ∏è Univers mis en cache")
    
    # ========== FILTRAGE ET PR√âPARATION DES DONN√âES ==========
    
    print("\nüîÑ Filtrage et pr√©paration des donn√©es...")
    
    # Cr√©er le r√©sum√© des stocks (pour compatibilit√© avec affichage)
    filtered_lists = build_lists_summary_from_stocks_files(stocks_files_exist)
    
    # Charger et filtrer les ETF (pour compatibilit√©)
    etfs_data = load_etf_dict_from_csvs(str(etf_csv), str(bonds_csv))
    filtered_etfs, bond_etf_names = filter_etf_data(etfs_data)
    
    # Charger et filtrer les cryptos (pour compatibilit√©)
    crypto_data = load_crypto_dict_from_csv(str(crypto_csv))
    filtered_crypto = filter_crypto_data(crypto_data)
    
    # Filtrer les autres donn√©es avec les fonctions existantes
    filtered_news = filter_news_data(news_data) if news_data else "Aucune donn√©e d'actualit√© disponible"
    filtered_markets = filter_markets_data(markets_data) if markets_data else "Aucune donn√©e de march√© disponible"
    filtered_sectors = filter_sectors_data(sectors_data) if sectors_data else "Aucune donn√©e sectorielle disponible"
    filtered_themes = filter_themes_data(themes_data) if themes_data else "Aucune donn√©e de tendances disponible"
    filtered_brief = format_brief_data(brief_data) if brief_data else "Aucun r√©sum√© d'actualit√©s disponible"
    
    # ========== G√âN√âRATION DES PORTEFEUILLES AVEC UNIVERS QUANTITATIF ==========
    
    print("\nüß† G√©n√©ration des portefeuilles optimis√©s v3 (quantitatif + compliance AMF + stabilit√©)...")
    
    # Pr√©parer le dictionnaire des donn√©es filtr√©es avec l'univers quantitatif
    filtered_data = {
        'news': filtered_news,
        'markets': filtered_markets,
        'sectors': filtered_sectors,
        'lists': filtered_lists,
        'etfs': filtered_etfs,
        'crypto': filtered_crypto,
        'themes': filtered_themes,
        'brief': filtered_brief,
        'bond_etf_names': bond_etf_names,
        'universe': universe  # <<‚Äî‚Äî NOUVEAU: Univers quantitatif
    }
    
    # G√©n√©rer les portefeuilles avec la nouvelle version quantitative v3
    portfolios = generate_portfolios(filtered_data)
    
    # ========== SAUVEGARDE ==========
    print("\nüíæ Sauvegarde des portefeuilles + g√©n√©ration des explications...")
    allowed_assets = extract_allowed_assets(filtered_data)  # mapping id -> nom/cat√©gorie
    structured_data_for_expl = prepare_structured_data(filtered_data)
    explanations = build_explanations(portfolios, allowed_assets, structured_data_for_expl)
    write_explanations_files(explanations)  # -> data/portfolio_explanations.{json,md}
    save_portfolios_normalized(portfolios, allowed_assets)

    print("\n‚ú® Traitement termin√© avec la version v3 quantitative + COMPLIANCE AMF + STABILIT√â!")
    print("üéØ Fonctionnalit√©s activ√©es:")
    print("   ‚Ä¢ Scoring quantitatif (momentum, volatilit√©, drawdown)")
    print("   ‚Ä¢ Filtrage automatique des ETF √† effet de levier")
    print("   ‚Ä¢ D√©tection des actifs sur-√©tendus")
    print("   ‚Ä¢ √âquilibrage par classes de risque")
    print("   ‚Ä¢ Diversification sectorielle round-robin (cap 30%)")
    print("   ‚Ä¢ Validation anti-fin-de-cycle (YTD>100% & 1M‚â§0)")
    print("   ‚Ä¢ Fallback crypto progressif")
    print("   ‚Ä¢ Cache intelligent d'univers (hash fichiers)")
    print("   ‚Ä¢ Retry API robuste (5 tentatives, timeouts √©tendus)")
    print("   üõ°Ô∏è COMPLIANCE AMF:")
    print("     ‚àò Langage neutre (pas d'incitation)")
    print("     ‚àò Disclaimer automatique")
    print("     ‚àò Liste des risques")
    print("     ‚àò M√©thodologie transparente")
    print("     ‚àò Sanitisation anti-marketing")
    print("   üîß FIXES DE STABILIT√â:")
    print("     ‚àò Regex pandas warning corrig√©")
    print("     ‚àò D√©tection ETF levier corrig√©e")
    print("     ‚àò Timeouts API √©tendus (20s/180s)")
    print("     ‚àò Protection de type am√©lior√©e")
    print("     ‚àò Syst√®me de fallback cache")
def load_json_data(file_path):
    """Charger des donn√©es depuis un fichier JSON."""
    try:
        with open(file_path, 'r', encoding='utf-8') as file:
            data = json.load(file)
            print(f"  ‚úÖ {file_path}: {len(data)} entr√©es")
            return data
    except Exception as e:
        print(f"  ‚ùå Erreur {file_path}: {str(e)}")
        return {}

if __name__ == "__main__":
    main()



