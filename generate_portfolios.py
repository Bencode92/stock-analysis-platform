import os
import json
import requests
import datetime
import locale
import time
import random
import re
from bs4 import BeautifulSoup
# Importer les fonctions d'ajustement des portefeuilles
from portfolio_adjuster import check_portfolio_constraints, adjust_portfolios, get_portfolio_prompt_additions, valid_etfs_cache, valid_bonds_cache

def extract_content_from_html(html_file):
    """Extraire le contenu pertinent d'un fichier HTML."""
    try:
        # Initialiser content comme une liste vide par d√©faut
        content = []
        
        with open(html_file, 'r', encoding='utf-8') as file:
            soup = BeautifulSoup(file, 'html.parser')
            
            # Extraire le contenu principal
            if html_file.endswith('actualites.html'):
                # Pour les actualit√©s, on cherche les articles de news
                articles = soup.select('.news-card, .article-item, .news-item')
                if not articles:
                    # Fallback: essayer de trouver d'autres √©l√©ments qui pourraient contenir des actualit√©s
                    articles = soup.select('article, .news, .actualite, .card')
                
                for article in articles[:15]:  # Limiter aux 15 premiers articles pour √©viter un prompt trop long
                    title = article.select_one('h2, h3, .title, .headline')
                    summary = article.select_one('p, .summary, .description')
                    
                    if title:
                        title_text = title.get_text(strip=True)
                        if title_text:
                            content.append("‚Ä¢ {}".format(title_text))
                            if summary:
                                summary_text = summary.get_text(strip=True)
                                if summary_text:
                                    content.append("  {}...".format(summary_text[:150]))  # Limiter la longueur
            
            elif html_file.endswith('marches.html'):
                # Extraction am√©lior√©e pour les march√©s - cibler les tableaux
                tables = soup.select('table, .table')
                if tables:
                    print(f"Trouv√© {len(tables)} tableaux dans {html_file}")
                    for table in tables:
                        # Extraire l'en-t√™te du tableau si pr√©sent
                        table_header = table.select_one('caption, thead, th')
                        if table_header:
                            header_text = table_header.get_text(strip=True)
                            content.append(f"üìä {header_text.upper()}:")
                        
                        # Extraire les lignes du tableau
                        rows = table.select('tr, .row')
                        for row in rows[:10]:  # Limiter √† 10 lignes
                            cells = row.select('td, th, .cell')
                            if cells:
                                row_data = " | ".join([cell.get_text(strip=True) for cell in cells if cell.get_text(strip=True)])
                                if row_data:
                                    content.append(f"‚Ä¢ {row_data}")
                
                # Si aucun tableau n'est trouv√©, essayer d'autres s√©lecteurs
                # CORRECTION: V√©rifier que le contenu n'a pas de lignes de donn√©es (avec ‚Ä¢)
                if not content or not any("‚Ä¢" in item for item in content):
                    market_data = soup.select('.market-trend, .market-data, .trend-item, .index-card, .market-item')
                    if not market_data:
                        # Fallback
                        market_data = soup.select('.card, .market, .indice, .asset-card')
                    
                    for item in market_data:
                        name = item.select_one('h3, h4, .name, .asset-name, .title')
                        value = item.select_one('.value, .price, .current-price')
                        change = item.select_one('.change, .variation, .performance')
                        
                        if name:
                            name_text = name.get_text(strip=True)
                            if name_text:
                                data_line = "‚Ä¢ {}".format(name_text)
                                if value:
                                    value_text = value.get_text(strip=True)
                                    data_line += ": {}".format(value_text)
                                if change:
                                    change_text = change.get_text(strip=True)
                                    data_line += " ({})".format(change_text)
                                content.append(data_line)
            
            elif html_file.endswith('secteurs.html'):
                # Extraction am√©lior√©e pour les secteurs - cibler les tableaux
                tables = soup.select('table, .table')
                if tables:
                    print(f"Trouv√© {len(tables)} tableaux dans {html_file}")
                    for table in tables:
                        # Extraire l'en-t√™te du tableau si pr√©sent
                        table_header = table.select_one('caption, thead, th')
                        if table_header:
                            header_text = table_header.get_text(strip=True)
                            content.append(f"üìä {header_text.upper() or 'PERFORMANCES SECTORIELLES'}:")
                        else:
                            content.append("üìä PERFORMANCES SECTORIELLES:")
                        
                        # Extraire les lignes du tableau
                        rows = table.select('tr, .row')
                        for row in rows[:15]:  # Limiter √† 15 lignes
                            cells = row.select('td, th, .cell')
                            if cells:
                                row_data = " | ".join([cell.get_text(strip=True) for cell in cells if cell.get_text(strip=True)])
                                if row_data:
                                    content.append(f"‚Ä¢ {row_data}")
                
                # CORRECTION: V√©rifier que le contenu n'a pas de lignes de donn√©es (avec ‚Ä¢)
                if not any("‚Ä¢" in item for item in content):
                    sector_data = soup.select('.sector-card, .sector-item, .performance-card')
                    if not sector_data:
                        # Fallback
                        sector_data = soup.select('.card, .sector, .industry-card, .industry-item')
                    
                    if not content:
                        content.append("üìä PERFORMANCES SECTORIELLES:")
                    
                    for item in sector_data:
                        name = item.select_one('h3, h4, .sector-name, .name, .title')
                        performance = item.select_one('.performance, .change, .variation')
                        trend = item.select_one('.trend, .direction, .recommendation')
                        
                        if name:
                            name_text = name.get_text(strip=True)
                            if name_text:
                                data_line = "‚Ä¢ {}".format(name_text)
                                if performance:
                                    perf_text = performance.get_text(strip=True)
                                    data_line += ": {}".format(perf_text)
                                if trend:
                                    trend_text = trend.get_text(strip=True)
                                    data_line += " - {}".format(trend_text)
                                content.append(data_line)
            
            elif html_file.endswith('liste.html'):
                # Extraction am√©lior√©e pour les listes - cibler les tableaux
                tables = soup.select('table, .table')
                if tables:
                    print(f"Trouv√© {len(tables)} tableaux dans {html_file}")
                    for table in tables:
                        # Extraire l'en-t√™te du tableau si pr√©sent
                        table_header = table.select_one('caption, thead, th')
                        if table_header:
                            header_text = table_header.get_text(strip=True)
                            # Utiliser des guillemets doubles pour √©viter d'√©chapper l'apostrophe
                            content.append(f"üìã {header_text.upper() or 'LISTES ACTIFS SURVEILL√âS'}:")
                        else:
                            content.append("üìã LISTES ACTIFS SURVEILL√âS:")
                        
                        # Extraire les lignes du tableau
                        rows = table.select('tr, .row')
                        for row in rows[:20]:  # Limiter √† 20 lignes
                            cells = row.select('td, th, .cell')
                            if cells:
                                row_data = " | ".join([cell.get_text(strip=True) for cell in cells if cell.get_text(strip=True)])
                                if row_data:
                                    content.append(f"‚Ä¢ {row_data}")
                
                # CORRECTION: V√©rifier que le contenu n'a pas de lignes de donn√©es (avec ‚Ä¢)
                if not any("‚Ä¢" in item for item in content):
                    asset_items = soup.select('.asset-item, .watchlist-item, .stock-item, .list-card')
                    if not asset_items:
                        # Fallback
                        asset_items = soup.select('.card, .item, tr, .asset')
                    
                    if not content:
                        content.append("üìã LISTES ACTIFS SURVEILL√âS:")
                    
                    for item in asset_items:
                        name = item.select_one('h3, h4, .asset-name, .name, .symbol, .title, td:first-child')
                        sector = item.select_one('.sector, .category, .type')
                        price = item.select_one('.price, .value, .current-price')
                        
                        if name:
                            name_text = name.get_text(strip=True)
                            if name_text:
                                data_line = "‚Ä¢ {}".format(name_text)
                                if sector:
                                    sector_text = sector.get_text(strip=True)
                                    data_line += " ({}): ".format(sector_text)
                                if price:
                                    price_text = price.get_text(strip=True)
                                    data_line += "{}".format(price_text)
                                content.append(data_line)
            
            elif html_file.endswith('etf.html'):
                # Extraction am√©lior√©e pour les ETF - cibler les tableaux
                tables = soup.select('table, .table')
                if tables:
                    print(f"Trouv√© {len(tables)} tableaux dans {html_file}")
                    for table in tables:
                        # Extraire l'en-t√™te du tableau si pr√©sent
                        table_header = table.select_one('caption, thead, th, h2, h3')
                        if table_header:
                            header_text = table_header.get_text(strip=True)
                            if "ETF" in header_text or not header_text:
                                content.append("üìä TOP ETF PERFORMANCES:")
                            else:
                                content.append(f"üìä {header_text.upper()}:")
                        else:
                            content.append("üìä ANALYSE DES ETF:")
                        
                        # Extraire les lignes du tableau
                        rows = table.select('tr, .row')
                        for row in rows[:15]:  # Limiter √† 15 lignes
                            cells = row.select('td, th, .cell')
                            if cells:
                                row_data = " | ".join([cell.get_text(strip=True) for cell in cells if cell.get_text(strip=True)])
                                if row_data:
                                    content.append(f"‚Ä¢ {row_data}")
                
                # CORRECTION: V√©rifier que le contenu n'a pas de lignes de donn√©es (avec ‚Ä¢)
                if not any("‚Ä¢" in item for item in content):
                    # Chercher d'abord des sections avec des titres mentionnant ETF
                    etf_sections = []
                    for heading in soup.select('h1, h2, h3, h4, h5, h6'):
                        if 'ETF' in heading.get_text():
                            etf_sections.append(heading.parent)
                    
                    # Si des sections sont trouv√©es, extraire leur contenu
                    if etf_sections:
                        content.append("üìä ANALYSE DES ETF:")
                        for section in etf_sections:
                            title = section.select_one('h1, h2, h3, h4, h5, h6')
                            if title:
                                content.append(f"‚Ä¢ {title.get_text(strip=True)}")
                            
                            # Extraire des √©l√©ments liste ou paragraphes
                            items = section.select('li, p')
                            for item in items[:10]:
                                content.append(f"  - {item.get_text(strip=True)}")
                    
                    # Fallback sur les s√©lecteurs originaux si aucune ligne de donn√©es trouv√©e
                    if not any("‚Ä¢" in item for item in content):
                        etf_items = soup.select('.etf-card, .etf-item, .fund-card, .etf-table tr')
                        if not etf_items:
                            # Fallback
                            etf_items = soup.select('.card, .etf, tr, .fund')
                        
                        if not content:
                            content.append("üìä ANALYSE DES ETF:")
                        
                        for item in etf_items:
                            name = item.select_one('h3, h4, .etf-name, .name, .symbol, .title, td:first-child')
                            category = item.select_one('.category, .type, .asset-class')
                            aum = item.select_one('.aum, .size, .assets')
                            expense = item.select_one('.expense, .ter, .fee')
                            
                            if name:
                                name_text = name.get_text(strip=True)
                                if name_text:
                                    data_line = "‚Ä¢ {}".format(name_text)
                                    if category:
                                        category_text = category.get_text(strip=True)
                                        data_line += " ({})".format(category_text)
                                    if aum:
                                        aum_text = aum.get_text(strip=True)
                                        data_line += " AUM: {}".format(aum_text)
                                    if expense:
                                        expense_text = expense.get_text(strip=True)
                                        data_line += ", Frais: {}".format(expense_text)
                                    content.append(data_line)
            
            # CORRECTION: Si aucun contenu sp√©cifique n'a √©t√© trouv√©, extraire le texte brut avec marqueur clair
            if not content:
                # Extraire tout le contenu textuel de la page pour avoir quelque chose
                body_text = soup.body.get_text(strip=True) if soup.body else ""
                if body_text:
                    # Limiter √† 1000 caract√®res pour √©viter un prompt trop long
                    content.append(f"[FALLBACK BRUT - {html_file}]")
                    
                    # D√©couper le texte en lignes plus courtes pour plus de lisibilit√©
                    chunks = [body_text[i:i+100] for i in range(0, min(1000, len(body_text)), 100)]
                    for chunk in chunks:
                        content.append(chunk)
                else:
                    content.append(f"[Aucun contenu trouv√© dans {html_file}]")
            
            # Ajouter une ligne de log pour d√©boguer
            print(f"‚úÖ Contenu extrait de {html_file}: {len(content)} √©l√©ments trouv√©s")
            
            return "\n".join(content)
    except Exception as e:
        print(f"‚ùå Erreur lors de l'extraction du contenu de {html_file}: {str(e)}")
        # En cas d'erreur, retourner un placeholder pour ne pas bloquer l'ex√©cution
        return f"[Contenu non disponible pour {html_file}]"

def get_current_month_fr():
    """Retourne le nom du mois courant en fran√ßais."""
    try:
        # Tenter de d√©finir la locale en fran√ßais
        locale.setlocale(locale.LC_TIME, 'fr_FR.UTF-8')
    except locale.Error:
        # Fallback si la locale fran√ßaise n'est pas disponible
        month_names = {
            1: "janvier", 2: "f√©vrier", 3: "mars", 4: "avril",
            5: "mai", 6: "juin", 7: "juillet", 8: "ao√ªt",
            9: "septembre", 10: "octobre", 11: "novembre", 12: "d√©cembre"
        }
        return month_names[datetime.datetime.now().month]
    
    # Obtenir le mois en fran√ßais
    return datetime.datetime.now().strftime('%B').lower()

def filter_news_data(news_data):
    """Filtre les donn√©es d'actualit√©s pour n'inclure que les plus pertinentes."""
    if not news_data or not isinstance(news_data, dict):
        return "Aucune donn√©e d'actualit√© disponible"
    
    # S√©lectionner uniquement les actualit√©s des derniers jours
    filtered_news = []
    
    # Parcourir les actualit√©s par r√©gion
    for region, news_list in news_data.items():
        if not isinstance(news_list, list):
            continue
            
        # Ne prendre que les 5 actualit√©s les plus importantes par r√©gion
        important_news = []
        for news in news_list[:5]:  # Limiter √† 5 actualit√©s par r√©gion
            if not isinstance(news, dict):
                continue
                
            # Ne garder que les champs essentiels
            important_news.append({
                "title": news.get("title", ""),
                "impact": news.get("impact", ""),
                "category": news.get("category", ""),
                "date": news.get("date", "")
            })
        
        # Ajouter seulement si nous avons des actualit√©s
        if important_news:
            filtered_news.append(f