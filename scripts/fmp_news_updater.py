#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
Script d'extraction des actualit√©s et √©v√©nements depuis Financial Modeling Prep
- General News API: Pour l'actualit√© √©conomique g√©n√©rale
- Stock News API: Pour les actions et ETF
- Crypto News API: Pour les cryptomonnaies
- Press Releases API: Pour les communiqu√©s de presse des entreprises
- FMP Articles API: Pour les articles r√©dig√©s par FMP
"""

import os
import json
import requests
import logging
from datetime import datetime, timedelta
import re
from collections import Counter

# Configuration du logger
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# Chemins des fichiers
NEWS_JSON_PATH = os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(__file__))), "data", "news.json")
THEMES_JSON_PATH = os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(__file__))), "data", "themes.json")

# Configuration
CONFIG = {
    "api_key": os.environ.get("FMP_API_KEY", ""),
    "endpoints": {
        "general_news": "https://financialmodelingprep.com/stable/news/general-latest",
        "fmp_articles": "https://financialmodelingprep.com/stable/fmp-articles",
        "stock_news": "https://financialmodelingprep.com/stable/news/stock-latest",
        "crypto_news": "https://financialmodelingprep.com/stable/news/crypto-latest", 
        "press_releases": "https://financialmodelingprep.com/stable/news/press-releases-latest",
        "earnings_calendar": "https://financialmodelingprep.com/api/v3/earning_calendar",
        "economic_calendar": "https://financialmodelingprep.com/api/v3/economic_calendar"
    },
    "news_limits": {
        "general_news": 15,
        "fmp_articles": 10,
        "stock_news": 15,
        "crypto_news": 10,
        "press_releases": 5
    },
    "output_limits": {
        "us": 15,
        "france": 10
    },
    "days_ahead": 7
}

# Mots-cl√©s pour le score des actualit√©s
NEWS_KEYWORDS = {
    "high_impact": [
        "crash", "collapse", "crise", "recession", "fail", "bankruptcy", "r√©cession", "banque centrale", 
        "inflation", "hike", "drop", "plunge", "default", "fitch downgrade", "downgrade", "hausse des taux", 
        "bond yield", "yield curve", "sell-off", "bear market", "effondrement", "chute", "krach",
        "d√©gringolade", "catastrophe", "urgence", "alerte", "d√©faut", "risque", "choc", "contagion",
        "panique", "d√©faillance", "correction", "faillite", "taux directeur"
    ],
    "medium_impact": [
        "growth", "expansion", "job report", "fed decision", "quarterly earnings", "acquisition", 
        "ipo", "merger", "partnership", "profit warning", "bond issuance", "croissance", "emploi", 
        "rapport", "BCE", "FED", "r√©sultats trimestriels", "fusion", "acquisition", "partenariat",
        "b√©n√©fices", "√©mission obligataire", "√©mission d'obligations", "perspectives", "avertissement",
        "rachat", "introduction en bourse", "nouveau PDG", "restructuration"
    ],
    "low_impact": [
        "recommendation", "stock buyback", "dividend", "announcement", "management change", "forecast",
        "recommandation", "rachat d'actions", "dividende", "annonce", "changement de direction", "pr√©vision",
        "nomination", "produit", "service", "strat√©gie", "march√©", "plan", "mise √† jour", "tendance"
    ]
}

# Structure des th√®mes dominants
THEMES_DOMINANTS = {
    "macroeconomie": {
        "inflation": ["inflation", "prix", "CPI", "taux d'int√©r√™t", "interest rate", "yield"],
        "recession": ["recession", "slowdown", "GDP", "PIB", "croissance", "crise"],
        "politique_monetaire": ["fed", "bce", "banque centrale", "tapering", "quantitative easing"],
        "geopolitique": ["conflit", "guerre", "tensions", "ukraine", "israel", "chine", "taiwan"],
        "transition_energetique": ["climat", "esg", "biodiversit√©", "net zero", "transition", "durable"]
    },
    "secteurs": {
        "technologie": ["ai", "cloud", "cyber", "tech", "semiconducteur", "digital", "data"],
        "energie": ["p√©trole", "gas", "uranium", "√©nergie", "baril", "oil", "renouvelable"],
        "defense": ["d√©fense", "militaire", "armes", "nato", "r√©armement"],
        "finance": ["banques", "assurances", "taux", "obligations", "treasury"],
        "immobilier": ["real estate", "immobilier", "epra", "infrastructure"],
        "consommation": ["retail", "consommation", "luxe", "achat", "revenu disponible"]
    },
    "regions": {
        "europe": ["europe", "france", "bce", "allemagne", "italie", "zone euro"],
        "usa": ["usa", "fed", "s&p", "nasdaq", "dow jones", "√©tats-unis"],
        "asie": ["chine", "japon", "cor√©e", "inde", "asie", "emerging asia"],
        "latam": ["br√©sil", "mexique", "latam", "am√©rique latine"],
        "global": ["monde", "acwi", "international", "global", "tous march√©s"]
    }
}

# Liste des sources importantes
IMPORTANT_SOURCES = [
    "Bloomberg", "Reuters", "WSJ", "FT", "CNBC", "Financial Times", "Wall Street Journal", 
    "Les √âchos", "La Tribune", "Le Figaro", "Le Monde", "Le Revenu", "BFM Business", 
    "L'AGEFI", "Investir", "Capital"
]

def read_existing_news():
    """Lit le fichier JSON existant comme fallback"""
    try:
        with open(NEWS_JSON_PATH, 'r', encoding='utf-8') as f:
            return json.load(f)
    except:
        return None

def fetch_api_data(endpoint, params=None):
    """Fonction g√©n√©rique pour r√©cup√©rer des donn√©es depuis l'API FMP"""
    if not CONFIG["api_key"]:
        logger.error("Cl√© API FMP non d√©finie. Veuillez d√©finir FMP_API_KEY dans les variables d'environnement.")
        return []
        
    if params is None:
        params = {}
    
    params["apikey"] = CONFIG["api_key"]
    
    try:
        logger.info(f"R√©cup√©ration des donn√©es depuis {endpoint}")
        response = requests.get(endpoint, params=params, timeout=30)
        response.raise_for_status()
        data = response.json()
        logger.info(f"‚úÖ {len(data)} √©l√©ments r√©cup√©r√©s depuis {endpoint}")
        return data
    except Exception as e:
        logger.error(f"‚ùå Erreur lors de la r√©cup√©ration depuis {endpoint}: {str(e)}")
        return []

def get_general_news():
    """R√©cup√®re les actualit√©s √©conomiques g√©n√©rales"""
    params = {
        "limit": CONFIG["news_limits"]["general_news"]
    }
    return fetch_api_data(CONFIG["endpoints"]["general_news"], params)

def get_fmp_articles():
    """R√©cup√®re les articles r√©dig√©s par FMP"""
    params = {
        "limit": CONFIG["news_limits"]["fmp_articles"]
    }
    return fetch_api_data(CONFIG["endpoints"]["fmp_articles"], params)

def get_stock_news():
    """R√©cup√®re les actualit√©s des actions"""
    params = {
        "limit": CONFIG["news_limits"]["stock_news"]
    }
    return fetch_api_data(CONFIG["endpoints"]["stock_news"], params)

def get_crypto_news():
    """R√©cup√®re les actualit√©s des cryptomonnaies"""
    params = {
        "limit": CONFIG["news_limits"]["crypto_news"]
    }
    return fetch_api_data(CONFIG["endpoints"]["crypto_news"], params)

def get_press_releases():
    """R√©cup√®re les communiqu√©s de presse"""
    params = {
        "limit": CONFIG["news_limits"]["press_releases"]
    }
    return fetch_api_data(CONFIG["endpoints"]["press_releases"], params)

def get_earnings_calendar():
    """R√©cup√®re le calendrier des r√©sultats d'entreprises"""
    today = datetime.now().strftime("%Y-%m-%d")
    future = (datetime.now() + timedelta(days=CONFIG["days_ahead"])).strftime("%Y-%m-%d")
    
    params = {
        "from": today,
        "to": future
    }
    return fetch_api_data(CONFIG["endpoints"]["earnings_calendar"], params)

def get_economic_calendar():
    """R√©cup√®re le calendrier √©conomique"""
    today = datetime.now().strftime("%Y-%m-%d")
    future = (datetime.now() + timedelta(days=CONFIG["days_ahead"])).strftime("%Y-%m-%d")
    
    params = {
        "from": today,
        "to": future
    }
    return fetch_api_data(CONFIG["endpoints"]["economic_calendar"], params)

def extract_themes(article):
    """Identifie les th√®mes dominants √† partir du contenu de l'article"""
    text = (article.get("text", "") + " " + article.get("title", "")).lower()
    themes_detected = {"macroeconomie": [], "secteurs": [], "regions": []}
    
    for axe, groupes in THEMES_DOMINANTS.items():
        for theme, keywords in groupes.items():
            if any(kw in text for kw in keywords):
                themes_detected[axe].append(theme)

    return themes_detected

def determine_category(article, source=None):
    """
    D√©termine la cat√©gorie de l'actualit√©:
    - economie: actualit√©s macro-√©conomiques
    - marches: actualit√©s sur les indices, ETF, etc.
    - entreprises: actualit√©s sp√©cifiques aux entreprises
    - crypto: actualit√©s cryptomonnaies
    - tech: actualit√©s technologiques
    """
    # V√©rification du symbole pour la crypto
    if article.get("symbol") and any(ticker in str(article.get("symbol")) for ticker in ["BTC", "ETH", "CRYPTO", "COIN"]):
        return "crypto"
        
    # Analyse du texte pour d√©terminer la cat√©gorie
    text = (article.get("text", "") + " " + article.get("title", "")).lower()
    
    # Cat√©gorie crypto (priorit√© 1)
    crypto_keywords = [
        "crypto", "bitcoin", "ethereum", "blockchain", "token", "defi", "nft", 
        "altcoin", "binance", "coinbase", "mining", "miner", "wallet", "staking",
        "web3", "cryptocurrency"
    ]
    
    if any(word in text for word in crypto_keywords):
        return "crypto"
    
    # Cat√©gorie tech (priorit√© 2)
    tech_keywords = [
        "ai", "artificial intelligence", "machine learning", "data science", 
        "software", "hardware", "tech", "technology", "startup", "app", 
        "mobile", "cloud", "computing", "digital", "internet", "online", "web"
    ]
    
    if any(word in text for word in tech_keywords):
        return "tech"
    
    # Cat√©gorie √©conomie (priorit√© 3)
    economie_keywords = [
        "economy", "√©conomie", "inflation", "gdp", "pib", "fed", "central bank",
        "banque centrale", "interest rate", "taux d'int√©r√™t", "economic", "unemployment",
        "consumer", "spending", "policy", "fiscal", "monetary", "recession"
    ]
    
    if any(word in text for word in economie_keywords):
        return "economie"
    
    # Cat√©gorie march√©s (priorit√© 4)
    marches_keywords = [
        "etf", "fund", "fonds", "index", "indice", "s&p", "dow", "cac", "nasdaq", 
        "bond", "treasury", "yield", "mati√®res premi√®res", "commodities", "oil", 
        "gold", "p√©trole", "or", "market", "stock market", "bull market", 
        "bear market", "rally", "correction", "volatility", "vix"
    ]
    
    if any(word in text for word in marches_keywords):
        return "marches"
    
    # Par d√©faut: entreprises
    return "entreprises"

def determine_country(article):
    """D√©termine le pays de l'actualit√© (france/us)"""
    # Par d√©faut aux √âtats-Unis
    country = "us"
    
    # V√©rifier si c'est fran√ßais
    if article.get("symbol") and any(suffix in str(article.get("symbol")) for suffix in [".PA", ".PAR"]):
        country = "france"
    
    text = (article.get("text", "") + " " + article.get("title", "")).lower()
    french_keywords = [
        "france", "fran√ßais", "paris", "cac", "bourse de paris", "euronext",
        "amf", "autorit√© des march√©s", "bercy", "matignon", "elys√©e", "bpifrance",
        "fran√ßaise", "hexagone"
    ]
    
    european_keywords = [
        "europe", "eurozone", "euro", "european", "europ√©en", "bruxelles",
        "allemagne", "italie", "espagne", "bce", "ecb", "ue", "eu", "commission europ√©enne"
    ]
    
    if any(keyword in text for keyword in french_keywords):
        country = "france"
    elif any(keyword in text for keyword in european_keywords) and country != "france":
        # Marquer europ√©en comme fran√ßais si pas d√©j√† identifi√© comme fran√ßais
        country = "france"
        
    return country

def determine_impact(article):
    """D√©termine l'impact de l'actualit√© (positive/negative/neutral)"""
    # Si le sentiment est fourni par l'API
    sentiment = article.get("sentiment")
    if sentiment:
        try:
            sentiment_value = float(sentiment)
            if sentiment_value > 0.2:
                return "positive"
            elif sentiment_value < -0.2:
                return "negative"
            else:
                return "neutral"
        except:
            pass
    
    # Analyse basique du texte si pas de sentiment fourni
    text = (article.get("text", "") + " " + article.get("title", "")).lower()
    
    positive_words = [
        "surge", "soar", "gain", "rise", "jump", "boost", "recovery", "profit", 
        "beat", "success", "bullish", "upward", "rally", "outperform", "growth",
        "positive", "optimistic", "momentum", "exceed", "improvement", "confidence",
        "strong", "strength", "uptick", "upgrade", "hausse", "progresse", "augmente"
    ]
    
    negative_words = [
        "drop", "fall", "decline", "loss", "plunge", "tumble", "crisis", "risk", 
        "warning", "concern", "bearish", "downward", "slump", "underperform", "recession",
        "negative", "pessimistic", "weakness", "miss", "downgrade", "cut", "reduction",
        "pressure", "struggle", "slowdown", "baisse", "chute", "recule", "diminue" 
    ]
    
    positive_count = sum(1 for word in positive_words if word in text)
    negative_count = sum(1 for word in negative_words if word in text)
    
    if positive_count > negative_count:
        return "positive"
    elif negative_count > positive_count:
        return "negative"
    else:
        return "neutral"

def format_date(date_str):
    """Formate une date au format YYYY-MM-DD en DD/MM/YYYY"""
    try:
        date_parts = date_str.split(" ")[0].split("-")
        if len(date_parts) == 3:
            return f"{date_parts[2]}/{date_parts[1]}/{date_parts[0]}"
        return date_str.replace("-", "/")
    except:
        # Fallback en cas d'erreur
        return date_str.replace("-", "/")

def format_time(date_str):
    """Extrait l'heure au format HH:MM √† partir d'une date compl√®te"""
    try:
        time_parts = date_str.split(" ")[1].split(":")
        if len(time_parts) >= 2:
            return f"{time_parts[0]}:{time_parts[1]}"
        return "00:00"
    except:
        # Fallback en cas d'erreur
        return "00:00"

def normalize_article(article, source=None):
    """Normalise les diff√©rents formats d'articles FMP en un format standard"""
    # G√©rer les diff√©rents formats selon l'endpoint
    
    # D√©terminer les champs cl√©s
    title = article.get("title", "")
    
    # Pour FMP Articles API
    if "date" in article and "content" in article and "tickers" in article:
        text = article.get("content", "")
        date = article.get("date", "")
        symbol = article.get("tickers", "")
        site = article.get("site", "Financial Modeling Prep")
        url = article.get("link", "")
    # Pour les autres endpoints
    else:
        text = article.get("text", "")
        date = article.get("publishedDate", "")
        symbol = article.get("symbol", "")
        site = article.get("site", article.get("publisher", ""))
        url = article.get("url", "")
    
    # Retourner un article normalis√©
    return {
        "title": title,
        "text": text,
        "publishedDate": date,
        "symbol": symbol,
        "site": site,
        "url": url,
        "source_type": source  # Ajout du type de source pour la classification
    }

def remove_duplicates(news_list):
    """Supprime les articles en double bas√©s sur le titre"""
    seen_titles = set()
    unique_news = []
    
    for item in news_list:
        title = item["title"].lower()
        if title not in seen_titles:
            seen_titles.add(title)
            unique_news.append(item)
    
    return unique_news

def calculate_news_score(article):
    """
    Calcule un score pour classer l'importance d'une actualit√© en fonction des mots-cl√©s
    """
    # Cr√©er un texte combin√© pour l'analyse
    content = f"{article.get('title', '')} {article.get('content', '')}"
    if not content or not isinstance(content, str):
        content = ""
    content = content.lower()
    
    score = 0
    
    # Ajouter des points selon les occurrences de mots-cl√©s
    for word in NEWS_KEYWORDS["high_impact"]:
        if word in content:
            score += 10
    
    for word in NEWS_KEYWORDS["medium_impact"]:
        if word in content:
            score += 5
    
    for word in NEWS_KEYWORDS["low_impact"]:
        if word in content:
            score += 2
    
    # Ajustement bas√© sur la source
    if any(source in article.get("source", "") for source in IMPORTANT_SOURCES):
        score += 5
    
    # Bonus pour les actualit√©s n√©gatives (souvent plus impactantes)
    if article.get("impact") == "negative":
        score += 3
    
    # Bonus pour certaines cat√©gories g√©n√©ralement plus importantes
    if article.get("category") == "economie":
        score += 3
    elif article.get("category") == "marches":
        score += 2
    
    return score

def determine_event_impact(event):
    """D√©termine le niveau d'impact d'un √©v√©nement √©conomique"""
    # √âv√©nements √† fort impact
    high_impact_events = [
        "Interest Rate Decision", "Fed Interest Rate", "ECB Interest Rate", 
        "Inflation Rate", "GDP Growth", "GDP Release", "Employment Change",
        "Unemployment Rate", "Non-Farm Payrolls", "CPI", "Retail Sales",
        "FOMC", "FED", "BCE", "ECB", "Fed Chair", "Treasury", "Central Bank"
    ]
    
    # √âv√©nements √† impact moyen
    medium_impact_events = [
        "PMI", "Consumer Confidence", "Trade Balance", "Industrial Production",
        "Manufacturing Production", "Housing Starts", "Building Permits",
        "Durable Goods Orders", "Factory Orders", "Earnings Report", "Balance Sheet"
    ]
    
    # V√©rifier le nom de l'√©v√©nement
    event_name = event.get("event", "").lower()
    
    if any(keyword.lower() in event_name for keyword in high_impact_events):
        return "high"
    
    if any(keyword.lower() in event_name for keyword in medium_impact_events):
        return "medium"
    
    # V√©rifier si l'√©v√©nement est d√©j√† class√© par FMP
    if event.get("impact") == "High":
        return "high"
    elif event.get("impact") == "Medium":
        return "medium"
    
    # Par d√©faut, impact faible
    return "low"

def calculate_event_score(event):
    """Calcule un score pour hi√©rarchiser l'importance des √©v√©nements √©conomiques"""
    score = 0
    
    # Impact de l'√©v√©nement
    impact = determine_event_impact(event)
    if impact == "high":
        score += 10
    elif impact == "medium":
        score += 5
    else:
        score += 1
    
    # Bonus pour les √âtats-Unis (march√© influent)
    if event.get("country") == "US" or event.get("country") == "United States":
        score += 3
    
    # Bonus pour les √©v√©nements avec √©cart important vs pr√©visions
    if event.get("actual") and event.get("forecast"):
        try:
            actual = float(event.get("actual").replace("%", ""))
            forecast = float(event.get("forecast").replace("%", ""))
            diff = abs(actual - forecast)
            
            if diff > 5:
                score += 5  # √âcart tr√®s important
            elif diff > 2:
                score += 3  # √âcart significatif
            elif diff > 0.5:
                score += 1  # √âcart notable
        except (ValueError, AttributeError):
            # Si on ne peut pas convertir en float, on ignore
            pass
    
    # Ajustement par type d'√©v√©nement pour les r√©sultats d'entreprises
    if event.get("type") == "earnings":
        # Essayer d'extraire le symbole de l'action des r√©sultats
        title = event.get("title", "")
        
        # Bonus pour les entreprises importantes
        major_companies = ["AAPL", "MSFT", "GOOGL", "AMZN", "META", "NVDA", "TSLA", "JPM", "V", "PYPL", "DIS"]
        if any(company in title for company in major_companies):
            score += 3
    
    return score

def extract_top_themes(news_data, days=30):
    """Analyse les th√®mes dominants sur une p√©riode donn√©e (ex: 30 jours)"""
    cutoff_date = datetime.now() - timedelta(days=days)
    themes_counter = {
        "macroeconomie": Counter(),
        "secteurs": Counter(),
        "regions": Counter()
    }
    
    for country_articles in news_data.values():
        if not isinstance(country_articles, list):
            continue
        
        for article in country_articles:
            try:
                article_date = datetime.strptime(article["date"], "%d/%m/%Y")
            except:
                continue
            
            if article_date < cutoff_date:
                continue
            
            themes = article.get("themes", {})
            for axe, subthemes in themes.items():
                for theme in subthemes:
                    themes_counter[axe][theme] += 1
    
    # On retourne les 5 principaux pour chaque axe
    top_themes = {
        axe: themes_counter[axe].most_common(5) for axe in themes_counter
    }
    return top_themes

def process_news_data(news_sources):
    """Traite et formate les actualit√©s FMP pour correspondre au format TradePulse"""
    formatted_data = {
        "us": [],
        "france": [],
        "lastUpdated": datetime.now().isoformat()
    }
    
    # Traiter chaque source d'actualit√©s
    for source_type, articles in news_sources.items():
        for article in articles:
            # Normaliser l'article
            normalized = normalize_article(article, source_type)
            
            # V√©rifier si le titre est suffisamment long pour √™tre pertinent
            if len(normalized["title"]) < 10:
                continue
                
            # V√©rifier si le contenu est suffisamment d√©taill√©
            if len(normalized["text"]) < 50:
                continue
            
            # Donn√©es essentielles
            news_item = {
                "title": normalized["title"],
                "content": normalized["text"],
                "source": normalized["site"],
                "date": format_date(normalized["publishedDate"]),
                "time": format_time(normalized["publishedDate"]),
                "category": determine_category(normalized, source_type),
                "impact": determine_impact(normalized),
                "country": determine_country(normalized),
                "url": normalized.get("url", ""),
                "themes": extract_themes(normalized)
            }
            
            # Ajouter √† la section par pays
            if news_item["country"] == "france":
                formatted_data["france"].append(news_item)
            else:
                formatted_data["us"].append(news_item)
    
    # Ajouter un score √† chaque actualit√©
    for country in ["us", "france"]:
        for article in formatted_data[country]:
            article["score"] = calculate_news_score(article)
    
    # Trier chaque cat√©gorie par score (plus √©lev√© en premier), puis par date (plus r√©cent en premier)
    for country in ["us", "france"]:
        formatted_data[country] = sorted(
            formatted_data[country], 
            key=lambda x: (x["score"], x["date"], x["time"]), 
            reverse=True
        )
        
        # Supprimer les doublons
        formatted_data[country] = remove_duplicates(formatted_data[country])
        
        # Limiter le nombre d'articles
        formatted_data[country] = formatted_data[country][:CONFIG["output_limits"][country]]
    
    return formatted_data

def process_events_data(earnings, economic):
    """Traite et formate les donn√©es d'√©v√©nements"""
    events = []
    
    # Traiter le calendrier √©conomique
    for eco_event in economic:
        # Ajouter l'impact et le score
        impact = determine_event_impact(eco_event)
        score = calculate_event_score(eco_event)
        
        event = {
            "title": eco_event.get("event", ""),
            "date": format_date(eco_event.get("date", "")),
            "time": eco_event.get("time", "09:00"),
            "type": "economic",
            "importance": impact,
            "score": score
        }
        events.append(event)
    
    # Traiter le calendrier des r√©sultats
    for earning in earnings:
        # Ne garder que les r√©sultats avec des pr√©visions
        if earning.get("epsEstimated"):
            # Cr√©er un faux √©v√©nement pour le calcul du score
            temp_event = {
                "event": f"Earnings {earning.get('symbol')}",
                "type": "earnings",
                "title": f"R√©sultats {earning.get('symbol')} - Pr√©vision: {earning.get('epsEstimated')}$ par action"
            }
            
            impact = "medium"  # Par d√©faut pour les r√©sultats
            score = calculate_event_score(temp_event)
            
            event = {
                "title": f"R√©sultats {earning.get('symbol')} - Pr√©vision: {earning.get('epsEstimated')}$ par action",
                "date": format_date(earning.get("date", "")),
                "time": "16:30",  # Heure typique pour les annonces de r√©sultats
                "type": "earnings",
                "importance": impact,
                "score": score
            }
            events.append(event)
    
    # Trier les √©v√©nements par score puis par date
    events.sort(key=lambda x: (x["score"], x["date"]), reverse=True)
    
    # Limiter √† 10 √©v√©nements maximum
    return events[:10]

def update_news_json_file(news_data, events):
    """Met √† jour le fichier news.json avec les donn√©es format√©es"""
    try:
        output_data = {
            "us": news_data["us"],
            "france": news_data["france"],
            "events": events,
            "lastUpdated": datetime.now().isoformat()
        }
        
        # Cr√©er le dossier data s'il n'existe pas
        os.makedirs(os.path.dirname(NEWS_JSON_PATH), exist_ok=True)
        
        with open(NEWS_JSON_PATH, 'w', encoding='utf-8') as f:
            json.dump(output_data, f, ensure_ascii=False, indent=2)
            
        logger.info(f"‚úÖ Fichier news.json mis √† jour avec succ√®s")
        return True
    except Exception as e:
        logger.error(f"‚ùå Erreur lors de la mise √† jour du fichier: {str(e)}")
        return False

def generate_themes_json(news_data):
    """G√©n√®re un fichier JSON avec les th√®mes dominants sur diff√©rentes p√©riodes"""
    
    # D√©finir les p√©riodes d'analyse
    periods = {
        "weekly": 7,
        "monthly": 30,
        "quarterly": 90
    }
    
    # Extraire les th√®mes dominants pour chaque p√©riode
    themes_data = {
        period: extract_top_themes(news_data, days=days) 
        for period, days in periods.items()
    }
    
    # Ajouter des m√©tadonn√©es
    themes_output = {
        "themes": themes_data,
        "lastUpdated": datetime.now().isoformat(),
        "analysisCount": sum(len(articles) for articles in news_data.values() if isinstance(articles, list))
    }
    
    # Cr√©er le dossier data s'il n'existe pas
    os.makedirs(os.path.dirname(THEMES_JSON_PATH), exist_ok=True)
    
    # √âcrire dans le fichier
    try:
        with open(THEMES_JSON_PATH, 'w', encoding='utf-8') as f:
            json.dump(themes_output, f, ensure_ascii=False, indent=2)
        logger.info(f"‚úÖ Fichier themes.json mis √† jour avec succ√®s")
        return True
    except Exception as e:
        logger.error(f"‚ùå Erreur lors de la mise √† jour du fichier themes.json: {str(e)}")
        return False

def main():
    """Fonction principale d'ex√©cution"""
    try:
        # 0. Lire les donn√©es existantes pour fallback
        existing_data = read_existing_news()
        
        # 1. R√©cup√©rer les diff√©rentes actualit√©s
        general_news = get_general_news()
        fmp_articles = get_fmp_articles()
        stock_news = get_stock_news()
        crypto_news = get_crypto_news()
        press_releases = get_press_releases()
        
        # 2. R√©cup√©rer les √©v√©nements
        earnings = get_earnings_calendar()
        economic = get_economic_calendar()
        
        # 3. Organiser les sources d'actualit√©s
        news_sources = {
            "general_news": general_news,
            "fmp_articles": fmp_articles,
            "stock_news": stock_news,
            "crypto_news": crypto_news,
            "press_releases": press_releases
        }
        
        # Compter le nombre total d'actualit√©s
        total_news = sum(len(articles) for articles in news_sources.values())
        logger.info(f"Total des actualit√©s r√©cup√©r√©es: {total_news}")
        
        # V√©rifier si nous avons des donn√©es
        if total_news == 0:
            logger.warning("Aucune actualit√© r√©cup√©r√©e, utilisation des donn√©es existantes")
            if existing_data:
                return True
        
        # 4. Traiter et formater les donn√©es
        news_data = process_news_data(news_sources)
        events = process_events_data(earnings, economic)
        
        # 5. Mettre √† jour le fichier JSON des actualit√©s
        success_news = update_news_json_file(news_data, events)
        
        # 6. G√©n√©rer le fichier des th√®mes dominants
        success_themes = generate_themes_json(news_data)
        
        # 7. Afficher les th√®mes dominants sur 30 jours (pour le log)
        top_themes = extract_top_themes(news_data, days=30)
        logger.info("üéØ Th√®mes dominants sur 30 jours:")
        for axe, themes in top_themes.items():
            logger.info(f"  {axe.capitalize()}: {[f'{theme} ({count})' for theme, count in themes]}")
        
        return success_news and success_themes
    except Exception as e:
        logger.error(f"‚ùå Erreur dans l'ex√©cution du script: {str(e)}")
        import traceback
        logger.error(traceback.format_exc())
        return False

if __name__ == "__main__":
    success = main()
    if not success:
        exit(1)
