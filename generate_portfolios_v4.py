#!/usr/bin/env python3
"""
generate_portfolios_v4.py - Orchestrateur complet

Architecture v4 :
- Python d√©cide les poids (d√©terministe via portfolio_engine)
- LLM g√©n√®re uniquement les justifications (prompt compact)
- Compliance AMF appliqu√©e syst√©matiquement
- Backtest 90j int√©gr√© avec comparaison des 3 profils
- Filtre Buffett sectoriel int√©gr√©

V3.4:   FIX - Forcer fund_type="bond" pour TOUS les bonds (pas juste si colonne absente)
V4.4.1: FIX - Bug mapping % (agr√©gation coh√©rente front + _tickers)
V4.4:   FEAT - Nouveau format market_context.json unifi√© (GPT g√©n√®re secteurs/r√©gions favoris√©s)
V4.3.1: FIX - Utiliser markets.json au lieu de indices.json pour les donn√©es r√©gionales
V4.3.0: FEAT - Int√©gration tactical_context (sectors.json + markets.json + macro_tilts.json)
        Le scoring inclut maintenant le contexte march√© (momentum secteur/r√©gion + convictions macro)
V4.2.5: FIX - Charger combined_bonds.csv (vrais bonds, pas seulement ETF obligataires)
V4.2.4: FIX TICKER - ticker/symbol dans universe.py pour ETF/bonds
V4.2.3: FIX NaN float pandas + agr√©gation poids par ticker (+=)
V4.2.2: FIX TICKER - R√©cup√©rer ticker depuis source_data, pas Asset.ticker
V4.2.1: FIX AttributeError - utiliser getattr() pour Asset
V4.2: FIX EXPORT - Ajoute bloc _tickers pour le backtest (Solution C)
V4.1: FIX BACKTEST - Utilise poids FIXES du portfolio (pas recalcul dynamique)

"""

import os
import json
import logging
import datetime
import math
import re
from pathlib import Path
from typing import Dict, Any, Optional, List
from datetime import timedelta
import yaml
import pandas as pd

# === Nouveaux modules ===
from portfolio_engine import (
    build_scored_universe,
    rescore_universe_by_profile,
    PortfolioOptimizer,
    convert_universe_to_assets,
    PROFILES,
    build_commentary_prompt,
    generate_commentary_sync,
    generate_fallback_commentary,
    merge_commentary_into_portfolios,
    # Buffett filter
    apply_buffett_filter,
    get_sector_summary,
    SECTOR_PROFILES,
    compute_scores,
    filter_equities,
    sector_balanced_selection,
)

# 4.4: Import du chargeur de contexte march√©
from portfolio_engine.market_context import load_market_context

from compliance import (
    generate_compliance_block,
    sanitize_portfolio_output,
    AMF_DISCLAIMER,
)

# === Modules existants (compatibilit√©) ===
try:
    from brief_formatter import format_brief_data
except ImportError:
    def format_brief_data(data): return str(data) if data else ""

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s | %(levelname)s | %(name)s | %(message)s"
)
logger = logging.getLogger("portfolio-v4")


# ============= CONFIGURATION =============

CONFIG = {
    "stocks_paths": [
        "data/stocks_us.json",
        "data/stocks_europe.json",
        "data/stocks_asia.json",
    ],
    "etf_csv": "data/combined_etfs.csv",
    "bonds_csv": "data/combined_bonds.csv",  # V4.2.5: Ajout vrais bonds
    "crypto_csv": "data/filtered/Crypto_filtered_volatility.csv",
    "brief_paths": ["brief_ia.json", "./brief_ia.json", "data/brief_ia.json"],
    "output_path": "data/portfolios.json",
    "history_dir": "data/portfolio_history",
    "backtest_output": "data/backtest_results.json",
    "config_path": "config/portfolio_config.yaml",
    "use_llm": True,
    "llm_model": "gpt-4o-mini",
    "run_backtest": True,  # Activer le backtest
    "backtest_days": 90,
    "backtest_freq": "M",  # Monthly
    # === Buffett Filter Config ===
    "buffett_mode": "soft",      # "soft" (p√©nalise), "hard" (rejette), "both", "none" (d√©sactiv√©)
    "buffett_min_score": 40,     # Score minimum Buffett (0-100), 0 = pas de filtre
    # === v4.4: Tactical Context Config ===
    "use_tactical_context": True,  # Activer le scoring tactique
    "market_data_dir": "data",     # R√©pertoire du fichier market_context.json
}


# ============= CHARGEMENT DONN√âES =============

def load_json_safe(path: str) -> Dict:
    """Charge un JSON avec gestion d'erreur."""
    try:
        with open(path, 'r', encoding='utf-8') as f:
            return json.load(f)
    except Exception as e:
        logger.warning(f"Impossible de charger {path}: {e}")
        return {}


def load_yaml_config(path: str) -> Dict:
    """Charge la configuration YAML."""
    try:
        with open(path, 'r', encoding='utf-8') as f:
            return yaml.safe_load(f)
    except Exception as e:
        logger.warning(f"Impossible de charger config {path}: {e}")
        return {}


def load_brief_data() -> Optional[Dict]:
    """Cherche et charge le brief strat√©gique."""
    for path in CONFIG["brief_paths"]:
        if Path(path).exists():
            data = load_json_safe(path)
            if data:
                logger.info(f"Brief charg√© depuis {path}")
                return data
    logger.warning("Aucun brief trouv√©")
    return None


def load_stocks_data() -> list:
    """Charge les fichiers stocks JSON."""
    stocks = []
    for path in CONFIG["stocks_paths"]:
        if Path(path).exists():
            data = load_json_safe(path)
            if data:
                stocks.append(data)
                logger.info(f"Stocks: {path} ({len(data.get('stocks', []))} entr√©es)")
    return stocks


# ============= BUFFETT DIAGNOSTIC =============

def print_buffett_diagnostic(assets: List[dict], title: str = "DIAGNOSTIC FILTRE BUFFETT"):
    """
    Affiche un diagnostic du filtre Buffett sur l'univers.
    
    Args:
        assets: Liste des actifs avec m√©triques Buffett (_buffett_score, etc.)
        title: Titre du diagnostic
    """
    if not assets:
        print("‚ö†Ô∏è  Pas d'actifs √† analyser")
        return
        
    print("\n" + "=" * 80)
    print(f"üéØ {title}")
    print("=" * 80)
    
    # R√©cup√©rer les stats sectorielles
    summary = get_sector_summary(assets)
    
    if not summary:
        print("‚ö†Ô∏è  Pas de donn√©es sectorielles disponibles")
        return
    
    # Compter les actifs avec donn√©es
    total_with_roe = sum(1 for a in assets if a.get("roe") and float(a.get("roe", 0) or 0) > 0)
    total_with_de = sum(1 for a in assets if a.get("de_ratio") is not None)
    
    print(f"\nüìà Couverture donn√©es: ROE={total_with_roe}/{len(assets)} ({100*total_with_roe//max(1,len(assets))}%), "
          f"D/E={total_with_de}/{len(assets)} ({100*total_with_de//max(1,len(assets))}%)")
    
    # Afficher le tableau
    print(f"\n{'Secteur':<22} | {'Count':>6} | {'ROE moy':>10} | {'D/E moy':>10} | {'Score':>8} | {'Rejet√©s':>8}")
    print("-" * 80)
    
    total_count = 0
    total_rejected = 0
    scores = []
    
    # Trier par score d√©croissant
    sorted_sectors = sorted(
        summary.items(),
        key=lambda x: x[1].get("avg_buffett_score") or 0,
        reverse=True
    )
    
    for sector, stats in sorted_sectors:
        count = stats.get("count", 0)
        avg_roe = stats.get("avg_roe")
        avg_de = stats.get("avg_de")
        avg_score = stats.get("avg_buffett_score")
        rejected = stats.get("rejected_count", 0)
        
        total_count += count
        total_rejected += rejected
        if avg_score:
            scores.append(avg_score)
        
        # Formatage - D/E peut √™tre en d√©cimal (0.25) ou en % (25)
        roe_str = f"{avg_roe:.1f}%" if avg_roe else "N/A"
        
        # Si D/E < 10, c'est probablement en d√©cimal, convertir en %
        if avg_de is not None:
            if avg_de < 10:
                de_display = avg_de * 100
            else:
                de_display = avg_de
            de_str = f"{de_display:.0f}%"
        else:
            de_str = "N/A"
        
        score_str = f"{avg_score:.0f}" if avg_score else "N/A"
        
        # Emoji indicateur
        if avg_score and avg_score >= 70:
            indicator = "üü¢"
        elif avg_score and avg_score >= 50:
            indicator = "üü°"
        else:
            indicator = "üî¥"
        
        print(f"{indicator} {sector:<20} | {count:>6} | {roe_str:>10} | {de_str:>10} | {score_str:>8} | {rejected:>8}")
    
    print("-" * 80)
    
    # Totaux
    avg_global_score = sum(scores) / len(scores) if scores else 0
    print(f"{'TOTAL':<24} | {total_count:>6} | {'':<10} | {'':<10} | {avg_global_score:>7.0f} | {total_rejected:>8}")
    
    print("\nüìä L√©gende:")
    print("   üü¢ Score ‚â• 70 : Qualit√© Buffett excellente")
    print("   üü° Score 50-69 : Qualit√© acceptable")
    print("   üî¥ Score < 50 : Qualit√© insuffisante (filtr√© si score_min > 50)")
    
    # Top 5 et Bottom 5 - avec protection contre None
    scored_assets = [a for a in assets if a.get("_buffett_score") is not None]
    if len(scored_assets) >= 5:
        sorted_by_score = sorted(scored_assets, key=lambda x: x.get("_buffett_score", 0) or 0, reverse=True)
        
        print("\nüèÜ TOP 5 Buffett:")
        for a in sorted_by_score[:5]:
            name = (a.get("name") or a.get("ticker") or "?")[:25]
            score = a.get("_buffett_score") or 0
            roe = a.get("roe")
            sector = a.get("_sector_key") or a.get("sector") or "?"
            roe_str = f"{float(roe):.1f}%" if roe and roe != "N/A" else "N/A"
            print(f"   ‚Ä¢ {name:<25} | Score: {score:>5.0f} | ROE: {roe_str:>8} | {sector}")
        
        print("\n‚ö†Ô∏è  BOTTOM 5 Buffett:")
        for a in sorted_by_score[-5:]:
            name = (a.get("name") or a.get("ticker") or "?")[:25]
            score = a.get("_buffett_score") or 0
            reason = a.get("_buffett_reject_reason") or "score faible"
            sector = a.get("_sector_key") or a.get("sector") or "?"
            print(f"   ‚Ä¢ {name:<25} | Score: {score:>5.0f} | Raison: {reason} | {sector}")
    
    print("=" * 80 + "\n")


# ============= v4.4: TACTICAL CONTEXT DIAGNOSTIC =============

def print_tactical_context_diagnostic(market_context: Dict):
    """
    Affiche un diagnostic du contexte march√© charg√© (v4.4 format).
    
    Args:
        market_context: R√©sultat de load_market_context()
    """
    print("\n" + "=" * 80)
    print("üìä DIAGNOSTIC CONTEXTE TACTIQUE (v4.4)")
    print("=" * 80)
    
    # R√©gime
    regime = market_context.get("market_regime", "N/A")
    confidence = market_context.get("confidence", "N/A")
    as_of = market_context.get("as_of", "N/A")
    
    print(f"\nüìà R√©gime march√©: {regime} (confidence: {confidence})")
    print(f"   Date: {as_of}")
    
    # Macro tilts
    macro_tilts = market_context.get("macro_tilts", {})
    if macro_tilts:
        favored_sectors = macro_tilts.get("favored_sectors", [])
        avoided_sectors = macro_tilts.get("avoided_sectors", [])
        favored_regions = macro_tilts.get("favored_regions", [])
        avoided_regions = macro_tilts.get("avoided_regions", [])
        rationale = macro_tilts.get("rationale", "N/A")
        
        print(f"\n‚úÖ Tilts tactiques:")
        print(f"   Secteurs favoris√©s (+15%): {', '.join(favored_sectors) if favored_sectors else 'Aucun'}")
        print(f"   Secteurs √©vit√©s (-15%): {', '.join(avoided_sectors) if avoided_sectors else 'Aucun'}")
        print(f"   R√©gions favoris√©es (+15%): {', '.join(favored_regions) if favored_regions else 'Aucun'}")
        print(f"   R√©gions √©vit√©es (-15%): {', '.join(avoided_regions) if avoided_regions else 'Aucun'}")
        print(f"\n   Rationale: {rationale}")
    else:
        print("\n‚ö†Ô∏è Pas de tilts tactiques (mode neutre)")
    
    # Trends et risques
    trends = market_context.get("key_trends", [])
    risks = market_context.get("risks", [])
    
    if trends:
        print(f"\nüìà Tendances cl√©s: {', '.join(trends)}")
    if risks:
        print(f"‚ö†Ô∏è  Risques: {', '.join(risks)}")
    
    # Meta
    meta = market_context.get("_meta", {})
    if meta:
        model = meta.get("model", "N/A")
        is_fallback = meta.get("is_fallback", False)
        print(f"\nüîß M√©ta: model={model}, fallback={is_fallback}")
    
    print("\n" + "=" * 80 + "\n")


# ============= PIPELINE PRINCIPAL =============

def build_portfolios_deterministic() -> Dict[str, Dict]:
    """
    Pipeline d√©terministe : m√™mes donn√©es ‚Üí m√™mes poids.
    Utilise les modules portfolio_engine.
    
    v4.4: Utilise le nouveau format market_context.json unifi√©.
    """
    logger.info("üßÆ Construction des portefeuilles (d√©terministe)...")
    
    # v4.4: Charger le contexte march√© pour le scoring tactique
    market_context = None
    if CONFIG.get("use_tactical_context", True):
        logger.info("üìä Chargement du contexte march√© (tactical_context)...")
        market_context = load_market_context(CONFIG.get("market_data_dir", "data"))
        
        # v4.4 FIX: V√©rifier macro_tilts au lieu de sectors/indices
        macro_tilts = market_context.get("macro_tilts", {})
        has_tilts = (
            macro_tilts.get("favored_sectors") or 
            macro_tilts.get("avoided_sectors") or
            macro_tilts.get("favored_regions") or
            macro_tilts.get("avoided_regions")
        )
        
        if has_tilts:
            print_tactical_context_diagnostic(market_context)
            logger.info("‚úÖ Contexte march√© charg√© pour scoring tactique")
        else:
            # V√©rifier si c'est un fallback explicite
            is_fallback = market_context.get("_meta", {}).get("is_fallback", False)
            if is_fallback:
                logger.warning("‚ö†Ô∏è Contexte march√© en mode FALLBACK - scoring tactique neutre")
            else:
                logger.warning("‚ö†Ô∏è Contexte march√© sans tilts actifs - scoring tactique d√©sactiv√©")
            # On garde market_context pour √©viter les erreurs, mais les tilts seront 0
    
    # 1. Charger les donn√©es brutes
    stocks_data = load_stocks_data()
    
    # 2. Charger ETF, Bonds et Crypto (V4.2.5: ajout bonds s√©par√©s)
    etf_data = []
    bonds_data = []
    crypto_data = []
    
    # ETF
    if Path(CONFIG["etf_csv"]).exists():
        try:
            df = pd.read_csv(CONFIG["etf_csv"])
            etf_data = df.to_dict('records')
            logger.info(f"ETF: {CONFIG['etf_csv']} ({len(etf_data)} entr√©es)")
        except Exception as e:
            logger.warning(f"Impossible de charger ETF: {e}")
    
    # V3.4 FIX: Charger les vrais bonds depuis combined_bonds.csv
    # TOUJOURS forcer fund_type="bond" car TOUT le fichier = bonds
    if Path(CONFIG["bonds_csv"]).exists():
        try:
            df_b = pd.read_csv(CONFIG["bonds_csv"])
            # V3.4: Forcer TOUJOURS (pas juste si colonne absente)
            # Tous les assets de combined_bonds.csv sont des bonds par d√©finition
            df_b["category"] = "bond"
            df_b["fund_type"] = "bond"
            bonds_data = df_b.to_dict("records")
            logger.info(f"Bonds: {CONFIG['bonds_csv']} ({len(bonds_data)} entr√©es) - fund_type forc√© √† 'bond'")
        except Exception as e:
            logger.warning(f"Impossible de charger Bonds: {e}")
    
    # Crypto
    if Path(CONFIG["crypto_csv"]).exists():
        try:
            df = pd.read_csv(CONFIG["crypto_csv"])
            crypto_data = df.to_dict('records')
            logger.info(f"Crypto: {CONFIG['crypto_csv']} ({len(crypto_data)} entr√©es)")
        except Exception as e:
            logger.warning(f"Impossible de charger crypto: {e}")
    
    # 3. Extraire les stocks bruts pour le filtre Buffett
    logger.info("üìä Construction de l'univers...")
    logger.info(f"   Mode Buffett: {CONFIG['buffett_mode']}, Score min: {CONFIG['buffett_min_score']}")
    
    # Construire la liste d'equities brutes
    eq_rows = []
    for data in stocks_data:
        stocks_list = data.get("stocks", []) if isinstance(data, dict) else data
        for it in stocks_list:
            eq_rows.append({
                "id": f"EQ_{len(eq_rows)+1}",
                "name": it.get("name") or it.get("ticker"),
                "ticker": it.get("ticker"),
                "perf_1m": it.get("perf_1m"),
                "perf_3m": it.get("perf_3m"),
                "ytd": it.get("perf_ytd") or it.get("ytd"),
                "perf_24h": it.get("perf_1d"),
                "vol_3y": it.get("volatility_3y") or it.get("vol"),
                "vol": it.get("volatility_3y") or it.get("vol"),
                "volatility_3y": it.get("volatility_3y"),
                "max_dd": it.get("max_drawdown_ytd"),
                "max_drawdown_ytd": it.get("max_drawdown_ytd"),
                "liquidity": it.get("market_cap"),
                "market_cap": it.get("market_cap"),
                "sector": it.get("sector", "Unknown"),
                "country": it.get("country", "Global"),
                "category": "equity",
                # M√©triques fondamentales pour Buffett filter
                "roe": it.get("roe"),
                "de_ratio": it.get("de_ratio"),
                "payout_ratio_ttm": it.get("payout_ratio_ttm"),
                "dividend_yield": it.get("dividend_yield"),
                "dividend_coverage": it.get("dividend_coverage"),
                "pe_ratio": it.get("pe_ratio"),
                "eps_ttm": it.get("eps_ttm"),
                # v4.3.0: Champs pour tactical_context
                "sector_top": it.get("sector"),
                "country_top": it.get("country"),
            })
    
    logger.info(f"   Equities brutes charg√©es: {len(eq_rows)}")
    
    # 4. Appliquer le filtre Buffett sur TOUS les stocks bruts AVANT le scoring
    if CONFIG["buffett_mode"] != "none" and eq_rows:
        logger.info(f"   Application filtre Buffett sur {len(eq_rows)} actions...")
        
        eq_rows_filtered = apply_buffett_filter(
            eq_rows,
            mode=CONFIG["buffett_mode"],
            strict=False,
            min_score=CONFIG["buffett_min_score"],
        )
        
        # === DIAGNOSTIC BUFFETT ===
        print_buffett_diagnostic(
            eq_rows_filtered, 
            f"QUALIT√â SECTORIELLE - {len(eq_rows_filtered)}/{len(eq_rows)} actions apr√®s filtre Buffett"
        )
        
        logger.info(f"   Equities apr√®s filtre Buffett: {len(eq_rows_filtered)}")
        eq_rows = eq_rows_filtered
    
    # 5. Appliquer scoring quantitatif et filtres standards
    eq_rows = compute_scores(eq_rows, "equity", None)
    eq_filtered = filter_equities(eq_rows)
    equities = sector_balanced_selection(eq_filtered, min(25, len(eq_filtered)))
    
    logger.info(f"   Equities finales s√©lectionn√©es: {len(equities)}")
    
    # 6. V4.2.5: Fusionner bonds + ETF pour build_scored_universe
    #    (car build_scored_universe ne supporte pas bonds_data s√©par√©ment)
    all_funds_data = []
    all_funds_data.extend(etf_data)
    all_funds_data.extend(bonds_data)
    
    logger.info(f"   Fonds combin√©s (ETF + Bonds): {len(all_funds_data)} ({len(etf_data)} ETF + {len(bonds_data)} Bonds)")
    
    # 7. Construire le reste de l'univers (ETF, bonds, crypto) via build_scored_universe
    universe_others = build_scored_universe(
        stocks_data=None,  # Pas de stocks, on les a d√©j√†
        etf_data=all_funds_data,  # V4.2.5: ETF + Bonds fusionn√©s
        crypto_data=crypto_data,
        returns_series=None,
        buffett_mode="none",  # Pas de Buffett pour ETF/crypto/bonds
        buffett_min_score=0,
    )
    
    # Combiner equities + autres
    universe = equities + universe_others
    
    logger.info(f"   Univers final: {len(universe)} actifs total")
    
    # 8. Optimiser pour chaque profil
    optimizer = PortfolioOptimizer()
    portfolios = {}
    all_assets = []
    
    for profile in ["Agressif", "Mod√©r√©", "Stable"]:
        logger.info(f"‚öôÔ∏è  Optimisation profil {profile}...")
        
        # v4.4: Re-scorer selon le profil AVEC le contexte march√©
        scored_universe = rescore_universe_by_profile(
            universe, 
            profile, 
            market_context=market_context  # ‚Üê Contexte tactique v4.4
        )
        
        # Convertir en objets Asset
        assets = convert_universe_to_assets(scored_universe)
        if not all_assets:
            all_assets = assets
        
        # Optimiser
        allocation, diagnostics = optimizer.build_portfolio(assets, profile)
        
        portfolios[profile] = {
            "allocation": allocation,
            "diagnostics": diagnostics,
            "assets": assets,
        }
        
        logger.info(
            f"   ‚Üí {len(allocation)} lignes, "
            f"vol={diagnostics.get('portfolio_vol', 'N/A'):.1f}%"
        )
    
    return portfolios, all_assets


def add_commentary(
    portfolios: Dict[str, Dict],
    assets: list,
    brief_data: Optional[Dict] = None
) -> Dict[str, Dict]:
    """
    Ajoute les commentaires et justifications.
    Via LLM si disponible, sinon fallback.
    """
    logger.info("üí¨ G√©n√©ration des commentaires...")
    
    portfolios_for_prompt = {
        profile: {
            "allocation": data["allocation"],
            "diagnostics": data["diagnostics"],
        }
        for profile, data in portfolios.items()
    }
    
    if CONFIG["use_llm"]:
        try:
            api_key = os.environ.get("API_CHAT") or os.environ.get("OPENAI_API_KEY")
            if api_key:
                from openai import OpenAI
                client = OpenAI(api_key=api_key)
                
                commentary = generate_commentary_sync(
                    portfolios=portfolios_for_prompt,
                    assets=assets,
                    brief_data=brief_data,
                    openai_client=client,
                    model=CONFIG["llm_model"],
                )
                logger.info("‚úÖ Commentaires g√©n√©r√©s via LLM")
            else:
                logger.warning("‚ö†Ô∏è Pas de cl√© API, fallback sans LLM")
                commentary = generate_fallback_commentary(portfolios_for_prompt, assets)
        except Exception as e:
            logger.error(f"Erreur LLM: {e}, fallback sans LLM")
            commentary = generate_fallback_commentary(portfolios_for_prompt, assets)
    else:
        commentary = generate_fallback_commentary(portfolios_for_prompt, assets)
    
    return merge_commentary_into_portfolios(portfolios_for_prompt, commentary)


def apply_compliance(portfolios: Dict[str, Dict]) -> Dict[str, Dict]:
    """
    Applique la compliance AMF et sanitise le langage.
    """
    logger.info("üõ°Ô∏è  Application compliance AMF...")
    
    for profile in portfolios:
        portfolios[profile] = sanitize_portfolio_output(portfolios[profile])
        
        diag = portfolios[profile].get("diagnostics", {})
        allocation = portfolios[profile].get("allocation", {})
        
        # Fix: Convert aid to string before calling .upper()
        crypto_exposure = sum(
            w for aid, w in allocation.items()
            if any(c in str(aid).upper() for c in ["CR_", "BTC", "ETH", "CRYPTO"])
        )
        
        portfolios[profile]["compliance"] = generate_compliance_block(
            profile=profile,
            vol_estimate=diag.get("portfolio_vol"),
            crypto_exposure=crypto_exposure,
        )
    
    return portfolios


# ============= BACKTEST =============

def run_backtest_all_profiles(config: Dict) -> Dict:
    """
    Ex√©cute le backtest pour les 3 profils avec POIDS FIXES du portfolio.
    
    V4.1: Utilise run_backtest_fixed_weights() au lieu de run_backtest()
    pour refl√©ter vraiment la performance du portfolio g√©n√©r√©.
    """
    logger.info("\n" + "="*60)
    logger.info("üìà BACKTEST - Validation historique (POIDS FIXES)")
    logger.info("="*60)
    
    # V√©rifier la cl√© API Twelve Data
    api_key = os.environ.get("TWELVE_DATA_API")
    if not api_key:
        logger.warning("‚ö†Ô∏è TWELVE_DATA_API non d√©finie, backtest ignor√©")
        return {"error": "TWELVE_DATA_API not set", "skipped": True}
    
    try:
        from backtest import BacktestConfig, load_prices_for_backtest
        from backtest.engine import (
            run_backtest_fixed_weights,  # ‚úÖ NOUVELLE FONCTION
            print_backtest_report, 
            compute_backtest_stats
        )
        from backtest.data_loader import extract_portfolio_weights  # ‚úÖ NOUVEAU
    except ImportError as e:
        logger.error(f"‚ùå Import backtest failed: {e}")
        return {"error": str(e), "skipped": True}
    
    # Charger la config YAML
    yaml_config = load_yaml_config(CONFIG["config_path"])
    if not yaml_config:
        logger.warning("‚ö†Ô∏è Config YAML non trouv√©e, utilisation des d√©fauts")
        yaml_config = {"backtest": {"test_universe": {"stocks": ["AAPL", "MSFT", "GOOGL"]}}}
    
    # Dates
    end_date = datetime.datetime.now().strftime("%Y-%m-%d")
    start_date = (datetime.datetime.now() - timedelta(days=CONFIG["backtest_days"] + 30)).strftime("%Y-%m-%d")
    backtest_start = (datetime.datetime.now() - timedelta(days=CONFIG["backtest_days"])).strftime("%Y-%m-%d")
    
    # ‚úÖ NOUVEAU: Charger les poids FIXES depuis portfolios.json
    logger.info("üì• Chargement des poids depuis portfolios.json...")
    portfolio_weights = extract_portfolio_weights(CONFIG["output_path"])
    
    if not portfolio_weights:
        logger.error("‚ùå Impossible de charger les poids du portfolio")
        return {"error": "No portfolio weights found", "skipped": True}
    
    for profile, weights in portfolio_weights.items():
        logger.info(f"   {profile}: {len(weights)} actifs, total={sum(weights.values()):.1%}")
    
    # Charger les prix UNE SEULE FOIS
    logger.info(f"üì• Chargement des prix ({CONFIG['backtest_days']}j)...")
    try:
        prices = load_prices_for_backtest(
            yaml_config,
            start_date=start_date,
            end_date=end_date,
            api_key=api_key,
            plan="ultra"  # Plan ultra = pas de rate limit
        )
        logger.info(f"‚úÖ {len(prices.columns)} symboles, {len(prices)} jours")
    except Exception as e:
        logger.error(f"‚ùå √âchec chargement prix: {e}")
        return {"error": str(e), "skipped": True}
    
    # Ex√©cuter les 3 profils avec POIDS FIXES
    results = []
    profiles = ["Agressif", "Mod√©r√©", "Stable"]
    
    for profile in profiles:
        logger.info(f"\n‚öôÔ∏è  Backtest {profile} (poids fixes)...")
        
        # R√©cup√©rer les poids fixes pour ce profil
        fixed_weights = portfolio_weights.get(profile, {})
        
        if not fixed_weights:
            logger.warning(f"‚ö†Ô∏è Pas de poids pour {profile}, skip")
            results.append({
                "profile": profile,
                "success": False,
                "error": "No weights found",
            })
            continue
        
        backtest_config = BacktestConfig(
            profile=profile,
            start_date=backtest_start,
            end_date=end_date,
            rebalance_freq=CONFIG["backtest_freq"],
            transaction_cost_bp=yaml_config.get("backtest", {}).get("transaction_cost_bp", 10),
            turnover_penalty=0,  # Pas de p√©nalit√©, poids fixes
        )
        
        try:
            # ‚úÖ UTILISE LA NOUVELLE FONCTION AVEC POIDS FIXES
            result = run_backtest_fixed_weights(
                prices=prices,
                fixed_weights=fixed_weights,
                config=backtest_config,
            )
            print_backtest_report(result)
            
            results.append({
                "profile": profile,
                "success": True,
                "stats": result.stats,
                "equity_curve": {
                    str(k.date()): round(v, 2)
                    for k, v in result.equity_curve.items()
                },
            })
        except Exception as e:
            logger.error(f"‚ùå Backtest {profile} failed: {e}")
            import traceback
            traceback.print_exc()
            results.append({
                "profile": profile,
                "success": False,
                "error": str(e),
            })
    
    # Tableau comparatif
    print_comparison_table(results)
    
    return {
        "timestamp": datetime.datetime.now().isoformat(),
        "period_days": CONFIG["backtest_days"],
        "frequency": CONFIG["backtest_freq"],
        "symbols_count": len(prices.columns),
        "backtest_mode": "fixed_weights",  # ‚úÖ NOUVEAU
        "results": results,
        "comparison": {
            r["profile"]: r.get("stats", {})
            for r in results if r.get("success")
        }
    }


def print_comparison_table(results: List[dict]):
    """Affiche un tableau comparatif des 3 profils."""
    print("\n" + "="*80)
    print("üìä COMPARAISON DES 3 PROFILS (POIDS FIXES)")
    print("="*80)
    
    print(f"\n{'M√©trique':<25} | {'Agressif':>15} | {'Mod√©r√©':>15} | {'Stable':>15}")
    print("-"*80)
    
    metrics = [
        ("Total Return", "total_return_pct", "%"),
        ("CAGR", "cagr_pct", "%"),
        ("Volatility", "volatility_pct", "%"),
        ("Sharpe Ratio", "sharpe_ratio", ""),
        ("Max Drawdown", "max_drawdown_pct", "%"),
        ("Win Rate", "win_rate_pct", "%"),
        ("Weight Coverage", "weight_coverage_pct", "%"),  # ‚úÖ NOUVEAU
        ("Benchmark Return", "benchmark_return_pct", "%"),
        ("Excess Return", "excess_return_pct", "%"),
    ]
    
    by_profile = {r["profile"]: r.get("stats", {}) for r in results if r.get("success")}
    
    for label, key, suffix in metrics:
        agg = by_profile.get("Agressif", {}).get(key, "N/A")
        mod = by_profile.get("Mod√©r√©", {}).get(key, "N/A")
        stb = by_profile.get("Stable", {}).get(key, "N/A")
        
        agg_str = f"{agg}{suffix}" if isinstance(agg, (int, float)) else str(agg)
        mod_str = f"{mod}{suffix}" if isinstance(mod, (int, float)) else str(mod)
        stb_str = f"{stb}{suffix}" if isinstance(stb, (int, float)) else str(stb)
        
        print(f"{label:<25} | {agg_str:>15} | {mod_str:>15} | {stb_str:>15}")
    
    print("="*80)
    
    # Verdict
    print("\nüèÜ VERDICT:")
    
    sharpes = [(r["profile"], r["stats"].get("sharpe_ratio", -999)) 
               for r in results if r.get("success")]
    if sharpes:
        best = max(sharpes, key=lambda x: x[1])
        print(f"   Meilleur Sharpe: {best[0]} ({best[1]:.2f})")
    
    returns = [(r["profile"], r["stats"].get("total_return_pct", -999)) 
               for r in results if r.get("success")]
    if returns:
        best = max(returns, key=lambda x: x[1])
        print(f"   Meilleur Return: {best[0]} ({best[1]:.2f}%)")
    
    dds = [(r["profile"], r["stats"].get("max_drawdown_pct", -999)) 
           for r in results if r.get("success")]
    if dds:
        best = max(dds, key=lambda x: x[1])
        print(f"   Meilleur Drawdown: {best[0]} ({best[1]:.2f}%)")
    
    # V√©rifier l'ordre attendu
    print("\nüìã VALIDATION ORDRE DES RETURNS:")
    sorted_returns = sorted(returns, key=lambda x: x[1], reverse=True)
    expected_order = ["Agressif", "Mod√©r√©", "Stable"]
    actual_order = [r[0] for r in sorted_returns]
    
    if actual_order == expected_order:
        print("   ‚úÖ Ordre correct: Agressif > Mod√©r√© > Stable")
    else:
        print(f"   ‚ö†Ô∏è Ordre inattendu: {' > '.join(actual_order)}")
        print(f"      Attendu: {' > '.join(expected_order)}")
    
    print()


# ============= HELPER FUNCTIONS =============

# Regex pour d√©tecter les IDs internes
INTERNAL_ID_PATTERN = re.compile(r'^(EQ_|ETF_|BOND_|CRYPTO_|CR_)\d+$', re.IGNORECASE)


def _is_internal_id(value: str) -> bool:
    """V√©rifie si une valeur est un ID interne (EQ_10, ETF_123, etc.)."""
    if not value or not isinstance(value, str):
        return False
    return bool(INTERNAL_ID_PATTERN.match(value))


def _normalize_ticker_value(raw) -> Optional[str]:
    """
    V4.2.3: Normalise une valeur de ticker.
    
    G√®re les cas probl√©matiques de pandas:
    - float('nan') ‚Üí None
    - "" ou "  " ‚Üí None
    - "nan" (string) ‚Üí None
    - int/float valides ‚Üí string
    
    Returns:
        String propre ou None si invalide.
    """
    if raw is None:
        return None
    
    # Cas pandas: float NaN
    if isinstance(raw, float):
        if math.isnan(raw):
            return None
        # Float valide (rare) ‚Üí string
        return str(int(raw)) if raw == int(raw) else str(raw)
    
    # Cas int
    if isinstance(raw, int):
        return str(raw)
    
    # Cas string
    if isinstance(raw, str):
        s = raw.strip()
        if not s:
            return None
        if s.lower() == "nan":
            return None
        return s
    
    # Autre type: fallback string
    s = str(raw).strip()
    return s if s and s.lower() != "nan" else None


def _safe_get_attr(obj, key, default=None):
    """
    R√©cup√®re un attribut d'un objet ou d'un dict de mani√®re s√ªre.
    
    V4.2.3: Utilise _normalize_ticker_value pour nettoyer les valeurs.
    
    Ordre de recherche:
    1. Attribut direct sur l'objet
    2. Dans source_data (si Asset)
    3. Dans le dict (si dict)
    4. Valeur par d√©faut
    """
    val = None
    
    # 1. Essayer l'attribut direct
    if hasattr(obj, key):
        val = getattr(obj, key)
        if val is not None:
            # Ne pas normaliser ici, juste retourner
            return val
    
    # 2. Essayer dans source_data (pour les objets Asset)
    if hasattr(obj, 'source_data') and obj.source_data:
        val = obj.source_data.get(key)
        if val is not None:
            return val
    
    # 3. Essayer comme dict
    if isinstance(obj, dict):
        val = obj.get(key)
        if val is not None:
            return val
    
    return default


def _extract_ticker_from_asset(asset, fallback_id: str) -> str:
    """
    V4.2.3: Extrait le ticker d'un actif de mani√®re robuste.
    
    G√®re:
    - float('nan') de pandas
    - strings vides ou "nan"
    - IDs internes (EQ_10, ETF_123)
    
    Returns:
        Ticker valide (jamais None, NaN ou ID interne si √©vitable)
    """
    ticker = None
    
    # 1. Attribut ticker direct
    if hasattr(asset, 'ticker'):
        ticker = _normalize_ticker_value(getattr(asset, 'ticker'))
    
    # 2. Dans source_data
    if not ticker and hasattr(asset, 'source_data') and asset.source_data:
        ticker = _normalize_ticker_value(asset.source_data.get('ticker'))
        if not ticker:
            ticker = _normalize_ticker_value(asset.source_data.get('symbol'))
    
    # 3. Si c'est un dict
    if not ticker and isinstance(asset, dict):
        ticker = _normalize_ticker_value(asset.get('ticker')) or _normalize_ticker_value(asset.get('symbol'))
    
    # 4. Validation: rejeter les IDs internes
    if ticker and _is_internal_id(ticker):
        ticker = None
    
    # 5. Fallback: utiliser le nom si pas de ticker valide
    if not ticker:
        name = _safe_get_attr(asset, 'name')
        name = _normalize_ticker_value(name)
        if name and not _is_internal_id(name):
            # Pour les ETF, le nom peut √™tre le ticker (SPY, QQQ, URTH...)
            if len(name) <= 5 and name.isupper():
                ticker = name
    
    # 6. Dernier recours: utiliser l'ID seulement si ce n'est pas un ID interne
    if not ticker:
        fid = _normalize_ticker_value(fallback_id)
        if fid and not _is_internal_id(fid):
            ticker = fid
        else:
            # ID interne ‚Üí utiliser le nom brut
            name = _safe_get_attr(asset, 'name')
            ticker = _normalize_ticker_value(name) or fid or "UNKNOWN"
    
    return ticker


# ============= NORMALISATION POUR LE FRONT =============

def normalize_to_frontend_v1(portfolios: Dict[str, Dict], assets: list) -> Dict:
    """
    V4.4.1: Convertit le format interne vers le format v1 attendu par le front.
    
    CORRECTIONS v4.4.1:
    - Agr√©gation des poids AUSSI pour le format lisible (+=)
    - Validation crois√©e front vs _tickers
    - Bloc _debug avec mappings d√©taill√©s
    - Warning si incoh√©rence d√©tect√©e
    
    Structure:
        "Agressif": {
            "Commentaire": "...",
            "Actions": { "ELI LILLY AND CO": "14%", ... },  # Pour le front
            "ETF": { ... },
            "_tickers": { "LLY": 0.14, "TJX": 0.12, ... }   # Pour le backtest
        }
    """
    # Construire le lookup avec extraction robuste du ticker
    asset_lookup = {}
    ticker_debug = []  # Pour debug
    
    for a in assets:
        aid = _safe_get_attr(a, 'id')
        name = _safe_get_attr(a, 'name') or aid
        category = _safe_get_attr(a, 'category') or 'ETF'
        
        # V4.2.3: Extraction robuste du ticker avec nettoyage NaN
        ticker = _extract_ticker_from_asset(a, aid)
        
        asset_lookup[str(aid)] = {
            "name": name, 
            "category": category, 
            "ticker": ticker
        }
        
        # Debug log pour les premiers actifs
        if len(ticker_debug) < 5:
            ticker_debug.append(f"{aid} -> {ticker}")
    
    logger.info(f"üîç Sample ticker mapping: {ticker_debug}")
    
    def _category_v1(cat: str) -> str:
        cat = (cat or "").lower()
        if "action" in cat or "equity" in cat or "stock" in cat:
            return "Actions"
        if "oblig" in cat or "bond" in cat:
            return "Obligations"
        if "crypto" in cat:
            return "Crypto"
        return "ETF"
    
    result = {}
    
    for profile, data in portfolios.items():
        allocation = data.get("allocation", {})
        comment = data.get("comment", "")
        
        result[profile] = {
            "Commentaire": comment,
            "Actions": {},
            "ETF": {},
            "Obligations": {},
            "Crypto": {},
            "_tickers": {},  # V4.2: Bloc pour le backtest
        }
        
        # V4.4.1: Tracks pour agr√©gation ET debug
        ticker_collisions = {}
        name_collisions = {}  # NEW: Track collisions de noms aussi
        
        # V4.4.1: Dictionnaires pour agr√©gation des poids lisibles (en float)
        readable_weights = {
            "Actions": {},
            "ETF": {},
            "Obligations": {},
            "Crypto": {},
        }
        
        for asset_id, weight in allocation.items():
            asset_id_str = str(asset_id)
            info = asset_lookup.get(asset_id_str, {"name": asset_id_str, "category": "ETF", "ticker": asset_id_str})
            name = info["name"]
            ticker = info["ticker"]
            cat_v1 = _category_v1(info["category"])
            
            # V4.4.1: AGR√âGATION pour le format lisible aussi (+=)
            prev_readable = readable_weights[cat_v1].get(name, 0.0)
            readable_weights[cat_v1][name] = prev_readable + weight
            
            # Track collision de nom pour debug
            if prev_readable > 0:
                if name not in name_collisions:
                    name_collisions[name] = prev_readable
                name_collisions[name] = readable_weights[cat_v1][name]
            
            # V4.2.3: Nettoyage final du ticker_key
            ticker_key = ticker if ticker and not _is_internal_id(ticker) else name
            ticker_key = _normalize_ticker_value(ticker_key) or name
            
            # V4.2.3: AGR√âGATION avec += au lieu d'√©crasement =
            tickers_dict = result[profile]["_tickers"]
            prev_weight = tickers_dict.get(ticker_key, 0.0)
            new_weight = round(prev_weight + weight / 100.0, 4)
            tickers_dict[ticker_key] = new_weight
            
            # Track collision ticker pour debug
            if prev_weight > 0:
                if ticker_key not in ticker_collisions:
                    ticker_collisions[ticker_key] = prev_weight
                ticker_collisions[ticker_key] = new_weight
        
        # V4.4.1: Convertir les poids agr√©g√©s en strings "X%"
        for cat_v1, weights_dict in readable_weights.items():
            for name, weight in weights_dict.items():
                result[profile][cat_v1][name] = f"{int(round(weight))}%"
        
        # V4.4.1: Log les collisions si pr√©sentes
        if ticker_collisions:
            logger.info(f"   {profile}: {len(ticker_collisions)} ticker(s) agr√©g√©(s): {ticker_collisions}")
        if name_collisions:
            logger.info(f"   {profile}: {len(name_collisions)} nom(s) agr√©g√©(s): {name_collisions}")
        
        # V4.4.1: Validation am√©lior√©e - v√©rifier coh√©rence front vs _tickers
        total_tickers = sum(result[profile]["_tickers"].values())
        
        # Calculer total des sections lisibles
        total_readable = 0
        for cat_v1 in ["Actions", "ETF", "Obligations", "Crypto"]:
            for name, pct_str in result[profile][cat_v1].items():
                try:
                    pct_val = int(pct_str.replace("%", ""))
                    total_readable += pct_val
                except:
                    pass
        
        n_allocation = len(allocation)
        n_tickers = len(result[profile]["_tickers"])
        n_readable = sum(len(result[profile][c]) for c in ["Actions", "ETF", "Obligations", "Crypto"])
        
        # V4.4.1: Validation crois√©e
        if abs(total_tickers - 1.0) > 0.02:
            logger.warning(
                f"‚ö†Ô∏è {profile}: _tickers sum = {total_tickers:.2%} (expected ~100%) "
                f"‚Üí {n_allocation} lignes allocation, {n_tickers} tickers uniques"
            )
        elif abs(total_readable - 100) > 2:
            logger.warning(
                f"‚ö†Ô∏è {profile}: readable sum = {total_readable}% (expected ~100%) "
                f"‚Üí {n_readable} items lisibles"
            )
        else:
            logger.info(f"‚úÖ {profile}: _tickers={total_tickers:.2%}, readable={total_readable}% ({n_tickers} tickers, {n_readable} items)")
        
        # V4.4.1: V√©rifier coh√©rence entre les deux
        if abs(total_tickers * 100 - total_readable) > 5:
            logger.error(
                f"‚ùå {profile}: INCOH√âRENCE D√âTECT√âE! "
                f"_tickers={total_tickers:.2%} vs readable={total_readable}%"
            )
        
        # V4.2.3: Log les tickers pour debug (sans NaN)
        tickers_list = [t for t in list(result[profile]["_tickers"].keys())[:5] if t]
        logger.info(f"   {profile} _tickers sample: {tickers_list}")
    
    result["_meta"] = {
        "generated_at": datetime.datetime.now().isoformat(),
        "version": "v3.4_fix_bond_detection",
        "buffett_mode": CONFIG["buffett_mode"],
        "buffett_min_score": CONFIG["buffett_min_score"],
        "tactical_context_enabled": CONFIG.get("use_tactical_context", True),
    }
    
    return result


# ============= SAUVEGARDE =============

def save_portfolios(portfolios: Dict, assets: list):
    """Sauvegarde les portefeuilles."""
    os.makedirs("data", exist_ok=True)
    os.makedirs(CONFIG["history_dir"], exist_ok=True)
    
    # 1. Format v1 pour le front
    v1_data = normalize_to_frontend_v1(portfolios, assets)
    
    v1_path = CONFIG["output_path"]
    with open(v1_path, "w", encoding="utf-8") as f:
        json.dump(v1_data, f, ensure_ascii=False, indent=2)
    logger.info(f"‚úÖ Sauvegard√©: {v1_path}")
    
    # 2. Archive v4 compl√®te
    ts = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
    archive_path = f"{CONFIG['history_dir']}/portfolios_v4_{ts}.json"
    
    archive_data = {
        "version": "v3.4_fix_bond_detection",
        "timestamp": ts,
        "date": datetime.datetime.now().isoformat(),
        "buffett_config": {
            "mode": CONFIG["buffett_mode"],
            "min_score": CONFIG["buffett_min_score"],
        },
        "tactical_config": {
            "enabled": CONFIG.get("use_tactical_context", True),
            "data_dir": CONFIG.get("market_data_dir", "data"),
        },
        "portfolios": portfolios,
    }
    
    with open(archive_path, "w", encoding="utf-8") as f:
        json.dump(archive_data, f, ensure_ascii=False, indent=2, default=str)
    logger.info(f"‚úÖ Archive: {archive_path}")
    
    for profile in ["Agressif", "Mod√©r√©", "Stable"]:
        n_assets = len(portfolios.get(profile, {}).get("allocation", {}))
        logger.info(f"   {profile}: {n_assets} lignes")


def save_backtest_results(backtest_data: Dict):
    """Sauvegarde les r√©sultats du backtest."""
    os.makedirs("data", exist_ok=True)
    
    output_path = CONFIG["backtest_output"]
    with open(output_path, "w", encoding="utf-8") as f:
        json.dump(backtest_data, f, ensure_ascii=False, indent=2, default=str)
    logger.info(f"‚úÖ Backtest sauvegard√©: {output_path}")


# ============= MAIN =============

def main():
    """Point d'entr√©e principal."""
    logger.info("=" * 60)
    logger.info("üöÄ Portfolio Engine v3.4 - G√©n√©ration + Backtest (FIX BOND DETECTION)")
    logger.info("=" * 60)
    
    # 1. Charger le brief (optionnel)
    brief_data = load_brief_data()
    
    # 2. Construire les portefeuilles (d√©terministe + Buffett + Tactical)
    #    Le diagnostic Buffett et Tactical s'affiche ICI, avant l'optimisation
    portfolios, assets = build_portfolios_deterministic()
    
    # 3. Ajouter les commentaires (LLM ou fallback)
    portfolios = add_commentary(portfolios, assets, brief_data)
    
    # 4. Appliquer compliance AMF
    portfolios = apply_compliance(portfolios)
    
    # 5. Sauvegarder les portfolios
    save_portfolios(portfolios, assets)
    
    # 6. Backtest (si activ√©) - AVEC POIDS FIXES
    backtest_results = None
    if CONFIG["run_backtest"]:
        yaml_config = load_yaml_config(CONFIG["config_path"])
        backtest_results = run_backtest_all_profiles(yaml_config)
        
        if not backtest_results.get("skipped"):
            save_backtest_results(backtest_results)
    
    # 7. R√©sum√© final
    logger.info("\n" + "=" * 60)
    logger.info("‚ú® G√©n√©ration termin√©e avec succ√®s!")
    logger.info("=" * 60)
    logger.info("Fichiers g√©n√©r√©s:")
    logger.info(f"   ‚Ä¢ {CONFIG['output_path']} (portfolios)")
    if backtest_results and not backtest_results.get("skipped"):
        logger.info(f"   ‚Ä¢ {CONFIG['backtest_output']} (backtest)")
    logger.info("")
    logger.info("Fonctionnalit√©s v3.4:")
    logger.info("   ‚Ä¢ Poids d√©terministes (Python, pas LLM)")
    logger.info("   ‚Ä¢ Prompt LLM r√©duit ~1500 tokens")
    logger.info("   ‚Ä¢ Compliance AMF automatique")
    logger.info("   ‚Ä¢ Backtest 90j avec POIDS FIXES ‚úÖ")
    logger.info("   ‚Ä¢ Export _tickers - FIX NaN + agr√©gation ‚úÖ")
    logger.info("   ‚Ä¢ üÜï FIX BOND DETECTION: fund_type='bond' forc√© pour combined_bonds.csv ‚úÖ")
    logger.info("   ‚Ä¢ MARKET CONTEXT UNIFI√â: market_context.json (GPT) ‚úÖ")
    logger.info("   ‚Ä¢ Reproductibilit√© garantie")
    logger.info(f"   ‚Ä¢ Filtre Buffett: mode={CONFIG['buffett_mode']}, score_min={CONFIG['buffett_min_score']}")
    logger.info(f"   ‚Ä¢ Contexte tactique: {'‚úÖ activ√©' if CONFIG.get('use_tactical_context') else '‚ùå d√©sactiv√©'}")


if __name__ == "__main__":
    main()
