"""
Module d'entra√Ænement du mod√®le d'impact d'actualit√©s financi√®res

Ce module permet de cr√©er et d'entra√Æner un mod√®le sp√©cifique pour
pr√©dire l'impact des actualit√©s financi√®res, en utilisant les
corrections des utilisateurs.
"""

import os
import json
import torch
import numpy as np
from datetime import datetime
from sklearn.model_selection import train_test_split
from transformers import AutoTokenizer, AutoModelForSequenceClassification
from transformers import TrainingArguments, Trainer, DataCollatorWithPadding
from datasets import Dataset

# Import du gestionnaire de base de donn√©es pour les corrections
from db_manager import export_training_data

# Chemins des r√©pertoires
BASE_DIR = os.path.dirname(__file__)
MODELS_DIR = os.path.join(BASE_DIR, "models")
IMPACT_MODEL_DIR = os.path.join(MODELS_DIR, "impact_model")
TRAINING_LOGS_DIR = os.path.join(BASE_DIR, "logs")

# S'assurer que les r√©pertoires existent
for directory in [MODELS_DIR, IMPACT_MODEL_DIR, TRAINING_LOGS_DIR]:
    os.makedirs(directory, exist_ok=True)

# Configuration de l'entra√Ænement
DEFAULT_TRAINING_CONFIG = {
    "batch_size": 8,
    "learning_rate": 5e-5,
    "epochs": 3,
    "warmup_steps": 100,
    "weight_decay": 0.01,
    "evaluation_strategy": "epoch",
    "save_steps": 500,
    "min_correction_entries": 20,  # Nombre minimum de corrections pour r√©entra√Æner
}

class ImpactModel:
    """Classe pour cr√©er et entra√Æner le mod√®le d'impact des actualit√©s"""
    
    def __init__(self, config=None):
        """
        Initialise le mod√®le d'impact
        
        Args:
            config (dict, optional): Configuration d'entra√Ænement
        """
        self.config = config or DEFAULT_TRAINING_CONFIG
        self.tokenizer = None
        self.model = None
        self.impact_mapping = {
            "high": 0,
            "positive": 1,
            "slightly_positive": 2,
            "neutral": 3,
            "slightly_negative": 4,
            "negative": 5
        }
        self.reverse_mapping = {v: k for k, v in self.impact_mapping.items()}
        
        # Essayer de charger un mod√®le existant
        self._load_model()
    
    def _load_model(self):
        """Charge un mod√®le d'impact existant"""
        try:
            if os.path.exists(IMPACT_MODEL_DIR) and os.listdir(IMPACT_MODEL_DIR):
                self.tokenizer = AutoTokenizer.from_pretrained(IMPACT_MODEL_DIR)
                self.model = AutoModelForSequenceClassification.from_pretrained(IMPACT_MODEL_DIR)
                print(f"‚úÖ Mod√®le d'impact charg√© depuis {IMPACT_MODEL_DIR}")
                return True
            else:
                print("‚ö†Ô∏è Aucun mod√®le d'impact existant trouv√©.")
                return False
        except Exception as e:
            print(f"‚ùå Erreur lors du chargement du mod√®le d'impact: {e}")
            return False
    
    def _prepare_data(self):
        """
        Pr√©pare les donn√©es pour l'entra√Ænement en utilisant les corrections utilisateur
        
        Returns:
            tuple: (textes, √©tiquettes) ou (None, None) en cas d'√©chec
        """
        try:
            # Exporter les donn√©es d'entra√Ænement
            success, file_path = export_training_data()
            
            if not success:
                print("‚ö†Ô∏è Impossible d'exporter les donn√©es d'entra√Ænement")
                return None, None
            
            # Charger les donn√©es d'entra√Ænement
            with open(file_path, 'r', encoding='utf-8') as f:
                training_data = json.load(f)
            
            # V√©rifier si nous avons suffisamment de donn√©es pour l'impact
            if len(training_data["impact"]) < self.config["min_correction_entries"]:
                print(f"‚ö†Ô∏è Pas assez de donn√©es pour entra√Æner le mod√®le d'impact ({len(training_data['impact'])} < {self.config['min_correction_entries']})")
                return None, None
            
            # Extraire les textes et les √©tiquettes
            texts = [item["text"] for item in training_data["impact"]]
            labels = [self.impact_mapping.get(item["label"], self.impact_mapping["neutral"]) for item in training_data["impact"]]
            
            print(f"‚úÖ Donn√©es pr√©par√©es: {len(texts)} exemples")
            return texts, labels
        except Exception as e:
            print(f"‚ùå Erreur lors de la pr√©paration des donn√©es: {e}")
            return None, None
    
    def _initialize_base_model(self):
        """Initialise un mod√®le de base pour la classification d'impact"""
        try:
            # Utiliser BERT fran√ßais ou CamemBERT
            model_name = "camembert-base"  # Vous pouvez aussi utiliser "bert-base-multilingual-cased"
            
            self.tokenizer = AutoTokenizer.from_pretrained(model_name)
            self.model = AutoModelForSequenceClassification.from_pretrained(
                model_name,
                num_labels=len(self.impact_mapping)
            )
            
            print(f"‚úÖ Mod√®le de base initialis√© avec {model_name}")
            return True
        except Exception as e:
            print(f"‚ùå Erreur lors de l'initialisation du mod√®le de base: {e}")
            return False
    
    def train(self):
        """
        Entra√Æne le mod√®le sur les donn√©es de correction
        
        Returns:
            bool: Succ√®s de l'op√©ration
        """
        # Pr√©parer les donn√©es
        texts, labels = self._prepare_data()
        if texts is None or not texts:
            print("‚ùå Impossible de cr√©er un mod√®le sans donn√©es d'entra√Ænement.")
            return False
        
        # Diviser en ensembles d'entra√Ænement et de validation
        train_texts, val_texts, train_labels, val_labels = train_test_split(
            texts, labels, test_size=0.2, random_state=42, stratify=labels
        )
        
        # Utiliser le mod√®le existant ou initialiser un nouveau
        if self.model is None or self.tokenizer is None:
            success = self._initialize_base_model()
            if not success:
                print("‚ùå √âchec de l'initialisation du mod√®le de base.")
                return False
        
        # Fonction de tokenisation
        def tokenize_function(examples):
            return self.tokenizer(examples["text"], truncation=True, padding="max_length", max_length=512)
        
        # Cr√©er les datasets
        train_dataset = Dataset.from_dict({
            "text": train_texts,
            "label": train_labels
        })
        val_dataset = Dataset.from_dict({
            "text": val_texts,
            "label": val_labels
        })
        
        # Tokeniser
        train_dataset = train_dataset.map(tokenize_function, batched=True)
        val_dataset = val_dataset.map(tokenize_function, batched=True)
        
        # Collateur de donn√©es
        data_collator = DataCollatorWithPadding(tokenizer=self.tokenizer)
        
        # Timestamp pour cette version du mod√®le
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        output_dir = os.path.join(TRAINING_LOGS_DIR, f"impact_model_{timestamp}")
        
        # Configuration de l'entra√Ænement
        training_args = TrainingArguments(
            output_dir=output_dir,
            num_train_epochs=self.config["epochs"],
            per_device_train_batch_size=self.config["batch_size"],
            per_device_eval_batch_size=self.config["batch_size"],
            warmup_steps=self.config["warmup_steps"],
            weight_decay=self.config["weight_decay"],
            learning_rate=self.config["learning_rate"],
            evaluation_strategy=self.config["evaluation_strategy"],
            save_steps=self.config["save_steps"],
            load_best_model_at_end=True,
            logging_dir=os.path.join(TRAINING_LOGS_DIR, "logs"),
        )
        
        # Cr√©er le trainer
        trainer = Trainer(
            model=self.model,
            args=training_args,
            train_dataset=train_dataset,
            eval_dataset=val_dataset,
            tokenizer=self.tokenizer,
            data_collator=data_collator,
        )
        
        # Entra√Æner le mod√®le
        try:
            print("üöÄ D√©but de l'entra√Ænement du mod√®le d'impact...")
            trainer.train()
            
            # √âvaluer
            eval_results = trainer.evaluate()
            print(f"üìä R√©sultats de l'√©valuation: {eval_results}")
            
            # Sauvegarder le mod√®le
            self.model.save_pretrained(IMPACT_MODEL_DIR)
            self.tokenizer.save_pretrained(IMPACT_MODEL_DIR)
            
            # Sauvegarder les m√©tadonn√©es
            metadata = {
                "timestamp": timestamp,
                "eval_results": eval_results,
                "config": self.config,
                "num_examples": len(texts),
                "train_test_split": {
                    "train": len(train_texts),
                    "val": len(val_texts)
                },
                "impact_mapping": self.impact_mapping
            }
            
            with open(os.path.join(IMPACT_MODEL_DIR, "metadata.json"), 'w', encoding='utf-8') as f:
                json.dump(metadata, f, ensure_ascii=False, indent=2)
            
            print(f"‚úÖ Mod√®le d'impact entra√Æn√© et sauvegard√© dans {IMPACT_MODEL_DIR}")
            return True
        except Exception as e:
            print(f"‚ùå Erreur lors de l'entra√Ænement du mod√®le: {e}")
            import traceback
            traceback.print_exc()
            return False
    
    def predict(self, text):
        """
        Pr√©dit l'impact d'un texte
        
        Args:
            text (str): Texte √† classifier
            
        Returns:
            dict: R√©sultat de la pr√©diction avec label et score
        """
        if not self.model or not self.tokenizer:
            print("‚ö†Ô∏è Mod√®le non initialis√©. Impossible de faire une pr√©diction.")
            return {"label": "neutral", "score": 0.5}
        
        try:
            # Tokeniser le texte
            inputs = self.tokenizer(text, return_tensors="pt", truncation=True, padding=True)
            
            # Pr√©dire
            with torch.no_grad():
                outputs = self.model(**inputs)
                logits = outputs.logits
            
            # Obtenir la classe pr√©dite et le score
            probabilities = torch.nn.functional.softmax(logits, dim=1)[0]
            predicted_class = torch.argmax(probabilities).item()
            confidence = probabilities[predicted_class].item()
            
            # Convertir en label
            label = self.reverse_mapping.get(predicted_class, "neutral")
            
            return {
                "label": label,
                "score": confidence
            }
        except Exception as e:
            print(f"‚ùå Erreur lors de la pr√©diction: {e}")
            return {"label": "neutral", "score": 0.5}

def train_impact_model():
    """
    Fonction d'utilit√© pour entra√Æner le mod√®le d'impact
    
    Returns:
        bool: Succ√®s de l'op√©ration
    """
    model = ImpactModel()
    return model.train()

# Pour un test rapide
if __name__ == "__main__":
    success = train_impact_model()
    
    if success:
        # Tester le mod√®le
        model = ImpactModel()
        
        test_texts = [
            "Le march√© boursier s'effondre suite √† la hausse des taux d'int√©r√™t",
            "Les r√©sultats trimestriels d'Apple d√©passent les attentes",
            "La Fed maintient ses taux directeurs",
            "Crash √©conomique en vue selon les analystes"
        ]
        
        print("\nTests de pr√©diction:")
        for text in test_texts:
            prediction = model.predict(text)
            print(f"Texte: {text}")
            print(f"Pr√©diction: {prediction['label']} (score: {prediction['score']:.4f})")
            print("")
    else:
        print("‚ùå √âchec de l'entra√Ænement du mod√®le d'impact.")
