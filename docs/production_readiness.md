# üîç Production Readiness Audit v2.0 - Stock Analysis Platform

**Version:** 2.0.0  
**Date:** 2025-12-15  
**Reviewer:** Claude + ChatGPT cross-audit  
**Statut global:** ‚ö†Ô∏è **EN PROGR√àS** (19/29 crit√®res satisfaits = 66%)  
**Prochaine revue:** Apr√®s correction P0 technique

---

## üìä Tableau de Synth√®se v2.0

| Section | Score | Points forts | Lacunes critiques |
|---------|-------|--------------|-------------------|
| A. Data lineage & repro | 5/8 (63%) | Manifest, Schema, Limitations | Mode DETERMINISTIC, test 20 runs |
| B. Calendrier & qualit√© | 6/7 (86%) | calendar.py, data_quality.py | Test split connu |
| C. Contraintes & optim | 5/5 (100%) | constraints.py complet | ‚úÖ Tous satisfaits |
| D. Backtest & m√©triques | 3/5 (60%) | Sharpe masqu√©, benchmarks | Modes R&D, net/gross |
| E. Observabilit√© | 0/4 (0%) | - | SLO, drift, golden, logs |

**Score global: 19/29 (66%)**

---

## ‚ö†Ô∏è INCOH√âRENCES FACTUELLES CORRIG√âES

| Fichier | Probl√®me signal√© | Statut r√©el |
|---------|------------------|-------------|
| `backtest/data_loader.py` | "fait encore ffill()" | ‚ùå **FAUX** - v10 utilise `align_to_reference_calendar()` ou `dropna()` |
| `backtest/engine.py:130` | "Yahoo Finance" hardcod√© | ‚úÖ **VRAI** - √Ä CORRIGER (5 min) |
| `optimizer.py` | "fallback_heuristic narratif" | ‚úÖ **OK** - `_optimization` block expos√© |

---

## A. DATA LINEAGE & REPRODUCTIBILIT√â (8 questions)

### Q1. Manifest complet par run ?

**Statut:** ‚úÖ OUI  
**Fichier:** `portfolio_engine/manifest.py`  
**Preuve:**

```python
# ManifestBuilder.to_dict() retourne:
{
    "git_sha": "abc123...",
    "git_branch": "main",
    "module_versions": {"numpy": "1.26.0", "portfolio_engine": "v6.13"},
    "data_sources": {"stocks_us": {"path": "...", "hash": "sha256:...", "rows": 150}},
    "execution": {"start_time": "...", "end_time": "...", "duration_ms": 4500},
    "errors": [],
    "warnings": []
}
```

**Manque:** Test CI v√©rifiant la pr√©sence du manifest dans l'output.

---

### Q2. Sch√©ma JSON versionn√© et valid√© ?

**Statut:** ‚úÖ OUI (d√©fini, pas valid√© en CI)  
**Fichier:** `portfolio_engine/data_lineage.py`  
**Preuve:**

```python
SCHEMA = {
    "version": "2.0.0",
    "min_compatible_version": "1.5.0",
    "breaking_changes": [
        {"version": "2.0.0", "change": "Added _optimization block", "date": "2025-12-15"},
        {"version": "1.5.0", "change": "Added _compliance_audit", "date": "2025-12-10"},
    ],
    "required_fields": ["_meta", "_schema", "Agressif", "Mod√©r√©", "Stable"],
}
```

**Manque:** Validation jsonschema/pydantic en CI + migration automatique.

---

### Q3. Rerun "√† l'identique" offline ?

**Statut:** ‚ùå NON  
**Preuve:** Pas de mode `DETERMINISTIC` avec cache prix.  
`data_loader.py` appelle toujours TwelveData API live.

**Action requise:**
```yaml
# config/deterministic.yaml (√Ä CR√âER)
deterministic_mode:
  enabled: false
  freeze_timestamp: "2025-12-15T00:00:00Z"
  use_cached_prices: true
  cache_path: "data/cache/prices_20251215.parquet"
```

---

### Q4. Tris totalement stables (tie-breaker) ?

**Statut:** ‚ö†Ô∏è PARTIEL  
**Fichier:** `portfolio_engine/optimizer.py`  
**Preuve:**

```python
sorted_assets = sorted(universe, key=lambda x: x.score, reverse=True)
# ‚ö†Ô∏è Pas de tie-breaker par ID en cas d'√©galit√©
```

**Action:** Ajouter `key=lambda x: (x.score, x.id)` (~10 min).

---

### Q5. Data_source unique import√© partout ?

**Statut:** ‚ö†Ô∏è PRESQUE (1 fichier √† corriger)  
**Fichiers OK:**
- `portfolio_engine/data_lineage.py` ‚Üí `get_data_source_string()` ‚úÖ
- `backtest/data_loader.py` ‚Üí importe `get_data_source_string()` ‚úÖ

**Fichier √† corriger:**
- `backtest/engine.py:130` ‚Üí `"data_source": "Yahoo Finance (adjusted close)"` ‚ùå

**Correction (5 min):**
```python
# engine.py - Remplacer ligne 130
from portfolio_engine.data_lineage import get_data_source_string
# ...
"data_source": get_data_source_string(),  # Au lieu de "Yahoo Finance..."
```

---

### Q6. Look-ahead + limitations expos√©s ?

**Statut:** ‚úÖ OUI  
**Fichier:** `portfolio_engine/data_lineage.py`  
**Preuve:**

```python
LIMITATIONS = {
    "survivorship_bias": {
        "present": True,
        "description": "L'univers ne contient que les actifs actuellement list√©s.",
        "impact": "Biais positif potentiel sur les performances historiques.",
        "mitigation": "Utiliser avec prudence pour analyse historique > 1 an."
    },
    "point_in_time": {
        "compliant": False,
        "description": "Les fondamentaux ne sont pas point-in-time. Look-ahead bias possible.",
    },
    "backfill_bias": {"present": True},
    "fx_handling": {"method": "USD_only"},
    "costs": {"included": ["transaction_cost_10bp"], "excluded": ["slippage", "taxes"]},
}

def get_limitations_for_output():
    return {
        "survivorship_free": False,
        "pit_fundamentals": False,
        "adjusted_prices": True,
        "costs_included": True,
        "base_currency": "USD",
    }
```

---

### Q7. Test reproductibilit√© 20 runs ?

**Statut:** ‚ùå NON  
**Pas de test CI automatis√©.**

**Action requise:**
```python
# tests/test_reproducibility.py (√Ä CR√âER)
def test_20_runs_identical():
    results = [generate_portfolios() for _ in range(20)]
    weights_agressif = [r["Agressif"]["_tickers"] for r in results]
    
    for i in range(1, 20):
        for ticker, weight in weights_agressif[0].items():
            assert abs(weights_agressif[i].get(ticker, 0) - weight) < 0.01
```

---

### Q8. Matrice compatibilit√© versions ?

**Statut:** ‚ö†Ô∏è PARTIEL  
**Fichier:** `SCHEMA["min_compatible_version"]` d√©fini  
**Manque:** Tests automatis√©s de compatibilit√© sch√©ma ‚Üî front.

---

## B. CALENDRIER & DATA QUALITY (7 questions)

### Q9. Alignement sans ffill() ?

**Statut:** ‚úÖ OUI  
**Fichier:** `portfolio_engine/calendar.py`  
**Preuve:**

```python
def align_to_reference_calendar(
    prices_df: pd.DataFrame,
    reference_calendar: str = "NYSE",
    max_nan_pct: float = 0.05,
    interpolation_method: Optional[str] = None,  # None = pas d'interpolation
) -> Tuple[pd.DataFrame, CalendarAlignmentReport]:
    """
    ‚ö†Ô∏è IMPORTANT: Cette fonction n'utilise JAMAIS ffill() sur les prix.
    Les NaN sont soit:
    - Exclus (jours supprim√©s)
    - Interpol√©s lin√©airement (document√©)
    - Cause d'exclusion du symbole (si > max_nan_pct)
    """
    # ... reindex sur ref_calendar ...
    aligned_df = aligned_df.dropna(how='any')  # PAS de ffill
    return aligned_df, report
```

**data_loader.py v10:**
```python
if align_calendar and HAS_CALENDAR:
    prices_df, cal_report = align_to_reference_calendar(...)
elif not HAS_CALENDAR:
    # FALLBACK SAFE: dropna au lieu de ffill
    prices_df = prices_df.dropna(how='any')
```

**Validation anti-ffill:**
```python
def validate_no_ffill_contamination(prices_df, max_consecutive_same=5):
    """D√©tecte les ffill cach√©s (prix identiques cons√©cutifs)."""
    suspects = []
    for symbol in prices_df.columns:
        # ... d√©tection s√©quences identiques ...
    return suspects
```

---

### Q10. Seuils de rejet data ?

**Statut:** ‚úÖ OUI  
**Fichier:** `portfolio_engine/data_quality.py`  
**Preuve:**

```python
@dataclass
class DataQualityThresholds:
    max_nan_pct: float = 0.05           # 5% max NaN
    max_nan_consecutive: int = 5        # Max 5 NaN cons√©cutifs
    min_price: float = 0.01             # Prix minimum
    max_daily_return: float = 0.50      # 50% max return journalier
    min_daily_return: float = -0.50     # -50% min
    min_history_days: int = 60          # 60 jours minimum
    max_stale_days: int = 3             # Max 3 jours de retard

class DataQualityChecker:
    def check(self, prices_df) -> DataQualityReport:
        # Retourne rejected_symbols, rejection_reasons, issues
```

---

### Q11. Delisting/survivorship document√©s ?

**Statut:** ‚úÖ OUI  
**Fichier:** `portfolio_engine/data_lineage.py` - voir Q6

---

### Q12. Tests corporate actions (split) ?

**Statut:** ‚ùå NON  
**Pas de test unitaire sur un split connu (ex: TSLA 3:1 ao√ªt 2022).**

**Action requise:**
```python
# tests/test_splits.py (√Ä CR√âER)
def test_tsla_split_august_2022():
    """V√©rifie que le split TSLA 3:1 est correctement g√©r√©."""
    prices = load_prices("TSLA", "2022-08-01", "2022-09-01")
    # Le prix pr√©-split doit √™tre ajust√©
    assert prices.loc["2022-08-24"] < prices.loc["2022-08-25"] * 1.5
```

---

### Q13. FX / base_currency explicit√©s ?

**Statut:** ‚úÖ OUI  
**Fichier:** `portfolio_engine/data_lineage.py`

```python
METHODOLOGY["prices"]["currency"] = "USD"
METHODOLOGY["risk_metrics"]["base_currency"] = "USD"
METHODOLOGY["risk_metrics"]["risk_free_rate_source"] = "US Fed Funds Rate"
METHODOLOGY["risk_metrics"]["risk_free_rate_value"] = 0.045  # 4.5%

LIMITATIONS["fx_handling"] = {
    "method": "USD_only",
    "description": "Tous les actifs convertis en USD. Pas de hedging FX."
}
```

---

### Q14. Universe coverage stats ?

**Statut:** ‚úÖ OUI  
**Fichier:** `portfolio_engine/data_quality.py`

```python
@dataclass
class UniverseCoverageReport:
    total_requested: int
    total_resolved: int
    total_with_data: int
    coverage_pct: float
    rejected_no_ticker: List[str]
    rejected_no_data: List[str]
    rejected_quality: List[str]
```

---

### Q15. Data freshness SLA ?

**Statut:** ‚úÖ OUI  
**Fichier:** `portfolio_engine/data_quality.py`

```python
def check_data_freshness(prices_df, max_stale_days=3) -> Tuple[bool, Dict]:
    """V√©rifie que les donn√©es sont fra√Æches."""
    last_date = prices_df.index.max()
    stale_days = (expected_date - last_date.date()).days
    is_fresh = stale_days <= max_stale_days
    return is_fresh, {"stale_days": stale_days, "is_fresh": is_fresh}
```

---

## C. CONTRAINTES & OPTIMISATION (5 questions)

### Q16. Constraint report apr√®s TOUTES transformations ?

**Statut:** ‚úÖ OUI  
**Fichier:** `portfolio_engine/constraints.py`  
**Preuve:**

```python
def verify_constraints_post_arrondi(
    allocation: Dict[str, float],
    assets_metadata: Dict[str, Dict],
    profile_constraints: Dict[str, Any],
    profile_name: str,
) -> ConstraintReport:
    """V√©rifie TOUTES les contraintes APR√àS arrondi/adjust_to_100."""
    violations = []
    
    # 1. SOMME = 100% (HARD)
    # 2. POIDS POSITIFS (HARD)
    # 3. MAX SINGLE POSITION (HARD)
    # 4. BONDS MINIMUM (HARD)
    # 5. CRYPTO MAXIMUM (HARD)
    # 6. MAX SINGLE BOND (HARD)
    # 7. NOMBRE D'ACTIFS (SOFT)
    # 8. BUCKET TARGETS (RELAXABLE)
    
    return ConstraintReport(
        all_hard_satisfied=len(hard_violations) == 0,
        violations=violations,
        margins=margins,
        relaxed_constraints=relaxed,
    )
```

---

### Q17. Repair respecte tous les caps ?

**Statut:** ‚úÖ OUI  
**Fichier:** `portfolio_engine/optimizer.py:_fallback_allocation()`  
Applique `max_single_bond`, `max_single_position` explicitement.

---

### Q18. Test faisabilit√© ex-ante ?

**Statut:** ‚úÖ OUI  
**Fichier:** `portfolio_engine/constraints.py`

```python
def check_feasibility(
    candidates: List[Dict],
    profile_constraints: Dict[str, Any],
    profile_name: str,
) -> FeasibilityReport:
    """V√©rifie si les contraintes sont satisfiables AVANT optimisation."""
    # V√©rifie: bonds_capacity, n_candidates, vol_atteignable
    
    if bonds_capacity < bonds_required:
        return FeasibilityReport(
            feasible=False,
            reason=f"Bonds capacity {bonds_capacity:.0f}% < required {bonds_required:.0f}%"
        )
    
    return FeasibilityReport(feasible=True, capacity=capacity, requirements=requirements)
```

---

### Q19. Hi√©rarchie formalis√©e HARD/SOFT/RELAXABLE ?

**Statut:** ‚úÖ OUI  
**Fichier:** `portfolio_engine/constraints.py`

```python
class ConstraintPriority(Enum):
    HARD = "hard"           # Violation = erreur/blocage
    SOFT = "soft"           # Violation = p√©nalit√©
    RELAXABLE = "relaxable" # Peut √™tre rel√¢ch√©e (document√©)

CONSTRAINT_REGISTRY: Dict[str, ConstraintDefinition] = {
    "sum_100": ConstraintDefinition(priority=ConstraintPriority.HARD, ...),
    "bounds_positive": ConstraintDefinition(priority=ConstraintPriority.HARD, ...),
    "max_single_position": ConstraintDefinition(priority=ConstraintPriority.HARD, ...),
    "bonds_min": ConstraintDefinition(priority=ConstraintPriority.HARD, ...),
    "crypto_max": ConstraintDefinition(priority=ConstraintPriority.HARD, ...),
    "vol_target": ConstraintDefinition(priority=ConstraintPriority.SOFT, ...),
    "bucket_core": ConstraintDefinition(priority=ConstraintPriority.RELAXABLE, tolerance=5.0),
    "bucket_defensive": ConstraintDefinition(priority=ConstraintPriority.RELAXABLE, tolerance=8.0),
}
```

---

### Q20. Stable heuristic document√© c√¥t√© sortie ?

**Statut:** ‚úÖ OUI  
**Output JSON:**

```json
"_optimization": {
    "mode": "fallback_heuristic",
    "is_heuristic": true,
    "disclaimer": "Ce portefeuille utilise une allocation heuristique bas√©e sur des r√®gles. Les poids sont d√©terministes mais ne r√©sultent pas d'une optimisation math√©matique."
}
```

---

## D. BACKTEST & M√âTRIQUES (5 questions)

### Q21. Co√ªts inclus/exclus coh√©rents ?

**Statut:** ‚ö†Ô∏è PARTIEL  
**data_lineage.py:**
```python
METHODOLOGY["backtest"]["costs_included"] = True
METHODOLOGY["backtest"]["transaction_cost_bp"] = 10
LIMITATIONS["costs"]["excluded"] = ["slippage", "market_impact", "taxes"]
```

**engine.py:** `transaction_cost_bp=10` utilis√©  
**Manque:** Champ `gross_return` vs `net_return` dans stats.

---

### Q22. Mode R&D vs illustratif s√©par√©s ?

**Statut:** ‚ö†Ô∏è D√âFINI mais pas impl√©ment√©  
**data_lineage.py:**
```python
METHODOLOGY["backtest"]["default_period_days"] = 90   # illustratif
METHODOLOGY["backtest"]["research_period_days"] = 1825  # 5 ans
```

**R√©alit√©:** Un seul mode backtest en prod.

---

### Q23. Turnover + costs + net/gross ?

**Statut:** ‚ö†Ô∏è PARTIEL  
**engine.py stats existantes:**
```python
stats["turnover_annualized_pct"] = ...
stats["avg_turnover_per_rebal"] = ...
```

**Manque:** `gross_return_pct`, `net_return_pct` explicites.

---

### Q24. Sharpe masqu√© < 252j, "winner" interdit ?

**Statut:** ‚úÖ OUI  
**engine.py v4:**
```python
MIN_DAYS_FOR_STATS = 252

if n_days < MIN_DAYS_FOR_STATS:
    stats["sharpe_ratio"] = None  # Masqu√©
    stats["sharpe_display"] = "Non calculable (p√©riode < 1 an)"
    stats["sharpe_significant"] = False
```

**LLM sanitizer:** Patterns "gagnant", "meilleur", "winner", "id√©al" d√©tect√©s et supprim√©s.

---

### Q25. Benchmarks coh√©rents par profil ?

**Statut:** ‚úÖ OUI  
**data_lineage.py:**
```python
METHODOLOGY["benchmarks"] = {
    "Agressif": {"symbol": "QQQ", "name": "Nasdaq-100 ETF"},
    "Mod√©r√©": {"symbol": "URTH", "name": "MSCI World ETF"},
    "Stable": {"symbol": "AGG", "name": "US Aggregate Bond ETF"},
}
```

---

## E. OBSERVABILIT√â (4 questions)

### Q26. SLO d√©finis et mesur√©s ?

**Statut:** ‚ùå NON  
**Pas de fichier `slo.yaml` ni monitoring.**

**Action requise:**
```yaml
# config/slo.yaml (√Ä CR√âER)
slo:
  generation:
    max_duration_seconds: 60
    success_rate_target: 0.99
  fallback:
    max_rate: 0.10
  constraints:
    violation_rate: 0.0
```

---

### Q27. Drift detection ?

**Statut:** ‚ùå NON  
**Pas de `monitoring/drift.py`.**

---

### Q28. Golden tests (fixtures gel√©es + invariants) ?

**Statut:** ‚ùå NON  
**Pas de `tests/test_golden.py` ni fixtures gel√©es.**

**Note ChatGPT:** "Golden snapshots exacts = anti-pattern sans dataset gel√©."  
**Solution:** Tester des *invariants* (n_assets, sum=100%, bonds_min) plut√¥t que des poids exacts.

---

### Q29. Logs structur√©s JSON + correlation_id ?

**Statut:** ‚ùå NON  
**Logs via `logging` standard, pas de correlation_id par run.**

---

## üî¥ P0 TECHNIQUE (√Ä corriger imm√©diatement)

| # | Action | Fichier | Effort | Impact |
|---|--------|---------|--------|--------|
| 1 | Corriger "Yahoo Finance" ‚Üí `get_data_source_string()` | `backtest/engine.py:130` | 5 min | Lineage coh√©rent |
| 2 | Ajouter tie-breaker `(score, id)` | `portfolio_engine/optimizer.py` | 10 min | D√©terminisme total |
| 3 | V√©rifier que `verify_constraints_post_arrondi()` est APPEL√â | `generate_portfolios_v4.py` | 30 min | Contrat contraintes |

---

## üìã CHECKLIST v2.0

```
=== A. DATA LINEAGE & REPRO (5/8) ===
[x] Q1  Manifest complet par run                 ‚úÖ manifest.py
[x] Q2  Sch√©ma JSON versionn√©                    ‚úÖ data_lineage.py
[ ] Q3  Mode DETERMINISTIC offline               ‚ùå √Ä cr√©er
[~] Q4  Tris totalement stables                  ‚ö†Ô∏è Manque tie-breaker
[~] Q5  Data_source unique partout               ‚ö†Ô∏è engine.py √† corriger
[x] Q6  Limitations expos√©es                     ‚úÖ data_lineage.py
[ ] Q7  Test 20 runs reproductibilit√©            ‚ùå √Ä cr√©er
[~] Q8  Matrice compatibilit√©                    ‚ö†Ô∏è Partiel

=== B. CALENDRIER & QUALIT√â (6/7) ===
[x] Q9  Alignement sans ffill()                  ‚úÖ calendar.py
[x] Q10 Seuils de rejet data                     ‚úÖ data_quality.py
[x] Q11 Survivorship document√©                   ‚úÖ data_lineage.py
[ ] Q12 Test split connu                         ‚ùå √Ä cr√©er
[x] Q13 FX/currency explicit√©s                   ‚úÖ data_lineage.py
[x] Q14 Universe coverage stats                  ‚úÖ data_quality.py
[x] Q15 Data freshness SLA                       ‚úÖ data_quality.py

=== C. CONTRAINTES & OPTIM (5/5) ===
[x] Q16 Constraint report post-arrondi           ‚úÖ constraints.py
[x] Q17 Repair respecte caps                     ‚úÖ optimizer.py
[x] Q18 Test faisabilit√© ex-ante                 ‚úÖ constraints.py
[x] Q19 Hi√©rarchie HARD/SOFT/RELAXABLE           ‚úÖ constraints.py
[x] Q20 Heuristic document√©                      ‚úÖ _optimization block

=== D. BACKTEST & M√âTRIQUES (3/5) ===
[~] Q21 Co√ªts coh√©rents                          ‚ö†Ô∏è Manque net/gross
[~] Q22 Mode R&D vs illustratif                  ‚ö†Ô∏è D√©fini pas impl√©ment√©
[~] Q23 Turnover + net/gross                     ‚ö†Ô∏è Partiel
[x] Q24 Sharpe masqu√© <252j                      ‚úÖ engine.py v4
[x] Q25 Benchmarks par profil                    ‚úÖ data_lineage.py

=== E. OBSERVABILIT√â (0/4) ===
[ ] Q26 SLO d√©finis                              ‚ùå √Ä cr√©er
[ ] Q27 Drift detection                          ‚ùå √Ä cr√©er
[ ] Q28 Golden tests                             ‚ùå √Ä cr√©er
[ ] Q29 Logs structur√©s + correlation_id         ‚ùå √Ä cr√©er
```

**Score: 19/29 (66%)**

---

## üö¶ Verdict v2.0

| Crit√®re | Statut | Blockers |
|---------|--------|----------|
| **Pr√™t MVP interne** | ‚úÖ Oui | - |
| **Pr√™t beta priv√©e** | ‚úÖ Oui | - |
| **Pr√™t B2C payant** | ‚ö†Ô∏è Presque | P0 technique (45 min) |
| **Pr√™t audit r√©gulateur** | ‚ùå Non | E. Observabilit√© manquant |

---

## üìÅ Modules cr√©√©s depuis v1.0

| Module | R√©pond √† | Lignes |
|--------|----------|--------|
| `portfolio_engine/data_lineage.py` | Q2, Q5, Q6, Q13, Q25 | ~180 |
| `portfolio_engine/calendar.py` | Q9 | ~250 |
| `portfolio_engine/data_quality.py` | Q10, Q14, Q15 | ~300 |
| `portfolio_engine/constraints.py` | Q16, Q17, Q18, Q19 | ~400 |
| `portfolio_engine/manifest.py` | Q1 | ~250 |
| `backtest/data_loader.py` v10 | Q9 (int√©gration) | +50 |

**Total ajout√©:** ~1,430 lignes de code production-grade.

---

## üí° Contre-arguments ChatGPT - R√©ponses

### 1. "Golden snapshots = anti-pattern sans dataset gel√©"
**Accord.** Solution = tester des **invariants** plut√¥t que des poids exacts:
- `n_assets >= min_assets`
- `sum(weights) == 100%`
- `bonds_pct >= bonds_min`
- `max(weight) <= max_single_position`

### 2. "Sanitizer LLM ‚â† conformit√©"
**Correct, mais on a:**
- Double barri√®re (add_commentary + sanitize_portfolio_output)
- Fallback si >50% supprim√©
- Audit trail dans `_compliance_audit`

**Manque:** Contr√¥le de *structure* ("vous devriez" sans mots interdits).

### 3. "Perfection institutionnelle = ralentissement"
**Accord.** Focus sur:
1. ‚úÖ Contrat de sortie stable (SCHEMA versionn√©)
2. ‚úÖ Trace compl√®te (manifest)
3. ‚úÖ Garde-fous data (DataQualityChecker)
4. ‚ùå Monitoring (P2)

Le reste (Ledoit-Wolf, DV01) = nice-to-have pour v2.

---

## üìÜ Plan d'action

### Imm√©diat (45 min)
1. ~~`engine.py:130`~~ ‚Üí `get_data_source_string()`
2. ~~`optimizer.py`~~ ‚Üí tie-breaker `(score, id)`
3. ~~`generate_portfolios_v4.py`~~ ‚Üí appeler `verify_constraints_post_arrondi()`

### Cette semaine
4. Test reproductibilit√© 20 runs
5. Test split TSLA

### Ce mois
6. Observabilit√© (SLO, drift, logs)
7. Mode DETERMINISTIC

---

*Document auto-g√©n√©r√© par l'audit crois√© Claude + ChatGPT. Derni√®re mise √† jour: 2025-12-15T15:00:00Z*
